{
  "KSampler": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model used for denoising the input latent."
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true,
            "tooltip": "The random seed used for creating the noise."
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000,
            "tooltip": "The number of steps used in the denoising process."
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01,
            "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ],
          {
            "tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."
          }
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ],
          {
            "tooltip": "The scheduler controls how noise is gradually removed to form the image."
          }
        ],
        "positive": [
          "CONDITIONING",
          {
            "tooltip": "The conditioning describing the attributes you want to include in the image."
          }
        ],
        "negative": [
          "CONDITIONING",
          {
            "tooltip": "The conditioning describing the attributes you want to exclude from the image."
          }
        ],
        "latent_image": [
          "LATENT",
          {
            "tooltip": "The latent image to denoise."
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "denoise"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "KSampler",
    "display_name": "KSampler",
    "description": "Uses the provided model, positive and negative conditioning to denoise the latent image.",
    "python_module": "nodes",
    "category": "sampling",
    "output_node": false,
    "output_tooltips": [
      "The denoised latent."
    ]
  },
  "CheckpointLoaderSimple": {
    "input": {
      "required": {
        "ckpt_name": [
          [],
          {
            "tooltip": "The name of the checkpoint (model) to load."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "name": "CheckpointLoaderSimple",
    "display_name": "Load Checkpoint",
    "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false,
    "output_tooltips": [
      "The model used for denoising latents.",
      "The CLIP model used for encoding text prompts.",
      "The VAE model used for encoding and decoding images to and from latent space."
    ]
  },
  "CLIPTextEncode": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true,
            "tooltip": "The text to be encoded."
          }
        ],
        "clip": [
          "CLIP",
          {
            "tooltip": "The CLIP model used for encoding the text."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "CLIPTextEncode",
    "display_name": "CLIP Text Encode (Prompt)",
    "description": "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false,
    "output_tooltips": [
      "A conditioning containing the embedded text used to guide the diffusion model."
    ]
  },
  "CLIPSetLastLayer": {
    "input": {
      "required": {
        "clip": [
          "CLIP"
        ],
        "stop_at_clip_layer": [
          "INT",
          {
            "default": -1,
            "min": -24,
            "max": -1,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "stop_at_clip_layer"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIPSetLastLayer",
    "display_name": "CLIP Set Last Layer",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "VAEDecode": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {
            "tooltip": "The latent to be decoded."
          }
        ],
        "vae": [
          "VAE",
          {
            "tooltip": "The VAE model used for decoding the latent."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "vae"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "VAEDecode",
    "display_name": "VAE Decode",
    "description": "Decodes latent images back into pixel space images.",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false,
    "output_tooltips": [
      "The decoded image."
    ]
  },
  "VAEEncode": {
    "input": {
      "required": {
        "pixels": [
          "IMAGE"
        ],
        "vae": [
          "VAE"
        ]
      }
    },
    "input_order": {
      "required": [
        "pixels",
        "vae"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "VAEEncode",
    "display_name": "VAE Encode",
    "description": "",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false
  },
  "VAEEncodeForInpaint": {
    "input": {
      "required": {
        "pixels": [
          "IMAGE"
        ],
        "vae": [
          "VAE"
        ],
        "mask": [
          "MASK"
        ],
        "grow_mask_by": [
          "INT",
          {
            "default": 6,
            "min": 0,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pixels",
        "vae",
        "mask",
        "grow_mask_by"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "VAEEncodeForInpaint",
    "display_name": "VAE Encode (for Inpainting)",
    "description": "",
    "python_module": "nodes",
    "category": "latent/inpaint",
    "output_node": false
  },
  "VAELoader": {
    "input": {
      "required": {
        "vae_name": [
          [
            "pixel_space"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "vae_name"
      ]
    },
    "output": [
      "VAE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VAE"
    ],
    "name": "VAELoader",
    "display_name": "Load VAE",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "EmptyLatentImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "min": 16,
            "max": 16384,
            "step": 8,
            "tooltip": "The width of the latent images in pixels."
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 16,
            "max": 16384,
            "step": 8,
            "tooltip": "The height of the latent images in pixels."
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096,
            "tooltip": "The number of latent images in the batch."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "EmptyLatentImage",
    "display_name": "Empty Latent Image",
    "description": "Create a new batch of empty latent images to be denoised via sampling.",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false,
    "output_tooltips": [
      "The empty latent image batch."
    ]
  },
  "LatentUpscale": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "upscale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "crop": [
          [
            "disabled",
            "center"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "upscale_method",
        "width",
        "height",
        "crop"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentUpscale",
    "display_name": "Upscale Latent",
    "description": "",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false
  },
  "LatentUpscaleBy": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "upscale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "scale_by": [
          "FLOAT",
          {
            "default": 1.5,
            "min": 0.01,
            "max": 8.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "upscale_method",
        "scale_by"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentUpscaleBy",
    "display_name": "Upscale Latent By",
    "description": "",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false
  },
  "LatentFromBatch": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "batch_index": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 63
          }
        ],
        "length": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "batch_index",
        "length"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentFromBatch",
    "display_name": "Latent From Batch",
    "description": "",
    "python_module": "nodes",
    "category": "latent/batch",
    "output_node": false
  },
  "RepeatLatentBatch": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "amount": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "amount"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "RepeatLatentBatch",
    "display_name": "Repeat Latent Batch",
    "description": "",
    "python_module": "nodes",
    "category": "latent/batch",
    "output_node": false
  },
  "SaveImage": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "The images to save."
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI",
            "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "images",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveImage",
    "display_name": "Save Image",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "nodes",
    "category": "image",
    "output_node": true
  },
  "PreviewImage": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "images"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "PreviewImage",
    "display_name": "Preview Image",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "nodes",
    "category": "image",
    "output_node": true
  },
  "LoadImage": {
    "input": {
      "required": {
        "image": [
          [],
          {
            "image_upload": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "LoadImage",
    "display_name": "Load Image",
    "description": "",
    "python_module": "nodes",
    "category": "image",
    "output_node": false
  },
  "LoadImageMask": {
    "input": {
      "required": {
        "image": [
          [],
          {
            "image_upload": true
          }
        ],
        "channel": [
          [
            "alpha",
            "red",
            "green",
            "blue"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "channel"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "LoadImageMask",
    "display_name": "Load Image (as Mask)",
    "description": "",
    "python_module": "nodes",
    "category": "mask",
    "output_node": false
  },
  "LoadImageOutput": {
    "input": {
      "required": {
        "image": [
          "COMBO",
          {
            "image_upload": true,
            "image_folder": "output",
            "remote": {
              "route": "/internal/files/output",
              "refresh_button": true,
              "control_after_refresh": "first"
            }
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "LoadImageOutput",
    "display_name": "Load Image (from Outputs)",
    "description": "Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.",
    "python_module": "nodes",
    "category": "image",
    "output_node": false,
    "experimental": true
  },
  "ImageScale": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "upscale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ]
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "crop": [
          [
            "disabled",
            "center"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "upscale_method",
        "width",
        "height",
        "crop"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageScale",
    "display_name": "Upscale Image",
    "description": "",
    "python_module": "nodes",
    "category": "image/upscaling",
    "output_node": false
  },
  "ImageScaleBy": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "upscale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ]
        ],
        "scale_by": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 8.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "upscale_method",
        "scale_by"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageScaleBy",
    "display_name": "Upscale Image By",
    "description": "",
    "python_module": "nodes",
    "category": "image/upscaling",
    "output_node": false
  },
  "ImageInvert": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageInvert",
    "display_name": "Invert Image",
    "description": "",
    "python_module": "nodes",
    "category": "image",
    "output_node": false
  },
  "ImageBatch": {
    "input": {
      "required": {
        "image1": [
          "IMAGE"
        ],
        "image2": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image1",
        "image2"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageBatch",
    "display_name": "Batch Images",
    "description": "",
    "python_module": "nodes",
    "category": "image",
    "output_node": false
  },
  "ImagePadForOutpaint": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "left": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "top": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "right": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "bottom": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "feathering": [
          "INT",
          {
            "default": 40,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "left",
        "top",
        "right",
        "bottom",
        "feathering"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "ImagePadForOutpaint",
    "display_name": "Pad Image for Outpainting",
    "description": "",
    "python_module": "nodes",
    "category": "image",
    "output_node": false
  },
  "EmptyImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "color": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16777215,
            "step": 1,
            "display": "color"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size",
        "color"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "EmptyImage",
    "display_name": "EmptyImage",
    "description": "",
    "python_module": "nodes",
    "category": "image",
    "output_node": false
  },
  "ConditioningAverage": {
    "input": {
      "required": {
        "conditioning_to": [
          "CONDITIONING"
        ],
        "conditioning_from": [
          "CONDITIONING"
        ],
        "conditioning_to_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_to",
        "conditioning_from",
        "conditioning_to_strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningAverage",
    "display_name": "ConditioningAverage",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningCombine": {
    "input": {
      "required": {
        "conditioning_1": [
          "CONDITIONING"
        ],
        "conditioning_2": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_1",
        "conditioning_2"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningCombine",
    "display_name": "Conditioning (Combine)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningConcat": {
    "input": {
      "required": {
        "conditioning_to": [
          "CONDITIONING"
        ],
        "conditioning_from": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_to",
        "conditioning_from"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningConcat",
    "display_name": "Conditioning (Concat)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningSetArea": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "width": [
          "INT",
          {
            "default": 64,
            "min": 64,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 64,
            "min": 64,
            "max": 16384,
            "step": 8
          }
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "width",
        "height",
        "x",
        "y",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetArea",
    "display_name": "Conditioning (Set Area)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningSetAreaPercentage": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "width": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "height": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "y": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "width",
        "height",
        "x",
        "y",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetAreaPercentage",
    "display_name": "Conditioning (Set Area with Percentage)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningSetAreaStrength": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetAreaStrength",
    "display_name": "ConditioningSetAreaStrength",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ConditioningSetMask": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "mask": [
          "MASK"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "set_cond_area": [
          [
            "default",
            "mask bounds"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "mask",
        "strength",
        "set_cond_area"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetMask",
    "display_name": "Conditioning (Set Mask)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "KSamplerAdvanced": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "add_noise": [
          [
            "enable",
            "disable"
          ]
        ],
        "noise_seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "latent_image": [
          "LATENT"
        ],
        "start_at_step": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10000
          }
        ],
        "end_at_step": [
          "INT",
          {
            "default": 10000,
            "min": 0,
            "max": 10000
          }
        ],
        "return_with_leftover_noise": [
          [
            "disable",
            "enable"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "add_noise",
        "noise_seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "start_at_step",
        "end_at_step",
        "return_with_leftover_noise"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "KSamplerAdvanced",
    "display_name": "KSampler (Advanced)",
    "description": "",
    "python_module": "nodes",
    "category": "sampling",
    "output_node": false
  },
  "SetLatentNoiseMask": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "mask"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "SetLatentNoiseMask",
    "display_name": "Set Latent Noise Mask",
    "description": "",
    "python_module": "nodes",
    "category": "latent/inpaint",
    "output_node": false
  },
  "LatentComposite": {
    "input": {
      "required": {
        "samples_to": [
          "LATENT"
        ],
        "samples_from": [
          "LATENT"
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "feather": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples_to",
        "samples_from",
        "x",
        "y",
        "feather"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentComposite",
    "display_name": "Latent Composite",
    "description": "",
    "python_module": "nodes",
    "category": "latent",
    "output_node": false
  },
  "LatentBlend": {
    "input": {
      "required": {
        "samples1": [
          "LATENT"
        ],
        "samples2": [
          "LATENT"
        ],
        "blend_factor": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2",
        "blend_factor"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentBlend",
    "display_name": "Latent Blend",
    "description": "",
    "python_module": "nodes",
    "category": "_for_testing",
    "output_node": false
  },
  "LatentRotate": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "rotation": [
          [
            "none",
            "90 degrees",
            "180 degrees",
            "270 degrees"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "rotation"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentRotate",
    "display_name": "Rotate Latent",
    "description": "",
    "python_module": "nodes",
    "category": "latent/transform",
    "output_node": false
  },
  "LatentFlip": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "flip_method": [
          [
            "x-axis: vertically",
            "y-axis: horizontally"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "flip_method"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentFlip",
    "display_name": "Flip Latent",
    "description": "",
    "python_module": "nodes",
    "category": "latent/transform",
    "output_node": false
  },
  "LatentCrop": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 8
          }
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "width",
        "height",
        "x",
        "y"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LatentCrop",
    "display_name": "Crop Latent",
    "description": "",
    "python_module": "nodes",
    "category": "latent/transform",
    "output_node": false
  },
  "LoraLoader": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The diffusion model the LoRA will be applied to."
          }
        ],
        "clip": [
          "CLIP",
          {
            "tooltip": "The CLIP model the LoRA will be applied to."
          }
        ],
        "lora_name": [
          [],
          {
            "tooltip": "The name of the LoRA."
          }
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -100.0,
            "max": 100.0,
            "step": 0.01,
            "tooltip": "How strongly to modify the diffusion model. This value can be negative."
          }
        ],
        "strength_clip": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -100.0,
            "max": 100.0,
            "step": 0.01,
            "tooltip": "How strongly to modify the CLIP model. This value can be negative."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip",
        "lora_name",
        "strength_model",
        "strength_clip"
      ]
    },
    "output": [
      "MODEL",
      "CLIP"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP"
    ],
    "name": "LoraLoader",
    "display_name": "Load LoRA",
    "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false,
    "output_tooltips": [
      "The modified diffusion model.",
      "The modified CLIP model."
    ]
  },
  "CLIPLoader": {
    "input": {
      "required": {
        "clip_name": [
          []
        ],
        "type": [
          [
            "stable_diffusion",
            "stable_cascade",
            "sd3",
            "stable_audio",
            "mochi",
            "ltxv",
            "pixart",
            "cosmos",
            "lumina2",
            "wan",
            "hidream",
            "chroma",
            "ace",
            "omnigen2",
            "qwen_image",
            "hunyuan_image",
            "flux2",
            "ovis"
          ]
        ]
      },
      "optional": {
        "device": [
          [
            "default",
            "cpu"
          ],
          {
            "advanced": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_name",
        "type"
      ],
      "optional": [
        "device"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIPLoader",
    "display_name": "Load CLIP",
    "description": "[Recipes]\n\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 xxl/ clip-g / clip-l\nstable_audio: t5 base\nmochi: t5 xxl\ncosmos: old t5 xxl\nlumina2: gemma 2 2B\nwan: umt5 xxl\n hidream: llama-3.1 (Recommend) or t5\nomnigen2: qwen vl 2.5 3B",
    "python_module": "nodes",
    "category": "advanced/loaders",
    "output_node": false
  },
  "UNETLoader": {
    "input": {
      "required": {
        "unet_name": [
          []
        ],
        "weight_dtype": [
          [
            "default",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "unet_name",
        "weight_dtype"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "UNETLoader",
    "display_name": "Load Diffusion Model",
    "description": "",
    "python_module": "nodes",
    "category": "advanced/loaders",
    "output_node": false
  },
  "DualCLIPLoader": {
    "input": {
      "required": {
        "clip_name1": [
          []
        ],
        "clip_name2": [
          []
        ],
        "type": [
          [
            "sdxl",
            "sd3",
            "flux",
            "hunyuan_video",
            "hidream",
            "hunyuan_image",
            "hunyuan_video_15",
            "kandinsky5",
            "kandinsky5_image"
          ]
        ]
      },
      "optional": {
        "device": [
          [
            "default",
            "cpu"
          ],
          {
            "advanced": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_name1",
        "clip_name2",
        "type"
      ],
      "optional": [
        "device"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "DualCLIPLoader",
    "display_name": "DualCLIPLoader",
    "description": "[Recipes]\n\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5\nhidream: at least one of t5 or llama, recommended t5 and llama\nhunyuan_image: qwen2.5vl 7b and byt5 small",
    "python_module": "nodes",
    "category": "advanced/loaders",
    "output_node": false
  },
  "CLIPVisionEncode": {
    "input": {
      "required": {
        "clip_vision": [
          "CLIP_VISION"
        ],
        "image": [
          "IMAGE"
        ],
        "crop": [
          [
            "center",
            "none"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision",
        "image",
        "crop"
      ]
    },
    "output": [
      "CLIP_VISION_OUTPUT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP_VISION_OUTPUT"
    ],
    "name": "CLIPVisionEncode",
    "display_name": "CLIP Vision Encode",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "StyleModelApply": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "style_model": [
          "STYLE_MODEL"
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.001
          }
        ],
        "strength_type": [
          [
            "multiply",
            "attn_bias"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "style_model",
        "clip_vision_output",
        "strength",
        "strength_type"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "StyleModelApply",
    "display_name": "Apply Style Model",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning/style_model",
    "output_node": false
  },
  "unCLIPConditioning": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "noise_augmentation": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "clip_vision_output",
        "strength",
        "noise_augmentation"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "unCLIPConditioning",
    "display_name": "unCLIPConditioning",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning",
    "output_node": false
  },
  "ControlNetApply": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "control_net": [
          "CONTROL_NET"
        ],
        "image": [
          "IMAGE"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "control_net",
        "image",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ControlNetApply",
    "display_name": "Apply ControlNet (OLD)",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning/controlnet",
    "output_node": false,
    "deprecated": true
  },
  "ControlNetApplyAdvanced": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "control_net": [
          "CONTROL_NET"
        ],
        "image": [
          "IMAGE"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "vae": [
          "VAE"
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "control_net",
        "image",
        "strength",
        "start_percent",
        "end_percent"
      ],
      "optional": [
        "vae"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "ControlNetApplyAdvanced",
    "display_name": "Apply ControlNet",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning/controlnet",
    "output_node": false
  },
  "ControlNetLoader": {
    "input": {
      "required": {
        "control_net_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "control_net_name"
      ]
    },
    "output": [
      "CONTROL_NET"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONTROL_NET"
    ],
    "name": "ControlNetLoader",
    "display_name": "Load ControlNet Model",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "DiffControlNetLoader": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "control_net_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "control_net_name"
      ]
    },
    "output": [
      "CONTROL_NET"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONTROL_NET"
    ],
    "name": "DiffControlNetLoader",
    "display_name": "Load ControlNet Model (diff)",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "StyleModelLoader": {
    "input": {
      "required": {
        "style_model_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "style_model_name"
      ]
    },
    "output": [
      "STYLE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STYLE_MODEL"
    ],
    "name": "StyleModelLoader",
    "display_name": "Load Style Model",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "CLIPVisionLoader": {
    "input": {
      "required": {
        "clip_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_name"
      ]
    },
    "output": [
      "CLIP_VISION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP_VISION"
    ],
    "name": "CLIPVisionLoader",
    "display_name": "Load CLIP Vision",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "VAEDecodeTiled": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "vae": [
          "VAE"
        ],
        "tile_size": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096,
            "step": 32
          }
        ],
        "overlap": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 4096,
            "step": 32
          }
        ],
        "temporal_size": [
          "INT",
          {
            "default": 64,
            "min": 8,
            "max": 4096,
            "step": 4,
            "tooltip": "Only used for video VAEs: Amount of frames to decode at a time."
          }
        ],
        "temporal_overlap": [
          "INT",
          {
            "default": 8,
            "min": 4,
            "max": 4096,
            "step": 4,
            "tooltip": "Only used for video VAEs: Amount of frames to overlap."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "vae",
        "tile_size",
        "overlap",
        "temporal_size",
        "temporal_overlap"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "VAEDecodeTiled",
    "display_name": "VAE Decode (Tiled)",
    "description": "",
    "python_module": "nodes",
    "category": "_for_testing",
    "output_node": false
  },
  "VAEEncodeTiled": {
    "input": {
      "required": {
        "pixels": [
          "IMAGE"
        ],
        "vae": [
          "VAE"
        ],
        "tile_size": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096,
            "step": 64
          }
        ],
        "overlap": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 4096,
            "step": 32
          }
        ],
        "temporal_size": [
          "INT",
          {
            "default": 64,
            "min": 8,
            "max": 4096,
            "step": 4,
            "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."
          }
        ],
        "temporal_overlap": [
          "INT",
          {
            "default": 8,
            "min": 4,
            "max": 4096,
            "step": 4,
            "tooltip": "Only used for video VAEs: Amount of frames to overlap."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pixels",
        "vae",
        "tile_size",
        "overlap",
        "temporal_size",
        "temporal_overlap"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "VAEEncodeTiled",
    "display_name": "VAE Encode (Tiled)",
    "description": "",
    "python_module": "nodes",
    "category": "_for_testing",
    "output_node": false
  },
  "unCLIPCheckpointLoader": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "CLIP_VISION"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "CLIP_VISION"
    ],
    "name": "unCLIPCheckpointLoader",
    "display_name": "unCLIPCheckpointLoader",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "GLIGENLoader": {
    "input": {
      "required": {
        "gligen_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "gligen_name"
      ]
    },
    "output": [
      "GLIGEN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GLIGEN"
    ],
    "name": "GLIGENLoader",
    "display_name": "GLIGENLoader",
    "description": "",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false
  },
  "GLIGENTextBoxApply": {
    "input": {
      "required": {
        "conditioning_to": [
          "CONDITIONING"
        ],
        "clip": [
          "CLIP"
        ],
        "gligen_textbox_model": [
          "GLIGEN"
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "width": [
          "INT",
          {
            "default": 64,
            "min": 8,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 64,
            "min": 8,
            "max": 16384,
            "step": 8
          }
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_to",
        "clip",
        "gligen_textbox_model",
        "text",
        "width",
        "height",
        "x",
        "y"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "GLIGENTextBoxApply",
    "display_name": "GLIGENTextBoxApply",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning/gligen",
    "output_node": false
  },
  "InpaintModelConditioning": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "vae": [
          "VAE"
        ],
        "pixels": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ],
        "noise_mask": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "pixels",
        "mask",
        "noise_mask"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "name": "InpaintModelConditioning",
    "display_name": "InpaintModelConditioning",
    "description": "",
    "python_module": "nodes",
    "category": "conditioning/inpaint",
    "output_node": false
  },
  "CheckpointLoader": {
    "input": {
      "required": {
        "config_name": [
          [
            "anything_v3.yaml",
            "v1-inference.yaml",
            "v1-inference_clip_skip_2.yaml",
            "v1-inference_clip_skip_2_fp16.yaml",
            "v1-inference_fp16.yaml",
            "v1-inpainting-inference.yaml",
            "v2-inference-v.yaml",
            "v2-inference-v_fp32.yaml",
            "v2-inference.yaml",
            "v2-inference_fp32.yaml",
            "v2-inpainting-inference.yaml"
          ]
        ],
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "config_name",
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "name": "CheckpointLoader",
    "display_name": "Load Checkpoint With Config (DEPRECATED)",
    "description": "",
    "python_module": "nodes",
    "category": "advanced/loaders",
    "output_node": false,
    "deprecated": true
  },
  "DiffusersLoader": {
    "input": {
      "required": {
        "model_path": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "model_path"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE"
    ],
    "name": "DiffusersLoader",
    "display_name": "DiffusersLoader",
    "description": "",
    "python_module": "nodes",
    "category": "advanced/loaders/deprecated",
    "output_node": false
  },
  "LoadLatent": {
    "input": {
      "required": {
        "latent": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "latent"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "LoadLatent",
    "display_name": "LoadLatent",
    "description": "",
    "python_module": "nodes",
    "category": "_for_testing",
    "output_node": false
  },
  "SaveLatent": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "latents/ComfyUI"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "samples",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveLatent",
    "display_name": "SaveLatent",
    "description": "",
    "python_module": "nodes",
    "category": "_for_testing",
    "output_node": true
  },
  "ConditioningZeroOut": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningZeroOut",
    "display_name": "ConditioningZeroOut",
    "description": "",
    "python_module": "nodes",
    "category": "advanced/conditioning",
    "output_node": false
  },
  "ConditioningSetTimestepRange": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "start": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "start",
        "end"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetTimestepRange",
    "display_name": "ConditioningSetTimestepRange",
    "description": "",
    "python_module": "nodes",
    "category": "advanced/conditioning",
    "output_node": false
  },
  "LoraLoaderModelOnly": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "lora_name": [
          []
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -100.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "lora_name",
        "strength_model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "LoraLoaderModelOnly",
    "display_name": "LoraLoaderModelOnly",
    "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    "python_module": "nodes",
    "category": "loaders",
    "output_node": false,
    "output_tooltips": [
      "The modified diffusion model.",
      "The modified CLIP model."
    ]
  },
  "LatentAdd": {
    "input": {
      "required": {
        "samples1": [
          "LATENT",
          {}
        ],
        "samples2": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentAdd",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentSubtract": {
    "input": {
      "required": {
        "samples1": [
          "LATENT",
          {}
        ],
        "samples2": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentSubtract",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentMultiply": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "multiplier": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "multiplier"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentMultiply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentInterpolate": {
    "input": {
      "required": {
        "samples1": [
          "LATENT",
          {}
        ],
        "samples2": [
          "LATENT",
          {}
        ],
        "ratio": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2",
        "ratio"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentInterpolate",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentConcat": {
    "input": {
      "required": {
        "samples1": [
          "LATENT",
          {}
        ],
        "samples2": [
          "LATENT",
          {}
        ],
        "dim": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "x",
              "-x",
              "y",
              "-y",
              "t",
              "-t"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2",
        "dim"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentConcat",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentCut": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "dim": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "x",
              "y",
              "t"
            ]
          }
        ],
        "index": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "amount": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "dim",
        "index",
        "amount"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentCut",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentBatch": {
    "input": {
      "required": {
        "samples1": [
          "LATENT",
          {}
        ],
        "samples2": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "samples1",
        "samples2"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentBatch",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentBatchSeedBehavior": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "seed_behavior": [
          "COMBO",
          {
            "default": "fixed",
            "multiselect": false,
            "options": [
              "random",
              "fixed"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "seed_behavior"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentBatchSeedBehavior",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentApplyOperation": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "operation": [
          "LATENT_OPERATION",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "operation"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentApplyOperation",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced/operations",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LatentApplyOperationCFG": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "operation": [
          "LATENT_OPERATION",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "operation"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentApplyOperationCFG",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced/operations",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LatentOperationTonemapReinhard": {
    "input": {
      "required": {
        "multiplier": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "multiplier"
      ]
    },
    "output": [
      "LATENT_OPERATION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT_OPERATION"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentOperationTonemapReinhard",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced/operations",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LatentOperationSharpen": {
    "input": {
      "required": {
        "sharpen_radius": [
          "INT",
          {
            "default": 9,
            "min": 1,
            "max": 31,
            "step": 1
          }
        ],
        "sigma": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 10.0,
            "step": 0.1
          }
        ],
        "alpha": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 5.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sharpen_radius",
        "sigma",
        "alpha"
      ]
    },
    "output": [
      "LATENT_OPERATION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT_OPERATION"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentOperationSharpen",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/advanced/operations",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ReplaceVideoLatentFrames": {
    "input": {
      "required": {
        "destination": [
          "LATENT",
          {
            "tooltip": "The destination latent where frames will be replaced."
          }
        ],
        "index": [
          "INT",
          {
            "tooltip": "The starting latent frame index in the destination latent where the source latent frames will be placed. Negative values count from the end.",
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ]
      },
      "optional": {
        "source": [
          "LATENT",
          {
            "tooltip": "The source latent providing frames to insert into the destination latent. If not provided, the destination latent is returned unchanged."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "destination",
        "index"
      ],
      "optional": [
        "source"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ReplaceVideoLatentFrames",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_latent",
    "category": "latent/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HypernetworkLoader": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "hypernetwork_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "hypernetwork_name",
        "strength"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "HypernetworkLoader",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hypernetwork",
    "category": "loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "UpscaleModelLoader": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name"
      ]
    },
    "output": [
      "UPSCALE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "UPSCALE_MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "UpscaleModelLoader",
    "display_name": "Load Upscale Model",
    "description": "",
    "python_module": "comfy_extras.nodes_upscale_model",
    "category": "loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageUpscaleWithModel": {
    "input": {
      "required": {
        "upscale_model": [
          "UPSCALE_MODEL",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "upscale_model",
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageUpscaleWithModel",
    "display_name": "Upscale Image (using Model)",
    "description": "",
    "python_module": "comfy_extras.nodes_upscale_model",
    "category": "image/upscaling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageBlend": {
    "input": {
      "required": {
        "image1": [
          "IMAGE",
          {}
        ],
        "image2": [
          "IMAGE",
          {}
        ],
        "blend_factor": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blend_mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "normal",
              "multiply",
              "screen",
              "overlay",
              "soft_light",
              "difference"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image1",
        "image2",
        "blend_factor",
        "blend_mode"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageBlend",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_post_processing",
    "category": "image/postprocessing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageBlur": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "blur_radius": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 31,
            "step": 1
          }
        ],
        "sigma": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 10.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "blur_radius",
        "sigma"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageBlur",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_post_processing",
    "category": "image/postprocessing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageQuantize": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "colors": [
          "INT",
          {
            "default": 256,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "dither": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "none",
              "floyd-steinberg",
              "bayer-2",
              "bayer-4",
              "bayer-8",
              "bayer-16"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "colors",
        "dither"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageQuantize",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_post_processing",
    "category": "image/postprocessing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageSharpen": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "sharpen_radius": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 31,
            "step": 1
          }
        ],
        "sigma": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "alpha": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 5.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "sharpen_radius",
        "sigma",
        "alpha"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageSharpen",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_post_processing",
    "category": "image/postprocessing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageScaleToTotalPixels": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "upscale_method": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "nearest-exact",
              "bilinear",
              "area",
              "bicubic",
              "lanczos"
            ]
          }
        ],
        "megapixels": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 16.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "upscale_method",
        "megapixels"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageScaleToTotalPixels",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_post_processing",
    "category": "image/upscaling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentCompositeMasked": {
    "input": {
      "required": {
        "destination": [
          "LATENT",
          {}
        ],
        "source": [
          "LATENT",
          {}
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "resize_source": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "destination",
        "source",
        "x",
        "y",
        "resize_source"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentCompositeMasked",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "latent",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageCompositeMasked": {
    "input": {
      "required": {
        "destination": [
          "IMAGE",
          {}
        ],
        "source": [
          "IMAGE",
          {}
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "resize_source": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "destination",
        "source",
        "x",
        "y",
        "resize_source"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageCompositeMasked",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "image",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "MaskToImage": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MaskToImage",
    "display_name": "Convert Mask to Image",
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageToMask": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "channel": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "red",
              "green",
              "blue",
              "alpha"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "channel"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageToMask",
    "display_name": "Convert Image to Mask",
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageColorToMask": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "color": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16777215,
            "step": 1,
            "display": "number"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "color"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageColorToMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SolidMask": {
    "input": {
      "required": {
        "value": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value",
        "width",
        "height"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SolidMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "InvertMask": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "mask"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "InvertMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CropMask": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "x",
        "y",
        "width",
        "height"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CropMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "MaskComposite": {
    "input": {
      "required": {
        "destination": [
          "MASK",
          {}
        ],
        "source": [
          "MASK",
          {}
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "operation": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "multiply",
              "add",
              "subtract",
              "and",
              "or",
              "xor"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "destination",
        "source",
        "x",
        "y",
        "operation"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MaskComposite",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FeatherMask": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ],
        "left": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "top": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "right": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "bottom": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "left",
        "top",
        "right",
        "bottom"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FeatherMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "GrowMask": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ],
        "expand": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "tapered_corners": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "expand",
        "tapered_corners"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "GrowMask",
    "display_name": "Grow Mask",
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ThresholdMask": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ],
        "value": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "value"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ThresholdMask",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "MaskPreview": {
    "input": {
      "required": {
        "mask": [
          "MASK",
          {}
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "mask"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "MaskPreview",
    "display_name": "Preview Mask",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "comfy_extras.nodes_mask",
    "category": "mask",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PorterDuffImageComposite": {
    "input": {
      "required": {
        "source": [
          "IMAGE",
          {}
        ],
        "source_alpha": [
          "MASK",
          {}
        ],
        "destination": [
          "IMAGE",
          {}
        ],
        "destination_alpha": [
          "MASK",
          {}
        ],
        "mode": [
          "COMBO",
          {
            "default": "DST",
            "multiselect": false,
            "options": [
              "ADD",
              "CLEAR",
              "DARKEN",
              "DST",
              "DST_ATOP",
              "DST_IN",
              "DST_OUT",
              "DST_OVER",
              "LIGHTEN",
              "MULTIPLY",
              "OVERLAY",
              "SCREEN",
              "SRC",
              "SRC_ATOP",
              "SRC_IN",
              "SRC_OUT",
              "SRC_OVER",
              "XOR"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "source",
        "source_alpha",
        "destination",
        "destination_alpha",
        "mode"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "PorterDuffImageComposite",
    "display_name": "Porter-Duff Image Composite",
    "description": "",
    "python_module": "comfy_extras.nodes_compositing",
    "category": "mask/compositing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SplitImageWithAlpha": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SplitImageWithAlpha",
    "display_name": "Split Image with Alpha",
    "description": "",
    "python_module": "comfy_extras.nodes_compositing",
    "category": "mask/compositing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "JoinImageWithAlpha": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "alpha": [
          "MASK",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "alpha"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "JoinImageWithAlpha",
    "display_name": "Join Image with Alpha",
    "description": "",
    "python_module": "comfy_extras.nodes_compositing",
    "category": "mask/compositing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RebatchLatents": {
    "input": {
      "required": {
        "latents": [
          "LATENT",
          {}
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latents",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RebatchLatents",
    "display_name": "Rebatch Latents",
    "description": "",
    "python_module": "comfy_extras.nodes_rebatch",
    "category": "latent/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RebatchImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {}
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "batch_size"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RebatchImages",
    "display_name": "Rebatch Images",
    "description": "",
    "python_module": "comfy_extras.nodes_rebatch",
    "category": "image/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ModelMergeSimple": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "ratio": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "ratio"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSimple",
    "display_name": "ModelMergeSimple",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "ModelMergeBlocks": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "input": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "out": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "input",
        "middle",
        "out"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeBlocks",
    "display_name": "ModelMergeBlocks",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "ModelMergeSubtract": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "multiplier": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "multiplier"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSubtract",
    "display_name": "ModelMergeSubtract",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "ModelMergeAdd": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeAdd",
    "display_name": "ModelMergeAdd",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "CheckpointSave": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "vae": [
          "VAE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "checkpoints/ComfyUI"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip",
        "vae",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "CheckpointSave",
    "display_name": "Save Checkpoint",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": true
  },
  "CLIPMergeSimple": {
    "input": {
      "required": {
        "clip1": [
          "CLIP"
        ],
        "clip2": [
          "CLIP"
        ],
        "ratio": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip1",
        "clip2",
        "ratio"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIPMergeSimple",
    "display_name": "CLIPMergeSimple",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "CLIPMergeSubtract": {
    "input": {
      "required": {
        "clip1": [
          "CLIP"
        ],
        "clip2": [
          "CLIP"
        ],
        "multiplier": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip1",
        "clip2",
        "multiplier"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIPMergeSubtract",
    "display_name": "CLIPMergeSubtract",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "CLIPMergeAdd": {
    "input": {
      "required": {
        "clip1": [
          "CLIP"
        ],
        "clip2": [
          "CLIP"
        ]
      }
    },
    "input_order": {
      "required": [
        "clip1",
        "clip2"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIPMergeAdd",
    "display_name": "CLIPMergeAdd",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": false
  },
  "CLIPSave": {
    "input": {
      "required": {
        "clip": [
          "CLIP"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "clip/ComfyUI"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "clip",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "CLIPSave",
    "display_name": "CLIPSave",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": true
  },
  "VAESave": {
    "input": {
      "required": {
        "vae": [
          "VAE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "vae/ComfyUI_vae"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "vae",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "VAESave",
    "display_name": "VAESave",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": true
  },
  "ModelSave": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "diffusion_models/ComfyUI"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "model",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "ModelSave",
    "display_name": "ModelSave",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging",
    "category": "advanced/model_merging",
    "output_node": true
  },
  "TomePatchModel": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "ratio": [
          "FLOAT",
          {
            "default": 0.3,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ratio"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TomePatchModel",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_tomesd",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeSDXLRefiner": {
    "input": {
      "required": {
        "ascore": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "clip": [
          "CLIP",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "ascore",
        "width",
        "height",
        "text",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeSDXLRefiner",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_clip_sdxl",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeSDXL": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "crop_w": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384
          }
        ],
        "crop_h": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384
          }
        ],
        "target_width": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "target_height": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "text_g": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "text_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "width",
        "height",
        "crop_w",
        "crop_h",
        "target_width",
        "target_height",
        "text_g",
        "text_l"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeSDXL",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_clip_sdxl",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Canny": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "low_threshold": [
          "FLOAT",
          {
            "default": 0.4,
            "min": 0.01,
            "max": 0.99,
            "step": 0.01
          }
        ],
        "high_threshold": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.01,
            "max": 0.99,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "low_threshold",
        "high_threshold"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Canny",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_canny",
    "category": "image/preprocessors",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FreeU": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "b1": [
          "FLOAT",
          {
            "default": 1.1,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "b2": [
          "FLOAT",
          {
            "default": 1.2,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "s1": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "s2": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "b1",
        "b2",
        "s1",
        "s2"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FreeU",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_freelunch",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FreeU_V2": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "b1": [
          "FLOAT",
          {
            "default": 1.3,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "b2": [
          "FLOAT",
          {
            "default": 1.4,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "s1": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "s2": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "b1",
        "b2",
        "s1",
        "s2"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FreeU_V2",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_freelunch",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerCustom": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "add_noise": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "noise_seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "sampler": [
          "SAMPLER",
          {}
        ],
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "latent_image": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "add_noise",
        "noise_seed",
        "cfg",
        "positive",
        "negative",
        "sampler",
        "sigmas",
        "latent_image"
      ]
    },
    "output": [
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "output",
      "denoised_output"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerCustom",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "BasicScheduler": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scheduler": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "simple",
              "sgm_uniform",
              "karras",
              "exponential",
              "ddim_uniform",
              "beta",
              "normal",
              "linear_quadratic",
              "kl_optimal"
            ]
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scheduler",
        "steps",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "BasicScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "KarrasScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 14.614642,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.0291675,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "rho": [
          "FLOAT",
          {
            "default": 7.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "sigma_max",
        "sigma_min",
        "rho"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KarrasScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ExponentialScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 14.614642,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.0291675,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "sigma_max",
        "sigma_min"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ExponentialScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PolyexponentialScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 14.614642,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.0291675,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "rho": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "sigma_max",
        "sigma_min",
        "rho"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PolyexponentialScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LaplaceScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 14.614642,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.0291675,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "mu": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.1,
            "round": false
          }
        ],
        "beta": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 10.0,
            "step": 0.1,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "sigma_max",
        "sigma_min",
        "mu",
        "beta"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LaplaceScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VPScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "beta_d": [
          "FLOAT",
          {
            "default": 19.9,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "beta_min": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 5000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "eps_s": [
          "FLOAT",
          {
            "default": 0.001,
            "min": 0.0,
            "max": 1.0,
            "step": 0.0001,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "beta_d",
        "beta_min",
        "eps_s"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VPScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "BetaSamplingScheduler": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "alpha": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.0,
            "max": 50.0,
            "step": 0.01,
            "round": false
          }
        ],
        "beta": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.0,
            "max": 50.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "steps",
        "alpha",
        "beta"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "BetaSamplingScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SDTurboScheduler": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "steps": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 10
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "steps",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SDTurboScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "KSamplerSelect": {
    "input": {
      "required": {
        "sampler_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "euler",
              "euler_cfg_pp",
              "euler_ancestral",
              "euler_ancestral_cfg_pp",
              "heun",
              "heunpp2",
              "dpm_2",
              "dpm_2_ancestral",
              "lms",
              "dpm_fast",
              "dpm_adaptive",
              "dpmpp_2s_ancestral",
              "dpmpp_2s_ancestral_cfg_pp",
              "dpmpp_sde",
              "dpmpp_sde_gpu",
              "dpmpp_2m",
              "dpmpp_2m_cfg_pp",
              "dpmpp_2m_sde",
              "dpmpp_2m_sde_gpu",
              "dpmpp_2m_sde_heun",
              "dpmpp_2m_sde_heun_gpu",
              "dpmpp_3m_sde",
              "dpmpp_3m_sde_gpu",
              "ddpm",
              "lcm",
              "ipndm",
              "ipndm_v",
              "deis",
              "res_multistep",
              "res_multistep_cfg_pp",
              "res_multistep_ancestral",
              "res_multistep_ancestral_cfg_pp",
              "gradient_estimation",
              "gradient_estimation_cfg_pp",
              "er_sde",
              "seeds_2",
              "seeds_3",
              "sa_solver",
              "sa_solver_pece",
              "ddim",
              "uni_pc",
              "uni_pc_bh2"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sampler_name"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KSamplerSelect",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerEulerAncestral": {
    "input": {
      "required": {
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "eta",
        "s_noise"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerEulerAncestral",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerEulerAncestralCFGPP": {
    "input": {
      "required": {
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "eta",
        "s_noise"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerEulerAncestralCFGPP",
    "display_name": "SamplerEulerAncestralCFG++",
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerLMS": {
    "input": {
      "required": {
        "order": [
          "INT",
          {
            "default": 4,
            "min": 1,
            "max": 100
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "order"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerLMS",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerDPMPP_3M_SDE": {
    "input": {
      "required": {
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "noise_device": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "gpu",
              "cpu"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "eta",
        "s_noise",
        "noise_device"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerDPMPP_3M_SDE",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerDPMPP_2M_SDE": {
    "input": {
      "required": {
        "solver_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "midpoint",
              "heun"
            ]
          }
        ],
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "noise_device": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "gpu",
              "cpu"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "solver_type",
        "eta",
        "s_noise",
        "noise_device"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerDPMPP_2M_SDE",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerDPMPP_SDE": {
    "input": {
      "required": {
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "r": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "noise_device": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "gpu",
              "cpu"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "eta",
        "s_noise",
        "r",
        "noise_device"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerDPMPP_SDE",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerDPMPP_2S_Ancestral": {
    "input": {
      "required": {
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "eta",
        "s_noise"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerDPMPP_2S_Ancestral",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerDPMAdaptative": {
    "input": {
      "required": {
        "order": [
          "INT",
          {
            "default": 3,
            "min": 2,
            "max": 3
          }
        ],
        "rtol": [
          "FLOAT",
          {
            "default": 0.05,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "atol": [
          "FLOAT",
          {
            "default": 0.0078,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "h_init": [
          "FLOAT",
          {
            "default": 0.05,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "pcoeff": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "icoeff": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "dcoeff": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "accept_safety": [
          "FLOAT",
          {
            "default": 0.81,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "eta": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "order",
        "rtol",
        "atol",
        "h_init",
        "pcoeff",
        "icoeff",
        "dcoeff",
        "accept_safety",
        "eta",
        "s_noise"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerDPMAdaptative",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerER_SDE": {
    "input": {
      "required": {
        "solver_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "ER-SDE",
              "Reverse-time SDE",
              "ODE"
            ]
          }
        ],
        "max_stage": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 3
          }
        ],
        "eta": [
          "FLOAT",
          {
            "tooltip": "Stochastic strength of reverse-time SDE.\nWhen eta=0, it reduces to deterministic ODE. This setting doesn't apply to ER-SDE solver type.",
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "solver_type",
        "max_stage",
        "eta",
        "s_noise"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerER_SDE",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerSASolver": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "eta": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01,
            "round": false
          }
        ],
        "sde_start_percent": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "sde_end_percent": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "s_noise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": false
          }
        ],
        "predictor_order": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 6
          }
        ],
        "corrector_order": [
          "INT",
          {
            "default": 4,
            "min": 0,
            "max": 6
          }
        ],
        "use_pece": [
          "BOOLEAN",
          {}
        ],
        "simple_order_2": [
          "BOOLEAN",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "eta",
        "sde_start_percent",
        "sde_end_percent",
        "s_noise",
        "predictor_order",
        "corrector_order",
        "use_pece",
        "simple_order_2"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerSASolver",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SplitSigmas": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "step": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10000
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "step"
      ]
    },
    "output": [
      "SIGMAS",
      "SIGMAS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "high_sigmas",
      "low_sigmas"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SplitSigmas",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SplitSigmasDenoise": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS",
      "SIGMAS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "high_sigmas",
      "low_sigmas"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SplitSigmasDenoise",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FlipSigmas": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FlipSigmas",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SetFirstSigma": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "sigma": [
          "FLOAT",
          {
            "default": 136.0,
            "min": 0.0,
            "max": 20000.0,
            "step": 0.001,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "sigma"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SetFirstSigma",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ExtendIntermediateSigmas": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "steps": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 100
          }
        ],
        "start_at_sigma": [
          "FLOAT",
          {
            "default": -1.0,
            "min": -1.0,
            "max": 20000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "end_at_sigma": [
          "FLOAT",
          {
            "default": 12.0,
            "min": 0.0,
            "max": 20000.0,
            "step": 0.01,
            "round": false
          }
        ],
        "spacing": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "linear",
              "cosine",
              "sine"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "steps",
        "start_at_sigma",
        "end_at_sigma",
        "spacing"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ExtendIntermediateSigmas",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplingPercentToSigma": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "sampling_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.0001
          }
        ],
        "return_actual_sigma": [
          "BOOLEAN",
          {
            "tooltip": "Return the actual sigma value instead of the value used for interval checks.\nThis only affects results at 0.0 and 1.0.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "sampling_percent",
        "return_actual_sigma"
      ]
    },
    "output": [
      "FLOAT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "sigma_value"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplingPercentToSigma",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CFGGuider": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "positive",
        "negative",
        "cfg"
      ]
    },
    "output": [
      "GUIDER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GUIDER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CFGGuider",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/guiders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "DualCFGGuider": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "cond1": [
          "CONDITIONING",
          {}
        ],
        "cond2": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "cfg_conds": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "cfg_cond2_negative": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "style": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "regular",
              "nested"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "cond1",
        "cond2",
        "negative",
        "cfg_conds",
        "cfg_cond2_negative",
        "style"
      ]
    },
    "output": [
      "GUIDER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GUIDER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "DualCFGGuider",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/guiders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "BasicGuider": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "conditioning": [
          "CONDITIONING",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "conditioning"
      ]
    },
    "output": [
      "GUIDER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GUIDER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "BasicGuider",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/guiders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RandomNoise": {
    "input": {
      "required": {
        "noise_seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "noise_seed"
      ]
    },
    "output": [
      "NOISE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "NOISE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RandomNoise",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/noise",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "DisableNoise": {
    "input": {
      "required": {}
    },
    "input_order": {
      "required": []
    },
    "output": [
      "NOISE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "NOISE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "DisableNoise",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling/noise",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AddNoise": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "noise": [
          "NOISE",
          {}
        ],
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "latent_image": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "noise",
        "sigmas",
        "latent_image"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AddNoise",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "_for_testing/custom_sampling/noise",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SamplerCustomAdvanced": {
    "input": {
      "required": {
        "noise": [
          "NOISE",
          {}
        ],
        "guider": [
          "GUIDER",
          {}
        ],
        "sampler": [
          "SAMPLER",
          {}
        ],
        "sigmas": [
          "SIGMAS",
          {}
        ],
        "latent_image": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "noise",
        "guider",
        "sampler",
        "sigmas",
        "latent_image"
      ]
    },
    "output": [
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "output",
      "denoised_output"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerCustomAdvanced",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_custom_sampler",
    "category": "sampling/custom_sampling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HyperTile": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "tile_size": [
          "INT",
          {
            "default": 256,
            "min": 1,
            "max": 2048
          }
        ],
        "swap_size": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 128
          }
        ],
        "max_depth": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10
          }
        ],
        "scale_depth": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "tile_size",
        "swap_size",
        "max_depth",
        "scale_depth"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "HyperTile",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hypertile",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ModelSamplingDiscrete": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "sampling": [
          [
            "eps",
            "v_prediction",
            "lcm",
            "x0",
            "img_to_img"
          ]
        ],
        "zsnr": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "sampling",
        "zsnr"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingDiscrete",
    "display_name": "ModelSamplingDiscrete",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingContinuousEDM": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "sampling": [
          [
            "v_prediction",
            "edm",
            "edm_playground_v2.5",
            "eps",
            "cosmos_rflow"
          ]
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 120.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.001,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.002,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.001,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "sampling",
        "sigma_max",
        "sigma_min"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingContinuousEDM",
    "display_name": "ModelSamplingContinuousEDM",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingContinuousV": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "sampling": [
          [
            "v_prediction"
          ]
        ],
        "sigma_max": [
          "FLOAT",
          {
            "default": 500.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.001,
            "round": false
          }
        ],
        "sigma_min": [
          "FLOAT",
          {
            "default": 0.03,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.001,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "sampling",
        "sigma_max",
        "sigma_min"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingContinuousV",
    "display_name": "ModelSamplingContinuousV",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingStableCascade": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "shift": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "shift"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingStableCascade",
    "display_name": "ModelSamplingStableCascade",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingSD3": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "shift": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "shift"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingSD3",
    "display_name": "ModelSamplingSD3",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingAuraFlow": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "shift": [
          "FLOAT",
          {
            "default": 1.73,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "shift"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingAuraFlow",
    "display_name": "ModelSamplingAuraFlow",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelSamplingFlux": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "max_shift": [
          "FLOAT",
          {
            "default": 1.15,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "base_shift": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "max_shift",
        "base_shift",
        "width",
        "height"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelSamplingFlux",
    "display_name": "ModelSamplingFlux",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "RescaleCFG": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "multiplier": [
          "FLOAT",
          {
            "default": 0.7,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "multiplier"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "RescaleCFG",
    "display_name": "RescaleCFG",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/model",
    "output_node": false
  },
  "ModelComputeDtype": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "dtype": [
          [
            "default",
            "fp32",
            "fp16",
            "bf16"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "dtype"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelComputeDtype",
    "display_name": "ModelComputeDtype",
    "description": "",
    "python_module": "comfy_extras.nodes_model_advanced",
    "category": "advanced/debug/model",
    "output_node": false
  },
  "PatchModelAddDownscale": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "block_number": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 32,
            "step": 1
          }
        ],
        "downscale_factor": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.1,
            "max": 9.0,
            "step": 0.001
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 0.35,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "downscale_after_skip": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "downscale_method": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "bicubic",
              "nearest-exact",
              "bilinear",
              "area",
              "bislerp"
            ]
          }
        ],
        "upscale_method": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "bicubic",
              "nearest-exact",
              "bilinear",
              "area",
              "bislerp"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "block_number",
        "downscale_factor",
        "start_percent",
        "end_percent",
        "downscale_after_skip",
        "downscale_method",
        "upscale_method"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PatchModelAddDownscale",
    "display_name": "PatchModelAddDownscale (Kohya Deep Shrink)",
    "description": "",
    "python_module": "comfy_extras.nodes_model_downscale",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageCrop": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "width",
        "height",
        "x",
        "y"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageCrop",
    "display_name": "Image Crop",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/transform",
    "output_node": false
  },
  "RepeatImageBatch": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "amount": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "amount"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "RepeatImageBatch",
    "display_name": "RepeatImageBatch",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/batch",
    "output_node": false
  },
  "ImageFromBatch": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "batch_index": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4095
          }
        ],
        "length": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "batch_index",
        "length"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageFromBatch",
    "display_name": "ImageFromBatch",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/batch",
    "output_node": false
  },
  "ImageAddNoise": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true,
            "tooltip": "The random seed used for creating the noise."
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "seed",
        "strength"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageAddNoise",
    "display_name": "ImageAddNoise",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image",
    "output_node": false
  },
  "SaveAnimatedWEBP": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI"
          }
        ],
        "fps": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.01,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "lossless": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "quality": [
          "INT",
          {
            "default": 80,
            "min": 0,
            "max": 100
          }
        ],
        "method": [
          [
            "default",
            "fastest",
            "slowest"
          ]
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "images",
        "filename_prefix",
        "fps",
        "lossless",
        "quality",
        "method"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveAnimatedWEBP",
    "display_name": "SaveAnimatedWEBP",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/animation",
    "output_node": true
  },
  "SaveAnimatedPNG": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI"
          }
        ],
        "fps": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.01,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "compress_level": [
          "INT",
          {
            "default": 4,
            "min": 0,
            "max": 9
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "images",
        "filename_prefix",
        "fps",
        "compress_level"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveAnimatedPNG",
    "display_name": "SaveAnimatedPNG",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/animation",
    "output_node": true
  },
  "SaveSVGNode": {
    "input": {
      "required": {
        "svg": [
          "SVG"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "svg/ComfyUI",
            "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "svg",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveSVGNode",
    "display_name": "SaveSVGNode",
    "description": "Save SVG files on disk.",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/save",
    "output_node": true
  },
  "ImageStitch": {
    "input": {
      "required": {
        "image1": [
          "IMAGE"
        ],
        "direction": [
          [
            "right",
            "down",
            "left",
            "up"
          ],
          {
            "default": "right"
          }
        ],
        "match_image_size": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "spacing_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 1024,
            "step": 2
          }
        ],
        "spacing_color": [
          [
            "white",
            "black",
            "red",
            "green",
            "blue"
          ],
          {
            "default": "white"
          }
        ]
      },
      "optional": {
        "image2": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image1",
        "direction",
        "match_image_size",
        "spacing_width",
        "spacing_color"
      ],
      "optional": [
        "image2"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageStitch",
    "display_name": "Image Stitch",
    "description": "\nStitches image2 to image1 in the specified direction.\nIf image2 is not provided, returns image1 unchanged.\nOptional spacing can be added between images.\n",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/transform",
    "output_node": false
  },
  "ResizeAndPadImage": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "target_width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "target_height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "padding_color": [
          [
            "white",
            "black"
          ]
        ],
        "interpolation": [
          [
            "area",
            "bicubic",
            "nearest-exact",
            "bilinear",
            "lanczos"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "target_width",
        "target_height",
        "padding_color",
        "interpolation"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ResizeAndPadImage",
    "display_name": "ResizeAndPadImage",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/transform",
    "output_node": false
  },
  "GetImageSize": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "unique_id"
      ]
    },
    "output": [
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "width",
      "height",
      "batch_size"
    ],
    "name": "GetImageSize",
    "display_name": "Get Image Size",
    "description": "Returns width and height of the image, and passes it through unchanged.",
    "python_module": "comfy_extras.nodes_images",
    "category": "image",
    "output_node": false
  },
  "ImageRotate": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "rotation": [
          [
            "none",
            "90 degrees",
            "180 degrees",
            "270 degrees"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "rotation"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageRotate",
    "display_name": "ImageRotate",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/transform",
    "output_node": false
  },
  "ImageFlip": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "flip_method": [
          [
            "x-axis: vertically",
            "y-axis: horizontally"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "flip_method"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageFlip",
    "display_name": "ImageFlip",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/transform",
    "output_node": false
  },
  "ImageScaleToMaxDimension": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "upscale_method": [
          [
            "area",
            "lanczos",
            "bilinear",
            "nearest-exact",
            "bilinear",
            "bicubic"
          ]
        ],
        "largest_size": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "upscale_method",
        "largest_size"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageScaleToMaxDimension",
    "display_name": "ImageScaleToMaxDimension",
    "description": "",
    "python_module": "comfy_extras.nodes_images",
    "category": "image/upscaling",
    "output_node": false
  },
  "ImageOnlyCheckpointLoader": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP_VISION",
      "VAE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP_VISION",
      "VAE"
    ],
    "name": "ImageOnlyCheckpointLoader",
    "display_name": "Image Only Checkpoint Loader (img2vid model)",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "loaders/video_models",
    "output_node": false
  },
  "SVD_img2vid_Conditioning": {
    "input": {
      "required": {
        "clip_vision": [
          "CLIP_VISION"
        ],
        "init_image": [
          "IMAGE"
        ],
        "vae": [
          "VAE"
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 576,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "video_frames": [
          "INT",
          {
            "default": 14,
            "min": 1,
            "max": 4096
          }
        ],
        "motion_bucket_id": [
          "INT",
          {
            "default": 127,
            "min": 1,
            "max": 1023
          }
        ],
        "fps": [
          "INT",
          {
            "default": 6,
            "min": 1,
            "max": 1024
          }
        ],
        "augmentation_level": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "video_frames",
        "motion_bucket_id",
        "fps",
        "augmentation_level"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "name": "SVD_img2vid_Conditioning",
    "display_name": "SVD_img2vid_Conditioning",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "conditioning/video_models",
    "output_node": false
  },
  "VideoLinearCFGGuidance": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "min_cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.5,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "min_cfg"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "VideoLinearCFGGuidance",
    "display_name": "VideoLinearCFGGuidance",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "sampling/video_models",
    "output_node": false
  },
  "VideoTriangleCFGGuidance": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "min_cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.5,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "min_cfg"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "VideoTriangleCFGGuidance",
    "display_name": "VideoTriangleCFGGuidance",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "sampling/video_models",
    "output_node": false
  },
  "ImageOnlyCheckpointSave": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ],
        "vae": [
          "VAE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "checkpoints/ComfyUI"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip_vision",
        "vae",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "ImageOnlyCheckpointSave",
    "display_name": "ImageOnlyCheckpointSave",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "advanced/model_merging",
    "output_node": true
  },
  "ConditioningSetAreaPercentageVideo": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "width": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "height": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "temporal": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "y": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "z": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "width",
        "height",
        "temporal",
        "x",
        "y",
        "z",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetAreaPercentageVideo",
    "display_name": "ConditioningSetAreaPercentageVideo",
    "description": "",
    "python_module": "comfy_extras.nodes_video_model",
    "category": "conditioning",
    "output_node": false
  },
  "TrainLoraNode": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model to train the LoRA on."
          }
        ],
        "latents": [
          "LATENT",
          {
            "tooltip": "The Latents to use for training, serve as dataset/input of the model."
          }
        ],
        "positive": [
          "CONDITIONING",
          {
            "tooltip": "The positive conditioning to use for training."
          }
        ],
        "batch_size": [
          "INT",
          {
            "tooltip": "The batch size to use for training.",
            "default": 1,
            "min": 1,
            "max": 10000
          }
        ],
        "grad_accumulation_steps": [
          "INT",
          {
            "tooltip": "The number of gradient accumulation steps to use for training.",
            "default": 1,
            "min": 1,
            "max": 1024
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "The number of steps to train the LoRA for.",
            "default": 16,
            "min": 1,
            "max": 100000
          }
        ],
        "learning_rate": [
          "FLOAT",
          {
            "tooltip": "The learning rate to use for training.",
            "default": 0.0005,
            "min": 1e-07,
            "max": 1.0,
            "step": 1e-07
          }
        ],
        "rank": [
          "INT",
          {
            "tooltip": "The rank of the LoRA layers.",
            "default": 8,
            "min": 1,
            "max": 128
          }
        ],
        "optimizer": [
          "COMBO",
          {
            "tooltip": "The optimizer to use for training.",
            "default": "AdamW",
            "multiselect": false,
            "options": [
              "AdamW",
              "Adam",
              "SGD",
              "RMSprop"
            ]
          }
        ],
        "loss_function": [
          "COMBO",
          {
            "tooltip": "The loss function to use for training.",
            "default": "MSE",
            "multiselect": false,
            "options": [
              "MSE",
              "L1",
              "Huber",
              "SmoothL1"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The seed to use for training (used in generator for LoRA weight initialization and noise sampling)",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "training_dtype": [
          "COMBO",
          {
            "tooltip": "The dtype to use for training.",
            "default": "bf16",
            "multiselect": false,
            "options": [
              "bf16",
              "fp32"
            ]
          }
        ],
        "lora_dtype": [
          "COMBO",
          {
            "tooltip": "The dtype to use for lora.",
            "default": "bf16",
            "multiselect": false,
            "options": [
              "bf16",
              "fp32"
            ]
          }
        ],
        "algorithm": [
          "COMBO",
          {
            "tooltip": "The algorithm to use for training.",
            "default": "LoRA",
            "multiselect": false,
            "options": [
              "LoRA",
              "LoHa",
              "LoKr",
              "OFT"
            ]
          }
        ],
        "gradient_checkpointing": [
          "BOOLEAN",
          {
            "tooltip": "Use gradient checkpointing for training.",
            "default": true
          }
        ],
        "existing_lora": [
          "COMBO",
          {
            "tooltip": "The existing LoRA to append to. Set to None for new LoRA.",
            "default": "[None]",
            "multiselect": false,
            "options": [
              "[None]"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "latents",
        "positive",
        "batch_size",
        "grad_accumulation_steps",
        "steps",
        "learning_rate",
        "rank",
        "optimizer",
        "loss_function",
        "seed",
        "training_dtype",
        "lora_dtype",
        "algorithm",
        "gradient_checkpointing",
        "existing_lora"
      ]
    },
    "output": [
      "MODEL",
      "LORA_MODEL",
      "LOSS_MAP",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "model",
      "lora",
      "loss_map",
      "steps"
    ],
    "output_tooltips": [
      "Model with LoRA applied",
      "LoRA weights",
      "Loss history",
      "Total training steps"
    ],
    "output_matchtypes": null,
    "name": "TrainLoraNode",
    "display_name": "Train LoRA",
    "description": "",
    "python_module": "comfy_extras.nodes_train",
    "category": "training",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LoraModelLoader": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The diffusion model the LoRA will be applied to."
          }
        ],
        "lora": [
          "LORA_MODEL",
          {
            "tooltip": "The LoRA model to apply to the diffusion model."
          }
        ],
        "strength_model": [
          "FLOAT",
          {
            "tooltip": "How strongly to modify the diffusion model. This value can be negative.",
            "default": 1.0,
            "min": -100.0,
            "max": 100.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "lora",
        "strength_model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "model"
    ],
    "output_tooltips": [
      "The modified diffusion model."
    ],
    "output_matchtypes": null,
    "name": "LoraModelLoader",
    "display_name": "Load LoRA Model",
    "description": "",
    "python_module": "comfy_extras.nodes_train",
    "category": "loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SaveLoRA": {
    "input": {
      "required": {
        "lora": [
          "LORA_MODEL",
          {
            "tooltip": "The LoRA model to save. Do not use the model with LoRA layers."
          }
        ],
        "prefix": [
          "STRING",
          {
            "tooltip": "The prefix to use for the saved LoRA file.",
            "default": "loras/ComfyUI_trained_lora",
            "multiline": false
          }
        ]
      },
      "optional": {
        "steps": [
          "INT",
          {
            "tooltip": "Optional: The number of steps to LoRA has been trained for, used to name the saved file."
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "lora",
        "prefix"
      ],
      "optional": [
        "steps"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveLoRA",
    "display_name": "Save LoRA Weights",
    "description": "",
    "python_module": "comfy_extras.nodes_train",
    "category": "loaders",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LossGraphNode": {
    "input": {
      "required": {
        "loss": [
          "LOSS_MAP",
          {
            "tooltip": "Loss map from training node."
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "tooltip": "Prefix for the saved loss graph image.",
            "default": "loss_graph",
            "multiline": false
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "loss",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "LossGraphNode",
    "display_name": "Plot Loss Graph",
    "description": "",
    "python_module": "comfy_extras.nodes_train",
    "category": "training",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LoadImageDataSetFromFolder": {
    "input": {
      "required": {
        "folder": [
          "COMBO",
          {
            "tooltip": "The folder to load images from.",
            "multiselect": false,
            "options": [
              "3d"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "folder"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "List of loaded images"
    ],
    "output_matchtypes": null,
    "name": "LoadImageDataSetFromFolder",
    "display_name": "Load Image Dataset from Folder",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LoadImageTextDataSetFromFolder": {
    "input": {
      "required": {
        "folder": [
          "COMBO",
          {
            "tooltip": "The folder to load images from.",
            "multiselect": false,
            "options": [
              "3d"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "folder"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      true,
      true
    ],
    "output_name": [
      "images",
      "texts"
    ],
    "output_tooltips": [
      "List of loaded images",
      "List of text captions"
    ],
    "output_matchtypes": null,
    "name": "LoadImageTextDataSetFromFolder",
    "display_name": "Load Image and Text Dataset from Folder",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SaveImageDataSetToFolder": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to save."
          }
        ],
        "folder_name": [
          "STRING",
          {
            "tooltip": "Name of the folder to save images to (inside output directory).",
            "default": "dataset",
            "multiline": false
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "tooltip": "Prefix for saved image filenames.",
            "default": "image",
            "multiline": false
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "folder_name",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveImageDataSetToFolder",
    "display_name": "Save Image Dataset to Folder",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SaveImageTextDataSetToFolder": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to save."
          }
        ],
        "texts": [
          "STRING",
          {
            "tooltip": "List of text captions to save.",
            "multiline": false
          }
        ],
        "folder_name": [
          "STRING",
          {
            "tooltip": "Name of the folder to save images to (inside output directory).",
            "default": "dataset",
            "multiline": false
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "tooltip": "Prefix for saved image filenames.",
            "default": "image",
            "multiline": false
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "texts",
        "folder_name",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveImageTextDataSetToFolder",
    "display_name": "Save Image and Text Dataset to Folder",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ResizeImagesByShorterEdge": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "shorter_edge": [
          "INT",
          {
            "tooltip": "Target length for the shorter edge.",
            "default": 512,
            "min": 1,
            "max": 8192
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "shorter_edge"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "ResizeImagesByShorterEdge",
    "display_name": "Resize Images by Shorter Edge",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ResizeImagesByLongerEdge": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "longer_edge": [
          "INT",
          {
            "tooltip": "Target length for the longer edge.",
            "default": 1024,
            "min": 1,
            "max": 8192
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "longer_edge"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "ResizeImagesByLongerEdge",
    "display_name": "Resize Images by Longer Edge",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "CenterCropImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "width": [
          "INT",
          {
            "tooltip": "Crop width.",
            "default": 512,
            "min": 1,
            "max": 8192
          }
        ],
        "height": [
          "INT",
          {
            "tooltip": "Crop height.",
            "default": 512,
            "min": 1,
            "max": 8192
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "width",
        "height"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "CenterCropImages",
    "display_name": "Center Crop Images",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "RandomCropImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "width": [
          "INT",
          {
            "tooltip": "Crop width.",
            "default": 512,
            "min": 1,
            "max": 8192
          }
        ],
        "height": [
          "INT",
          {
            "tooltip": "Crop height.",
            "default": 512,
            "min": 1,
            "max": 8192
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "width",
        "height",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "RandomCropImages",
    "display_name": "Random Crop Images",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "NormalizeImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "mean": [
          "FLOAT",
          {
            "tooltip": "Mean value for normalization.",
            "default": 0.5,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "std": [
          "FLOAT",
          {
            "tooltip": "Standard deviation for normalization.",
            "default": 0.5,
            "min": 0.001,
            "max": 1.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "mean",
        "std"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "NormalizeImages",
    "display_name": "Normalize Images",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "AdjustBrightness": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "factor": [
          "FLOAT",
          {
            "tooltip": "Brightness factor. 1.0 = no change, <1.0 = darker, >1.0 = brighter.",
            "default": 1.0,
            "min": 0.0,
            "max": 2.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "factor"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "AdjustBrightness",
    "display_name": "Adjust Brightness",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "AdjustContrast": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Image to process."
          }
        ],
        "factor": [
          "FLOAT",
          {
            "tooltip": "Contrast factor. 1.0 = no change, <1.0 = less contrast, >1.0 = more contrast.",
            "default": 1.0,
            "min": 0.0,
            "max": 2.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "factor"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "AdjustContrast",
    "display_name": "Adjust Contrast",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ShuffleDataset": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to process."
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "ShuffleDataset",
    "display_name": "Shuffle Image Dataset",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ShuffleImageTextDataset": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to shuffle."
          }
        ],
        "texts": [
          "STRING",
          {
            "tooltip": "List of texts to shuffle.",
            "multiline": false
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "texts",
        "seed"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      true,
      true
    ],
    "output_name": [
      "images",
      "texts"
    ],
    "output_tooltips": [
      "Shuffled images",
      "Shuffled texts"
    ],
    "output_matchtypes": null,
    "name": "ShuffleImageTextDataset",
    "display_name": "Shuffle Image-Text Dataset",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "TextToLowercase": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "TextToLowercase",
    "display_name": "Text to Lowercase",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "TextToUppercase": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "TextToUppercase",
    "display_name": "Text to Uppercase",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "TruncateText": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ],
        "max_length": [
          "INT",
          {
            "tooltip": "Maximum text length.",
            "default": 77,
            "min": 1,
            "max": 10000
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts",
        "max_length"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "TruncateText",
    "display_name": "Truncate Text",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "AddTextPrefix": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ],
        "prefix": [
          "STRING",
          {
            "tooltip": "Prefix to add.",
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts",
        "prefix"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "AddTextPrefix",
    "display_name": "Add Text Prefix",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "AddTextSuffix": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ],
        "suffix": [
          "STRING",
          {
            "tooltip": "Suffix to add.",
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts",
        "suffix"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "AddTextSuffix",
    "display_name": "Add Text Suffix",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ReplaceText": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ],
        "find": [
          "STRING",
          {
            "tooltip": "Text to find.",
            "default": "",
            "multiline": false
          }
        ],
        "replace": [
          "STRING",
          {
            "tooltip": "Text to replace with.",
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts",
        "find",
        "replace"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "ReplaceText",
    "display_name": "Replace Text",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "StripWhitespace": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "Text to process.",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "StripWhitespace",
    "display_name": "Strip Whitespace",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ImageDeduplication": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to process."
          }
        ],
        "similarity_threshold": [
          "FLOAT",
          {
            "tooltip": "Similarity threshold (0-1). Higher means more similar. Images above this threshold are considered duplicates.",
            "default": 0.95,
            "min": 0.0,
            "max": 1.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "similarity_threshold"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "ImageDeduplication",
    "display_name": "Image Deduplication",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "ImageGrid": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to process."
          }
        ],
        "columns": [
          "INT",
          {
            "tooltip": "Number of columns in the grid.",
            "default": 4,
            "min": 1,
            "max": 20
          }
        ],
        "cell_width": [
          "INT",
          {
            "tooltip": "Width of each cell in the grid.",
            "default": 256,
            "min": 32,
            "max": 2048
          }
        ],
        "cell_height": [
          "INT",
          {
            "tooltip": "Height of each cell in the grid.",
            "default": 256,
            "min": 32,
            "max": 2048
          }
        ],
        "padding": [
          "INT",
          {
            "tooltip": "Padding between images.",
            "default": 4,
            "min": 0,
            "max": 50
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "columns",
        "cell_width",
        "cell_height",
        "padding"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "ImageGrid",
    "display_name": "Image Grid",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "MergeImageLists": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to process."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "images"
    ],
    "output_tooltips": [
      "Processed images"
    ],
    "output_matchtypes": null,
    "name": "MergeImageLists",
    "display_name": "Merge Image Lists",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/image",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "MergeTextLists": {
    "input": {
      "required": {
        "texts": [
          "STRING",
          {
            "tooltip": "List of texts to process.",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "texts"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      null
    ],
    "output_name": [
      "texts"
    ],
    "output_tooltips": [
      "Processed texts"
    ],
    "output_matchtypes": null,
    "name": "MergeTextLists",
    "display_name": "Merge Text Lists",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset/text",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "MakeTrainingDataset": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "List of images to encode."
          }
        ],
        "vae": [
          "VAE",
          {
            "tooltip": "VAE model for encoding images to latents."
          }
        ],
        "clip": [
          "CLIP",
          {
            "tooltip": "CLIP model for encoding text to conditioning."
          }
        ]
      },
      "optional": {
        "texts": [
          "STRING",
          {
            "tooltip": "List of text captions. Can be length n (matching images), 1 (repeated for all), or omitted (uses empty string).",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "vae",
        "clip"
      ],
      "optional": [
        "texts"
      ]
    },
    "output": [
      "LATENT",
      "CONDITIONING"
    ],
    "output_is_list": [
      true,
      true
    ],
    "output_name": [
      "latents",
      "conditioning"
    ],
    "output_tooltips": [
      "List of latent dicts",
      "List of conditioning lists"
    ],
    "output_matchtypes": null,
    "name": "MakeTrainingDataset",
    "display_name": "Make Training Dataset",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SaveTrainingDataset": {
    "input": {
      "required": {
        "latents": [
          "LATENT",
          {
            "tooltip": "List of latent dicts from MakeTrainingDataset."
          }
        ],
        "conditioning": [
          "CONDITIONING",
          {
            "tooltip": "List of conditioning lists from MakeTrainingDataset."
          }
        ],
        "folder_name": [
          "STRING",
          {
            "tooltip": "Name of folder to save dataset (inside output directory).",
            "default": "training_dataset",
            "multiline": false
          }
        ],
        "shard_size": [
          "INT",
          {
            "tooltip": "Number of samples per shard file.",
            "default": 1000,
            "min": 1,
            "max": 100000
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "latents",
        "conditioning",
        "folder_name",
        "shard_size"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveTrainingDataset",
    "display_name": "Save Training Dataset",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LoadTrainingDataset": {
    "input": {
      "required": {
        "folder_name": [
          "STRING",
          {
            "tooltip": "Name of folder containing the saved dataset (inside output directory).",
            "default": "training_dataset",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "folder_name"
      ]
    },
    "output": [
      "LATENT",
      "CONDITIONING"
    ],
    "output_is_list": [
      true,
      true
    ],
    "output_name": [
      "latents",
      "conditioning"
    ],
    "output_tooltips": [
      "List of latent dicts",
      "List of conditioning lists"
    ],
    "output_matchtypes": null,
    "name": "LoadTrainingDataset",
    "display_name": "Load Training Dataset",
    "description": "",
    "python_module": "comfy_extras.nodes_dataset",
    "category": "dataset",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SelfAttentionGuidance": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scale": [
          "FLOAT",
          {
            "default": 0.5,
            "min": -2.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "blur_sigma": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scale",
        "blur_sigma"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SelfAttentionGuidance",
    "display_name": "Self-Attention Guidance",
    "description": "",
    "python_module": "comfy_extras.nodes_sag",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "PerpNeg": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "empty_conditioning": [
          "CONDITIONING",
          {}
        ],
        "neg_scale": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "empty_conditioning",
        "neg_scale"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PerpNeg",
    "display_name": "Perp-Neg (DEPRECATED by PerpNegGuider)",
    "description": "",
    "python_module": "comfy_extras.nodes_perpneg",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": true,
    "experimental": true,
    "api_node": false
  },
  "PerpNegGuider": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "empty_conditioning": [
          "CONDITIONING",
          {}
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "neg_scale": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "positive",
        "negative",
        "empty_conditioning",
        "cfg",
        "neg_scale"
      ]
    },
    "output": [
      "GUIDER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GUIDER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PerpNegGuider",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_perpneg",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "StableZero123_Conditioning": {
    "input": {
      "required": {
        "clip_vision": [
          "CLIP_VISION",
          {}
        ],
        "init_image": [
          "IMAGE",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 256,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 256,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "elevation": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ],
        "azimuth": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "elevation",
        "azimuth"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "StableZero123_Conditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable3d",
    "category": "conditioning/3d_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StableZero123_Conditioning_Batched": {
    "input": {
      "required": {
        "clip_vision": [
          "CLIP_VISION",
          {}
        ],
        "init_image": [
          "IMAGE",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 256,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 256,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "elevation": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ],
        "azimuth": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ],
        "elevation_batch_increment": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ],
        "azimuth_batch_increment": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -180.0,
            "max": 180.0,
            "step": 0.1,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "batch_size",
        "elevation",
        "azimuth",
        "elevation_batch_increment",
        "azimuth_batch_increment"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "StableZero123_Conditioning_Batched",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable3d",
    "category": "conditioning/3d_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SV3D_Conditioning": {
    "input": {
      "required": {
        "clip_vision": [
          "CLIP_VISION",
          {}
        ],
        "init_image": [
          "IMAGE",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 576,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 576,
            "min": 16,
            "max": 16384,
            "step": 8
          }
        ],
        "video_frames": [
          "INT",
          {
            "default": 21,
            "min": 1,
            "max": 4096
          }
        ],
        "elevation": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -90.0,
            "max": 90.0,
            "step": 0.1,
            "round": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision",
        "init_image",
        "vae",
        "width",
        "height",
        "video_frames",
        "elevation"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SV3D_Conditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable3d",
    "category": "conditioning/3d_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SD_4XUpscale_Conditioning": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {}
        ],
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "scale_ratio": [
          "FLOAT",
          {
            "default": 4.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "noise_augmentation": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "positive",
        "negative",
        "scale_ratio",
        "noise_augmentation"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SD_4XUpscale_Conditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_sdupscale",
    "category": "conditioning/upscale_diffusion",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PhotoMakerLoader": {
    "input": {
      "required": {
        "photomaker_model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "photomaker_model_name"
      ]
    },
    "output": [
      "PHOTOMAKER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "PHOTOMAKER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PhotoMakerLoader",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_photomaker",
    "category": "_for_testing/photomaker",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "PhotoMakerEncode": {
    "input": {
      "required": {
        "photomaker": [
          "PHOTOMAKER",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ],
        "clip": [
          "CLIP",
          {}
        ],
        "text": [
          "STRING",
          {
            "default": "photograph of photomaker",
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "photomaker",
        "image",
        "clip",
        "text"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PhotoMakerEncode",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_photomaker",
    "category": "_for_testing/photomaker",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "CLIPTextEncodePixArtAlpha": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 0,
            "max": 16384
          }
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "clip": [
          "CLIP",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "text",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodePixArtAlpha",
    "display_name": null,
    "description": "Encodes text and sets the resolution conditioning for PixArt Alpha. Does not apply to PixArt Sigma.",
    "python_module": "comfy_extras.nodes_pixart",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeControlnet": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "conditioning": [
          "CONDITIONING",
          {}
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "conditioning",
        "text"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeControlnet",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cond",
    "category": "_for_testing/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "T5TokenizerOptions": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "min_padding": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10000,
            "step": 1
          }
        ],
        "min_length": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10000,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "min_padding",
        "min_length"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "T5TokenizerOptions",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cond",
    "category": "_for_testing/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "Morphology": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "operation": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "erode",
              "dilate",
              "open",
              "close",
              "gradient",
              "bottom_hat",
              "top_hat"
            ]
          }
        ],
        "kernel_size": [
          "INT",
          {
            "default": 3,
            "min": 3,
            "max": 999,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "operation",
        "kernel_size"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Morphology",
    "display_name": "ImageMorphology",
    "description": "",
    "python_module": "comfy_extras.nodes_morphology",
    "category": "image/postprocessing",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageRGBToYUV": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "Y",
      "U",
      "V"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "ImageRGBToYUV",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_morphology",
    "category": "image/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ImageYUVToRGB": {
    "input": {
      "required": {
        "Y": [
          "IMAGE",
          {}
        ],
        "U": [
          "IMAGE",
          {}
        ],
        "V": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "Y",
        "U",
        "V"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ImageYUVToRGB",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_morphology",
    "category": "image/batch",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StableCascade_EmptyLatentImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 256,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 256,
            "max": 16384,
            "step": 8
          }
        ],
        "compression": [
          "INT",
          {
            "default": 42,
            "min": 4,
            "max": 128,
            "step": 1
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "compression",
        "batch_size"
      ]
    },
    "output": [
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "stage_c",
      "stage_b"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "StableCascade_EmptyLatentImage",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable_cascade",
    "category": "latent/stable_cascade",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StableCascade_StageB_Conditioning": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING",
          {}
        ],
        "stage_c": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "stage_c"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StableCascade_StageB_Conditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable_cascade",
    "category": "conditioning/stable_cascade",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StableCascade_StageC_VAEEncode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "compression": [
          "INT",
          {
            "default": 42,
            "min": 4,
            "max": 128,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "vae",
        "compression"
      ]
    },
    "output": [
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "stage_c",
      "stage_b"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "StableCascade_StageC_VAEEncode",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable_cascade",
    "category": "latent/stable_cascade",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StableCascade_SuperResolutionControlnet": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "vae"
      ]
    },
    "output": [
      "IMAGE",
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "controlnet_input",
      "stage_c",
      "stage_b"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "StableCascade_SuperResolutionControlnet",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_stable_cascade",
    "category": "_for_testing/stable_cascade",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "DifferentialDiffusion": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ]
      },
      "optional": {
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ],
      "optional": [
        "strength"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "DifferentialDiffusion",
    "display_name": "Differential Diffusion",
    "description": "",
    "python_module": "comfy_extras.nodes_differential_diffusion",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "InstructPixToPixConditioning": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "pixels": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "pixels"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "InstructPixToPixConditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_ip2p",
    "category": "conditioning/instructpix2pix",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ModelMergeSD1": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "time_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "label_emb.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "out.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0.",
        "input_blocks.1.",
        "input_blocks.2.",
        "input_blocks.3.",
        "input_blocks.4.",
        "input_blocks.5.",
        "input_blocks.6.",
        "input_blocks.7.",
        "input_blocks.8.",
        "input_blocks.9.",
        "input_blocks.10.",
        "input_blocks.11.",
        "middle_block.0.",
        "middle_block.1.",
        "middle_block.2.",
        "output_blocks.0.",
        "output_blocks.1.",
        "output_blocks.2.",
        "output_blocks.3.",
        "output_blocks.4.",
        "output_blocks.5.",
        "output_blocks.6.",
        "output_blocks.7.",
        "output_blocks.8.",
        "output_blocks.9.",
        "output_blocks.10.",
        "output_blocks.11.",
        "out."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSD1",
    "display_name": "ModelMergeSD1",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeSD2": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "time_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "label_emb.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "out.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0.",
        "input_blocks.1.",
        "input_blocks.2.",
        "input_blocks.3.",
        "input_blocks.4.",
        "input_blocks.5.",
        "input_blocks.6.",
        "input_blocks.7.",
        "input_blocks.8.",
        "input_blocks.9.",
        "input_blocks.10.",
        "input_blocks.11.",
        "middle_block.0.",
        "middle_block.1.",
        "middle_block.2.",
        "output_blocks.0.",
        "output_blocks.1.",
        "output_blocks.2.",
        "output_blocks.3.",
        "output_blocks.4.",
        "output_blocks.5.",
        "output_blocks.6.",
        "output_blocks.7.",
        "output_blocks.8.",
        "output_blocks.9.",
        "output_blocks.10.",
        "output_blocks.11.",
        "out."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSD2",
    "display_name": "ModelMergeSD2",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeSDXL": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "time_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "label_emb.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.0": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.1": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.3": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.4": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.5": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.6": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.7": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "input_blocks.8": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.0": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.1": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "middle_block.2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.0": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.1": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.3": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.4": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.5": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.6": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.7": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "output_blocks.8": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "out.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "time_embed.",
        "label_emb.",
        "input_blocks.0",
        "input_blocks.1",
        "input_blocks.2",
        "input_blocks.3",
        "input_blocks.4",
        "input_blocks.5",
        "input_blocks.6",
        "input_blocks.7",
        "input_blocks.8",
        "middle_block.0",
        "middle_block.1",
        "middle_block.2",
        "output_blocks.0",
        "output_blocks.1",
        "output_blocks.2",
        "output_blocks.3",
        "output_blocks.4",
        "output_blocks.5",
        "output_blocks.6",
        "output_blocks.7",
        "output_blocks.8",
        "out."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSDXL",
    "display_name": "ModelMergeSDXL",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeSD3_2B": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "context_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "y_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embed.",
        "x_embedder.",
        "context_embedder.",
        "y_embedder.",
        "t_embedder.",
        "joint_blocks.0.",
        "joint_blocks.1.",
        "joint_blocks.2.",
        "joint_blocks.3.",
        "joint_blocks.4.",
        "joint_blocks.5.",
        "joint_blocks.6.",
        "joint_blocks.7.",
        "joint_blocks.8.",
        "joint_blocks.9.",
        "joint_blocks.10.",
        "joint_blocks.11.",
        "joint_blocks.12.",
        "joint_blocks.13.",
        "joint_blocks.14.",
        "joint_blocks.15.",
        "joint_blocks.16.",
        "joint_blocks.17.",
        "joint_blocks.18.",
        "joint_blocks.19.",
        "joint_blocks.20.",
        "joint_blocks.21.",
        "joint_blocks.22.",
        "joint_blocks.23.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSD3_2B",
    "display_name": "ModelMergeSD3_2B",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeAuraflow": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "init_x_linear.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "positional_encoding": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "cond_seq_linear.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "register_tokens": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_layers.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_layers.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_layers.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_layers.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_layers.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "modF.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_linear.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "init_x_linear.",
        "positional_encoding",
        "cond_seq_linear.",
        "register_tokens",
        "t_embedder.",
        "double_layers.0.",
        "double_layers.1.",
        "double_layers.2.",
        "double_layers.3.",
        "single_layers.0.",
        "single_layers.1.",
        "single_layers.2.",
        "single_layers.3.",
        "single_layers.4.",
        "single_layers.5.",
        "single_layers.6.",
        "single_layers.7.",
        "single_layers.8.",
        "single_layers.9.",
        "single_layers.10.",
        "single_layers.11.",
        "single_layers.12.",
        "single_layers.13.",
        "single_layers.14.",
        "single_layers.15.",
        "single_layers.16.",
        "single_layers.17.",
        "single_layers.18.",
        "single_layers.19.",
        "single_layers.20.",
        "single_layers.21.",
        "single_layers.22.",
        "single_layers.23.",
        "single_layers.24.",
        "single_layers.25.",
        "single_layers.26.",
        "single_layers.27.",
        "single_layers.28.",
        "single_layers.29.",
        "single_layers.30.",
        "single_layers.31.",
        "modF.",
        "final_linear."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeAuraflow",
    "display_name": "ModelMergeAuraflow",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeFlux1": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "img_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "time_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "guidance_in": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "vector_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "txt_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "double_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.36.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "single_blocks.37.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "img_in.",
        "time_in.",
        "guidance_in",
        "vector_in.",
        "txt_in.",
        "double_blocks.0.",
        "double_blocks.1.",
        "double_blocks.2.",
        "double_blocks.3.",
        "double_blocks.4.",
        "double_blocks.5.",
        "double_blocks.6.",
        "double_blocks.7.",
        "double_blocks.8.",
        "double_blocks.9.",
        "double_blocks.10.",
        "double_blocks.11.",
        "double_blocks.12.",
        "double_blocks.13.",
        "double_blocks.14.",
        "double_blocks.15.",
        "double_blocks.16.",
        "double_blocks.17.",
        "double_blocks.18.",
        "single_blocks.0.",
        "single_blocks.1.",
        "single_blocks.2.",
        "single_blocks.3.",
        "single_blocks.4.",
        "single_blocks.5.",
        "single_blocks.6.",
        "single_blocks.7.",
        "single_blocks.8.",
        "single_blocks.9.",
        "single_blocks.10.",
        "single_blocks.11.",
        "single_blocks.12.",
        "single_blocks.13.",
        "single_blocks.14.",
        "single_blocks.15.",
        "single_blocks.16.",
        "single_blocks.17.",
        "single_blocks.18.",
        "single_blocks.19.",
        "single_blocks.20.",
        "single_blocks.21.",
        "single_blocks.22.",
        "single_blocks.23.",
        "single_blocks.24.",
        "single_blocks.25.",
        "single_blocks.26.",
        "single_blocks.27.",
        "single_blocks.28.",
        "single_blocks.29.",
        "single_blocks.30.",
        "single_blocks.31.",
        "single_blocks.32.",
        "single_blocks.33.",
        "single_blocks.34.",
        "single_blocks.35.",
        "single_blocks.36.",
        "single_blocks.37.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeFlux1",
    "display_name": "ModelMergeFlux1",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeSD35_Large": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "context_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "y_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.36.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "joint_blocks.37.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embed.",
        "x_embedder.",
        "context_embedder.",
        "y_embedder.",
        "t_embedder.",
        "joint_blocks.0.",
        "joint_blocks.1.",
        "joint_blocks.2.",
        "joint_blocks.3.",
        "joint_blocks.4.",
        "joint_blocks.5.",
        "joint_blocks.6.",
        "joint_blocks.7.",
        "joint_blocks.8.",
        "joint_blocks.9.",
        "joint_blocks.10.",
        "joint_blocks.11.",
        "joint_blocks.12.",
        "joint_blocks.13.",
        "joint_blocks.14.",
        "joint_blocks.15.",
        "joint_blocks.16.",
        "joint_blocks.17.",
        "joint_blocks.18.",
        "joint_blocks.19.",
        "joint_blocks.20.",
        "joint_blocks.21.",
        "joint_blocks.22.",
        "joint_blocks.23.",
        "joint_blocks.24.",
        "joint_blocks.25.",
        "joint_blocks.26.",
        "joint_blocks.27.",
        "joint_blocks.28.",
        "joint_blocks.29.",
        "joint_blocks.30.",
        "joint_blocks.31.",
        "joint_blocks.32.",
        "joint_blocks.33.",
        "joint_blocks.34.",
        "joint_blocks.35.",
        "joint_blocks.36.",
        "joint_blocks.37.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeSD35_Large",
    "display_name": "ModelMergeSD35_Large",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeMochiPreview": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_frequencies.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t5_y_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t5_yproj.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.36.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.37.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.38.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.39.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.40.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.41.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.42.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.43.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.44.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.45.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.46.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.47.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_frequencies.",
        "t_embedder.",
        "t5_y_embedder.",
        "t5_yproj.",
        "blocks.0.",
        "blocks.1.",
        "blocks.2.",
        "blocks.3.",
        "blocks.4.",
        "blocks.5.",
        "blocks.6.",
        "blocks.7.",
        "blocks.8.",
        "blocks.9.",
        "blocks.10.",
        "blocks.11.",
        "blocks.12.",
        "blocks.13.",
        "blocks.14.",
        "blocks.15.",
        "blocks.16.",
        "blocks.17.",
        "blocks.18.",
        "blocks.19.",
        "blocks.20.",
        "blocks.21.",
        "blocks.22.",
        "blocks.23.",
        "blocks.24.",
        "blocks.25.",
        "blocks.26.",
        "blocks.27.",
        "blocks.28.",
        "blocks.29.",
        "blocks.30.",
        "blocks.31.",
        "blocks.32.",
        "blocks.33.",
        "blocks.34.",
        "blocks.35.",
        "blocks.36.",
        "blocks.37.",
        "blocks.38.",
        "blocks.39.",
        "blocks.40.",
        "blocks.41.",
        "blocks.42.",
        "blocks.43.",
        "blocks.44.",
        "blocks.45.",
        "blocks.46.",
        "blocks.47.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeMochiPreview",
    "display_name": "ModelMergeMochiPreview",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeLTXV": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "patchify_proj.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "adaln_single.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "caption_projection.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "scale_shift_table": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "proj_out.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "patchify_proj.",
        "adaln_single.",
        "caption_projection.",
        "transformer_blocks.0.",
        "transformer_blocks.1.",
        "transformer_blocks.2.",
        "transformer_blocks.3.",
        "transformer_blocks.4.",
        "transformer_blocks.5.",
        "transformer_blocks.6.",
        "transformer_blocks.7.",
        "transformer_blocks.8.",
        "transformer_blocks.9.",
        "transformer_blocks.10.",
        "transformer_blocks.11.",
        "transformer_blocks.12.",
        "transformer_blocks.13.",
        "transformer_blocks.14.",
        "transformer_blocks.15.",
        "transformer_blocks.16.",
        "transformer_blocks.17.",
        "transformer_blocks.18.",
        "transformer_blocks.19.",
        "transformer_blocks.20.",
        "transformer_blocks.21.",
        "transformer_blocks.22.",
        "transformer_blocks.23.",
        "transformer_blocks.24.",
        "transformer_blocks.25.",
        "transformer_blocks.26.",
        "transformer_blocks.27.",
        "scale_shift_table",
        "proj_out."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeLTXV",
    "display_name": "ModelMergeLTXV",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeCosmos7B": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "extra_pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "affline_norm.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embedder.",
        "extra_pos_embedder.",
        "x_embedder.",
        "t_embedder.",
        "affline_norm.",
        "blocks.block0.",
        "blocks.block1.",
        "blocks.block2.",
        "blocks.block3.",
        "blocks.block4.",
        "blocks.block5.",
        "blocks.block6.",
        "blocks.block7.",
        "blocks.block8.",
        "blocks.block9.",
        "blocks.block10.",
        "blocks.block11.",
        "blocks.block12.",
        "blocks.block13.",
        "blocks.block14.",
        "blocks.block15.",
        "blocks.block16.",
        "blocks.block17.",
        "blocks.block18.",
        "blocks.block19.",
        "blocks.block20.",
        "blocks.block21.",
        "blocks.block22.",
        "blocks.block23.",
        "blocks.block24.",
        "blocks.block25.",
        "blocks.block26.",
        "blocks.block27.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeCosmos7B",
    "display_name": "ModelMergeCosmos7B",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeCosmos14B": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "extra_pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "affline_norm.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.block35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embedder.",
        "extra_pos_embedder.",
        "x_embedder.",
        "t_embedder.",
        "affline_norm.",
        "blocks.block0.",
        "blocks.block1.",
        "blocks.block2.",
        "blocks.block3.",
        "blocks.block4.",
        "blocks.block5.",
        "blocks.block6.",
        "blocks.block7.",
        "blocks.block8.",
        "blocks.block9.",
        "blocks.block10.",
        "blocks.block11.",
        "blocks.block12.",
        "blocks.block13.",
        "blocks.block14.",
        "blocks.block15.",
        "blocks.block16.",
        "blocks.block17.",
        "blocks.block18.",
        "blocks.block19.",
        "blocks.block20.",
        "blocks.block21.",
        "blocks.block22.",
        "blocks.block23.",
        "blocks.block24.",
        "blocks.block25.",
        "blocks.block26.",
        "blocks.block27.",
        "blocks.block28.",
        "blocks.block29.",
        "blocks.block30.",
        "blocks.block31.",
        "blocks.block32.",
        "blocks.block33.",
        "blocks.block34.",
        "blocks.block35.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeCosmos14B",
    "display_name": "ModelMergeCosmos14B",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeWAN2_1": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "patch_embedding.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "time_embedding.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "time_projection.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "text_embedding.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "img_emb.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.36.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.37.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.38.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.39.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "head.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "patch_embedding.",
        "time_embedding.",
        "time_projection.",
        "text_embedding.",
        "img_emb.",
        "blocks.0.",
        "blocks.1.",
        "blocks.2.",
        "blocks.3.",
        "blocks.4.",
        "blocks.5.",
        "blocks.6.",
        "blocks.7.",
        "blocks.8.",
        "blocks.9.",
        "blocks.10.",
        "blocks.11.",
        "blocks.12.",
        "blocks.13.",
        "blocks.14.",
        "blocks.15.",
        "blocks.16.",
        "blocks.17.",
        "blocks.18.",
        "blocks.19.",
        "blocks.20.",
        "blocks.21.",
        "blocks.22.",
        "blocks.23.",
        "blocks.24.",
        "blocks.25.",
        "blocks.26.",
        "blocks.27.",
        "blocks.28.",
        "blocks.29.",
        "blocks.30.",
        "blocks.31.",
        "blocks.32.",
        "blocks.33.",
        "blocks.34.",
        "blocks.35.",
        "blocks.36.",
        "blocks.37.",
        "blocks.38.",
        "blocks.39.",
        "head."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeWAN2_1",
    "display_name": "ModelMergeWAN2_1",
    "description": "1.3B model has 30 blocks, 14B model has 40 blocks. Image to video model has the extra img_emb.",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeCosmosPredict2_2B": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedding_norm.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embedder.",
        "x_embedder.",
        "t_embedder.",
        "t_embedding_norm.",
        "blocks.0.",
        "blocks.1.",
        "blocks.2.",
        "blocks.3.",
        "blocks.4.",
        "blocks.5.",
        "blocks.6.",
        "blocks.7.",
        "blocks.8.",
        "blocks.9.",
        "blocks.10.",
        "blocks.11.",
        "blocks.12.",
        "blocks.13.",
        "blocks.14.",
        "blocks.15.",
        "blocks.16.",
        "blocks.17.",
        "blocks.18.",
        "blocks.19.",
        "blocks.20.",
        "blocks.21.",
        "blocks.22.",
        "blocks.23.",
        "blocks.24.",
        "blocks.25.",
        "blocks.26.",
        "blocks.27.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeCosmosPredict2_2B",
    "display_name": "ModelMergeCosmosPredict2_2B",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeCosmosPredict2_14B": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "x_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedder.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "t_embedding_norm.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "final_layer.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embedder.",
        "x_embedder.",
        "t_embedder.",
        "t_embedding_norm.",
        "blocks.0.",
        "blocks.1.",
        "blocks.2.",
        "blocks.3.",
        "blocks.4.",
        "blocks.5.",
        "blocks.6.",
        "blocks.7.",
        "blocks.8.",
        "blocks.9.",
        "blocks.10.",
        "blocks.11.",
        "blocks.12.",
        "blocks.13.",
        "blocks.14.",
        "blocks.15.",
        "blocks.16.",
        "blocks.17.",
        "blocks.18.",
        "blocks.19.",
        "blocks.20.",
        "blocks.21.",
        "blocks.22.",
        "blocks.23.",
        "blocks.24.",
        "blocks.25.",
        "blocks.26.",
        "blocks.27.",
        "blocks.28.",
        "blocks.29.",
        "blocks.30.",
        "blocks.31.",
        "blocks.32.",
        "blocks.33.",
        "blocks.34.",
        "blocks.35.",
        "final_layer."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeCosmosPredict2_14B",
    "display_name": "ModelMergeCosmosPredict2_14B",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "ModelMergeQwenImage": {
    "input": {
      "required": {
        "model1": [
          "MODEL"
        ],
        "model2": [
          "MODEL"
        ],
        "pos_embeds.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "img_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "txt_norm.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "txt_in.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "time_text_embed.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.0.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.1.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.2.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.3.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.4.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.5.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.6.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.7.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.8.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.9.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.10.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.11.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.12.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.13.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.14.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.15.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.16.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.17.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.18.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.19.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.20.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.21.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.22.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.23.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.24.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.25.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.26.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.27.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.28.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.29.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.30.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.31.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.32.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.33.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.34.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.35.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.36.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.37.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.38.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.39.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.40.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.41.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.42.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.43.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.44.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.45.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.46.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.47.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.48.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.49.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.50.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.51.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.52.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.53.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.54.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.55.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.56.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.57.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.58.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "transformer_blocks.59.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "proj_out.": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model1",
        "model2",
        "pos_embeds.",
        "img_in.",
        "txt_norm.",
        "txt_in.",
        "time_text_embed.",
        "transformer_blocks.0.",
        "transformer_blocks.1.",
        "transformer_blocks.2.",
        "transformer_blocks.3.",
        "transformer_blocks.4.",
        "transformer_blocks.5.",
        "transformer_blocks.6.",
        "transformer_blocks.7.",
        "transformer_blocks.8.",
        "transformer_blocks.9.",
        "transformer_blocks.10.",
        "transformer_blocks.11.",
        "transformer_blocks.12.",
        "transformer_blocks.13.",
        "transformer_blocks.14.",
        "transformer_blocks.15.",
        "transformer_blocks.16.",
        "transformer_blocks.17.",
        "transformer_blocks.18.",
        "transformer_blocks.19.",
        "transformer_blocks.20.",
        "transformer_blocks.21.",
        "transformer_blocks.22.",
        "transformer_blocks.23.",
        "transformer_blocks.24.",
        "transformer_blocks.25.",
        "transformer_blocks.26.",
        "transformer_blocks.27.",
        "transformer_blocks.28.",
        "transformer_blocks.29.",
        "transformer_blocks.30.",
        "transformer_blocks.31.",
        "transformer_blocks.32.",
        "transformer_blocks.33.",
        "transformer_blocks.34.",
        "transformer_blocks.35.",
        "transformer_blocks.36.",
        "transformer_blocks.37.",
        "transformer_blocks.38.",
        "transformer_blocks.39.",
        "transformer_blocks.40.",
        "transformer_blocks.41.",
        "transformer_blocks.42.",
        "transformer_blocks.43.",
        "transformer_blocks.44.",
        "transformer_blocks.45.",
        "transformer_blocks.46.",
        "transformer_blocks.47.",
        "transformer_blocks.48.",
        "transformer_blocks.49.",
        "transformer_blocks.50.",
        "transformer_blocks.51.",
        "transformer_blocks.52.",
        "transformer_blocks.53.",
        "transformer_blocks.54.",
        "transformer_blocks.55.",
        "transformer_blocks.56.",
        "transformer_blocks.57.",
        "transformer_blocks.58.",
        "transformer_blocks.59.",
        "proj_out."
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelMergeQwenImage",
    "display_name": "ModelMergeQwenImage",
    "description": "",
    "python_module": "comfy_extras.nodes_model_merging_model_specific",
    "category": "advanced/model_merging/model_specific",
    "output_node": false
  },
  "PerturbedAttentionGuidance": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scale": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scale"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PerturbedAttentionGuidance",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_pag",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AlignYourStepsScheduler": {
    "input": {
      "required": {
        "model_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "SD1",
              "SDXL",
              "SVD"
            ]
          }
        ],
        "steps": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 10000
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_type",
        "steps",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AlignYourStepsScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_align_your_steps",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "UNetSelfAttentionMultiply": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "q": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "k": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "v": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "out": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "q",
        "k",
        "v",
        "out"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "UNetSelfAttentionMultiply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_attention_multiply",
    "category": "_for_testing/attention_experiments",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "UNetCrossAttentionMultiply": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "q": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "k": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "v": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "out": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "q",
        "k",
        "v",
        "out"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "UNetCrossAttentionMultiply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_attention_multiply",
    "category": "_for_testing/attention_experiments",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "CLIPAttentionMultiply": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "q": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "k": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "v": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "out": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "q",
        "k",
        "v",
        "out"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPAttentionMultiply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_attention_multiply",
    "category": "_for_testing/attention_experiments",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "UNetTemporalAttentionMultiply": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "self_structural": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "self_temporal": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "cross_structural": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "cross_temporal": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "self_structural",
        "self_temporal",
        "cross_structural",
        "cross_temporal"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "UNetTemporalAttentionMultiply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_attention_multiply",
    "category": "_for_testing/attention_experiments",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SamplerLCMUpscale": {
    "input": {
      "required": {
        "scale_ratio": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 20.0,
            "step": 0.01
          }
        ],
        "scale_steps": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 1000,
            "step": 1
          }
        ],
        "upscale_method": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "bislerp",
              "nearest-exact",
              "bilinear",
              "area",
              "bicubic"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "scale_ratio",
        "scale_steps",
        "upscale_method"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerLCMUpscale",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_advanced_samplers",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SamplerEulerCFGpp": {
    "input": {
      "required": {
        "version": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "regular",
              "alternative"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "version"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SamplerEulerCFGpp",
    "display_name": "SamplerEulerCFG++",
    "description": "",
    "python_module": "comfy_extras.nodes_advanced_samplers",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "WebcamCapture": {
    "input": {
      "required": {
        "image": [
          "WEBCAM",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "capture_on_queue": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "width",
        "height",
        "capture_on_queue"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "WebcamCapture",
    "display_name": "Webcam Capture",
    "description": "",
    "python_module": "comfy_extras.nodes_webcam",
    "category": "image",
    "output_node": false
  },
  "EmptyLatentAudio": {
    "input": {
      "required": {
        "seconds": [
          "FLOAT",
          {
            "default": 47.6,
            "min": 1.0,
            "max": 1000.0,
            "step": 0.1
          }
        ],
        "batch_size": [
          "INT",
          {
            "tooltip": "The number of latent images in the batch.",
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "seconds",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyLatentAudio",
    "display_name": "Empty Latent Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "latent/audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VAEEncodeAudio": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "vae"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VAEEncodeAudio",
    "display_name": "VAE Encode Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "latent/audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VAEDecodeAudio": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "vae"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VAEDecodeAudio",
    "display_name": "VAE Decode Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "latent/audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SaveAudio": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "audio/ComfyUI",
            "multiline": false
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveAudio",
    "display_name": "Save Audio (FLAC)",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SaveAudioMP3": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "audio/ComfyUI",
            "multiline": false
          }
        ],
        "quality": [
          "COMBO",
          {
            "default": "V0",
            "multiselect": false,
            "options": [
              "V0",
              "128k",
              "320k"
            ]
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "filename_prefix",
        "quality"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveAudioMP3",
    "display_name": "Save Audio (MP3)",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SaveAudioOpus": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "audio/ComfyUI",
            "multiline": false
          }
        ],
        "quality": [
          "COMBO",
          {
            "default": "128k",
            "multiselect": false,
            "options": [
              "64k",
              "96k",
              "128k",
              "192k",
              "320k"
            ]
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "filename_prefix",
        "quality"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveAudioOpus",
    "display_name": "Save Audio (Opus)",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LoadAudio": {
    "input": {
      "required": {
        "audio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [],
            "audio_upload": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LoadAudio",
    "display_name": "Load Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PreviewAudio": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "PreviewAudio",
    "display_name": "Preview Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ConditioningStableAudio": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "seconds_start": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.1
          }
        ],
        "seconds_total": [
          "FLOAT",
          {
            "default": 47.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "seconds_start",
        "seconds_total"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "ConditioningStableAudio",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecordAudio": {
    "input": {
      "required": {
        "audio": [
          "AUDIO_RECORD",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecordAudio",
    "display_name": "Record Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TrimAudioDuration": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "start_index": [
          "FLOAT",
          {
            "tooltip": "Start time in seconds, can be negative to count from the end (supports sub-seconds).",
            "default": 0.0,
            "min": -18446744073709551615,
            "max": 18446744073709551615,
            "step": 0.01
          }
        ],
        "duration": [
          "FLOAT",
          {
            "tooltip": "Duration in seconds",
            "default": 60.0,
            "min": 0.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "start_index",
        "duration"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TrimAudioDuration",
    "display_name": "Trim Audio Duration",
    "description": "Trim audio tensor into chosen time range.",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SplitAudioChannels": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ]
    },
    "output": [
      "AUDIO",
      "AUDIO"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "left",
      "right"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "SplitAudioChannels",
    "display_name": "Split Audio Channels",
    "description": "Separates the audio into left and right channels.",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AudioConcat": {
    "input": {
      "required": {
        "audio1": [
          "AUDIO",
          {}
        ],
        "audio2": [
          "AUDIO",
          {}
        ],
        "direction": [
          "COMBO",
          {
            "tooltip": "Whether to append audio2 after or before audio1.",
            "default": "after",
            "multiselect": false,
            "options": [
              "after",
              "before"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio1",
        "audio2",
        "direction"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AudioConcat",
    "display_name": "Audio Concat",
    "description": "Concatenates the audio1 to audio2 in the specified direction.",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AudioMerge": {
    "input": {
      "required": {
        "audio1": [
          "AUDIO",
          {}
        ],
        "audio2": [
          "AUDIO",
          {}
        ],
        "merge_method": [
          "COMBO",
          {
            "tooltip": "The method used to combine the audio waveforms.",
            "multiselect": false,
            "options": [
              "add",
              "mean",
              "subtract",
              "multiply"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio1",
        "audio2",
        "merge_method"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AudioMerge",
    "display_name": "Audio Merge",
    "description": "Combine two audio tracks by overlaying their waveforms.",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AudioAdjustVolume": {
    "input": {
      "required": {
        "audio": [
          "AUDIO",
          {}
        ],
        "volume": [
          "INT",
          {
            "tooltip": "Volume adjustment in decibels (dB). 0 = no change, +6 = double, -6 = half, etc",
            "default": 1,
            "min": -100,
            "max": 100
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio",
        "volume"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AudioAdjustVolume",
    "display_name": "Audio Adjust Volume",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyAudio": {
    "input": {
      "required": {
        "duration": [
          "FLOAT",
          {
            "tooltip": "Duration of the empty audio clip in seconds",
            "default": 60.0,
            "min": 0.0,
            "max": 18446744073709551615,
            "step": 0.01
          }
        ],
        "sample_rate": [
          "INT",
          {
            "tooltip": "Sample rate of the empty audio clip.",
            "default": 44100,
            "min": 1,
            "max": 192000
          }
        ],
        "channels": [
          "INT",
          {
            "tooltip": "Number of audio channels (1 for mono, 2 for stereo).",
            "default": 2,
            "min": 1,
            "max": 2
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "duration",
        "sample_rate",
        "channels"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyAudio",
    "display_name": "Empty Audio",
    "description": "",
    "python_module": "comfy_extras.nodes_audio",
    "category": "audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TripleCLIPLoader": {
    "input": {
      "required": {
        "clip_name1": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "clip_name2": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "clip_name3": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_name1",
        "clip_name2",
        "clip_name3"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TripleCLIPLoader",
    "display_name": null,
    "description": "[Recipes]\n\nsd3: clip-l, clip-g, t5",
    "python_module": "comfy_extras.nodes_sd3",
    "category": "advanced/loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptySD3LatentImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptySD3LatentImage",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_sd3",
    "category": "latent/sd3",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeSD3": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "clip_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "clip_g": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "t5xxl": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "empty_padding": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "none",
              "empty_prompt"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "clip_l",
        "clip_g",
        "t5xxl",
        "empty_padding"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeSD3",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_sd3",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ControlNetApplySD3": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "control_net": [
          "CONTROL_NET",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "control_net",
        "vae",
        "image",
        "strength",
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "ControlNetApplySD3",
    "display_name": "Apply Controlnet with VAE",
    "description": "",
    "python_module": "comfy_extras.nodes_sd3",
    "category": "conditioning/controlnet",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": false
  },
  "SkipLayerGuidanceSD3": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "layers": [
          "STRING",
          {
            "default": "7, 8, 9",
            "multiline": false
          }
        ],
        "scale": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.1
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.01,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "layers",
        "scale",
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SkipLayerGuidanceSD3",
    "display_name": null,
    "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.",
    "python_module": "comfy_extras.nodes_sd3",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "GITSScheduler": {
    "input": {
      "required": {
        "coeff": [
          "FLOAT",
          {
            "default": 1.2,
            "min": 0.8,
            "max": 1.5,
            "step": 0.05
          }
        ],
        "steps": [
          "INT",
          {
            "default": 10,
            "min": 2,
            "max": 1000
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "coeff",
        "steps",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "GITSScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_gits",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SetUnionControlNetType": {
    "input": {
      "required": {
        "control_net": [
          "CONTROL_NET",
          {}
        ],
        "type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "auto",
              "openpose",
              "depth",
              "hed/pidi/scribble/ted",
              "canny/lineart/anime_lineart/mlsd",
              "normal",
              "segment",
              "tile",
              "repaint"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "control_net",
        "type"
      ]
    },
    "output": [
      "CONTROL_NET"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONTROL_NET"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SetUnionControlNetType",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_controlnet",
    "category": "conditioning/controlnet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ControlNetInpaintingAliMamaApply": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "control_net": [
          "CONTROL_NET",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ],
        "mask": [
          "MASK",
          {}
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "control_net",
        "vae",
        "image",
        "mask",
        "strength",
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "ControlNetInpaintingAliMamaApply",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_controlnet",
    "category": "conditioning/controlnet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeHunyuanDiT": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "bert": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "mt5xl": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "bert",
        "mt5xl"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeHunyuanDiT",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TextEncodeHunyuanVideo_ImageToVideo": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "image_interleave": [
          "INT",
          {
            "tooltip": "How much the image influences things vs the text prompt. Higher number means more influence from the text prompt.",
            "default": 2,
            "min": 1,
            "max": 512
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "clip_vision_output",
        "prompt",
        "image_interleave"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TextEncodeHunyuanVideo_ImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyHunyuanLatentVideo": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 25,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "length",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyHunyuanLatentVideo",
    "display_name": "Empty HunyuanVideo 1.0 Latent",
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "latent/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyHunyuanVideo15Latent": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 25,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "length",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyHunyuanVideo15Latent",
    "display_name": "Empty HunyuanVideo 1.5 Latent",
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "latent/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HunyuanVideo15ImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 33,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "start_image",
        "clip_vision_output"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "HunyuanVideo15ImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HunyuanVideo15SuperResolution": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "latent": [
          "LATENT",
          {}
        ],
        "noise_augmentation": [
          "FLOAT",
          {
            "default": 0.7,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "vae": [
          "VAE",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "latent",
        "noise_augmentation"
      ],
      "optional": [
        "vae",
        "start_image",
        "clip_vision_output"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "HunyuanVideo15SuperResolution",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "sd",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HunyuanVideo15LatentUpscaleWithModel": {
    "input": {
      "required": {
        "model": [
          "LATENT_UPSCALE_MODEL",
          {}
        ],
        "samples": [
          "LATENT",
          {}
        ],
        "upscale_method": [
          "COMBO",
          {
            "default": "bilinear",
            "multiselect": false,
            "options": [
              "nearest-exact",
              "bilinear",
              "area",
              "bicubic",
              "bislerp"
            ]
          }
        ],
        "width": [
          "INT",
          {
            "default": 1280,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 720,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "crop": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "disabled",
              "center"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "samples",
        "upscale_method",
        "width",
        "height",
        "crop"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "HunyuanVideo15LatentUpscaleWithModel",
    "display_name": "Hunyuan Video 15 Latent Upscale With Model",
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "latent",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LatentUpscaleModelLoader": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name"
      ]
    },
    "output": [
      "LATENT_UPSCALE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT_UPSCALE_MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LatentUpscaleModelLoader",
    "display_name": "Load Latent Upscale Model",
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HunyuanImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 53,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "guidance_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "v1 (concat)",
              "v2 (replace)",
              "custom"
            ]
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "vae",
        "width",
        "height",
        "length",
        "batch_size",
        "guidance_type"
      ],
      "optional": [
        "start_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "latent"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "HunyuanImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyHunyuanImageLatent": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 2048,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 2048,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyHunyuanImageLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "latent",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "HunyuanRefinerLatent": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "latent": [
          "LATENT",
          {}
        ],
        "noise_augmentation": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "latent",
        "noise_augmentation"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "HunyuanRefinerLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan",
    "category": "sd",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Epsilon Scaling": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scaling_factor": [
          "FLOAT",
          {
            "default": 1.005,
            "min": 0.5,
            "max": 1.5,
            "step": 0.001,
            "display": "number"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scaling_factor"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Epsilon Scaling",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_eps",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TemporalScoreRescaling": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "tsr_k": [
          "FLOAT",
          {
            "tooltip": "Controls the rescaling strength.\nLower k produces more detailed results; higher k produces smoother results in image generation. Setting k = 1 disables rescaling.",
            "default": 0.95,
            "min": 0.01,
            "max": 100.0,
            "step": 0.001,
            "display": "number"
          }
        ],
        "tsr_sigma": [
          "FLOAT",
          {
            "tooltip": "Controls how early rescaling takes effect.\nLarger values take effect earlier.",
            "default": 1.0,
            "min": 0.01,
            "max": 100.0,
            "step": 0.001,
            "display": "number"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "tsr_k",
        "tsr_sigma"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "patched_model"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TemporalScoreRescaling",
    "display_name": "TSR - Temporal Score Rescaling",
    "description": "[Post-CFG Function]\nTSR - Temporal Score Rescaling (2510.01184)\n\nRescaling the model's score or noise to steer the sampling diversity.\n",
    "python_module": "comfy_extras.nodes_eps",
    "category": "model_patches/unet",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeFlux": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "clip_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "t5xxl": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "guidance": [
          "FLOAT",
          {
            "default": 3.5,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "clip_l",
        "t5xxl",
        "guidance"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeFlux",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_flux",
    "category": "advanced/conditioning/flux",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FluxGuidance": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING",
          {}
        ],
        "guidance": [
          "FLOAT",
          {
            "default": 3.5,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "guidance"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxGuidance",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_flux",
    "category": "advanced/conditioning/flux",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FluxDisableGuidance": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxDisableGuidance",
    "display_name": null,
    "description": "This node completely disables the guidance embed on Flux and Flux like models",
    "python_module": "comfy_extras.nodes_flux",
    "category": "advanced/conditioning/flux",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FluxKontextImageScale": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxKontextImageScale",
    "display_name": null,
    "description": "This node resizes the image to one that is more optimal for flux kontext.",
    "python_module": "comfy_extras.nodes_flux",
    "category": "advanced/conditioning/flux",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FluxKontextMultiReferenceLatentMethod": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING",
          {}
        ],
        "reference_latents_method": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "offset",
              "index",
              "uxo/uno"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "reference_latents_method"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxKontextMultiReferenceLatentMethod",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_flux",
    "category": "advanced/conditioning/flux",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "EmptyFlux2LatentImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyFlux2LatentImage",
    "display_name": "Empty Flux 2 Latent",
    "description": "",
    "python_module": "comfy_extras.nodes_flux",
    "category": "latent",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Flux2Scheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 4096
          }
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "width",
        "height"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Flux2Scheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_flux",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LoraSave": {
    "input": {
      "required": {
        "filename_prefix": [
          "STRING",
          {
            "default": "loras/ComfyUI_extracted_lora",
            "multiline": false
          }
        ],
        "rank": [
          "INT",
          {
            "default": 8,
            "min": 1,
            "max": 4096,
            "step": 1
          }
        ],
        "lora_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "standard",
              "full_diff"
            ]
          }
        ],
        "bias_diff": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      },
      "optional": {
        "model_diff": [
          "MODEL",
          {
            "tooltip": "The ModelSubtract output to be converted to a lora."
          }
        ],
        "text_encoder_diff": [
          "CLIP",
          {
            "tooltip": "The CLIPSubtract output to be converted to a lora."
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "filename_prefix",
        "rank",
        "lora_type",
        "bias_diff"
      ],
      "optional": [
        "model_diff",
        "text_encoder_diff"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "LoraSave",
    "display_name": "Extract and Save Lora",
    "description": "",
    "python_module": "comfy_extras.nodes_lora_extract",
    "category": "_for_testing",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "TorchCompileModel": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "backend": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "inductor",
              "cudagraphs"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "backend"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TorchCompileModel",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_torch_compile",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "EmptyMochiLatentVideo": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 25,
            "min": 7,
            "max": 16384,
            "step": 6
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "length",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyMochiLatentVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_mochi",
    "category": "latent/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SkipLayerGuidanceDiT": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "double_layers": [
          "STRING",
          {
            "default": "7, 8, 9",
            "multiline": false
          }
        ],
        "single_layers": [
          "STRING",
          {
            "default": "7, 8, 9",
            "multiline": false
          }
        ],
        "scale": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.1
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.01,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "rescaling_scale": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "double_layers",
        "single_layers",
        "scale",
        "start_percent",
        "end_percent",
        "rescaling_scale"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SkipLayerGuidanceDiT",
    "display_name": null,
    "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.",
    "python_module": "comfy_extras.nodes_slg",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SkipLayerGuidanceDiTSimple": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "double_layers": [
          "STRING",
          {
            "default": "7, 8, 9",
            "multiline": false
          }
        ],
        "single_layers": [
          "STRING",
          {
            "default": "7, 8, 9",
            "multiline": false
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "double_layers",
        "single_layers",
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "SkipLayerGuidanceDiTSimple",
    "display_name": null,
    "description": "Simple version of the SkipLayerGuidanceDiT node that only modifies the uncond pass.",
    "python_module": "comfy_extras.nodes_slg",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "Mahiro": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "patched_model"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Mahiro",
    "display_name": "Mahiro is so cute that she deserves a better guidance function!! ()",
    "description": "Modify the guidance to scale more on the 'direction' of the positive prompt rather than the difference between the negative prompt.",
    "python_module": "comfy_extras.nodes_mahiro",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "EmptyLTXVLatentVideo": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 768,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "length": [
          "INT",
          {
            "default": 97,
            "min": 1,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "length",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyLTXVLatentVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "latent/video/ltxv",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVImgToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 768,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 32
          }
        ],
        "length": [
          "INT",
          {
            "default": 97,
            "min": 9,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "image",
        "width",
        "height",
        "length",
        "batch_size",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVImgToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ModelSamplingLTXV": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "max_shift": [
          "FLOAT",
          {
            "default": 2.05,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "base_shift": [
          "FLOAT",
          {
            "default": 0.95,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "latent": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "max_shift",
        "base_shift"
      ],
      "optional": [
        "latent"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ModelSamplingLTXV",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "advanced/model",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVConditioning": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "frame_rate": [
          "FLOAT",
          {
            "default": 25.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "frame_rate"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVConditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVScheduler": {
    "input": {
      "required": {
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "max_shift": [
          "FLOAT",
          {
            "default": 2.05,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "base_shift": [
          "FLOAT",
          {
            "default": 0.95,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "stretch": [
          "BOOLEAN",
          {
            "tooltip": "Stretch the sigmas to be in the range [terminal, 1].",
            "default": true
          }
        ],
        "terminal": [
          "FLOAT",
          {
            "tooltip": "The terminal value of the sigmas after stretching.",
            "default": 0.1,
            "min": 0.0,
            "max": 0.99,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "latent": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "steps",
        "max_shift",
        "base_shift",
        "stretch",
        "terminal"
      ],
      "optional": [
        "latent"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVAddGuide": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "latent": [
          "LATENT",
          {}
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Image or video to condition the latent video on. Must be 8*n + 1 frames. If the video is not 8*n + 1 frames, it will be cropped to the nearest 8*n + 1 frames."
          }
        ],
        "frame_idx": [
          "INT",
          {
            "tooltip": "Frame index to start the conditioning at. For single-frame images or videos with 1-8 frames, any frame_idx value is acceptable. For videos with 9+ frames, frame_idx must be divisible by 8, otherwise it will be rounded down to the nearest multiple of 8. Negative values are counted from the end of the video.",
            "default": 0,
            "min": -9999,
            "max": 9999
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "latent",
        "image",
        "frame_idx",
        "strength"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVAddGuide",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVPreprocess": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "img_compression": [
          "INT",
          {
            "tooltip": "Amount of compression to apply on image.",
            "default": 35,
            "min": 0,
            "max": 100
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "img_compression"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "output_image"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVPreprocess",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "image",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LTXVCropGuides": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "latent": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "latent"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "LTXVCropGuides",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lt",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CreateHookLora": {
    "input": {
      "required": {
        "lora_name": [
          []
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ],
        "strength_clip": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "prev_hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "lora_name",
        "strength_model",
        "strength_clip"
      ],
      "optional": [
        "prev_hooks"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CreateHookLora",
    "display_name": "Create Hook LoRA",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/create",
    "output_node": false,
    "experimental": true
  },
  "CreateHookLoraModelOnly": {
    "input": {
      "required": {
        "lora_name": [
          []
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "prev_hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "lora_name",
        "strength_model"
      ],
      "optional": [
        "prev_hooks"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CreateHookLoraModelOnly",
    "display_name": "Create Hook LoRA (MO)",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/create",
    "output_node": false,
    "experimental": true
  },
  "CreateHookModelAsLora": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ],
        "strength_clip": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "prev_hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name",
        "strength_model",
        "strength_clip"
      ],
      "optional": [
        "prev_hooks"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CreateHookModelAsLora",
    "display_name": "Create Hook Model as LoRA",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/create",
    "output_node": false,
    "experimental": true
  },
  "CreateHookModelAsLoraModelOnly": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "prev_hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name",
        "strength_model"
      ],
      "optional": [
        "prev_hooks"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CreateHookModelAsLoraModelOnly",
    "display_name": "Create Hook Model as LoRA (MO)",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/create",
    "output_node": false,
    "experimental": true
  },
  "SetHookKeyframes": {
    "input": {
      "required": {
        "hooks": [
          "HOOKS"
        ]
      },
      "optional": {
        "hook_kf": [
          "HOOK_KEYFRAMES"
        ]
      }
    },
    "input_order": {
      "required": [
        "hooks"
      ],
      "optional": [
        "hook_kf"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "SetHookKeyframes",
    "display_name": "Set Hook Keyframes",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/scheduling",
    "output_node": false,
    "experimental": true
  },
  "CreateHookKeyframe": {
    "input": {
      "required": {
        "strength_mult": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "prev_hook_kf": [
          "HOOK_KEYFRAMES"
        ]
      }
    },
    "input_order": {
      "required": [
        "strength_mult",
        "start_percent"
      ],
      "optional": [
        "prev_hook_kf"
      ]
    },
    "output": [
      "HOOK_KEYFRAMES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOK_KF"
    ],
    "name": "CreateHookKeyframe",
    "display_name": "Create Hook Keyframe",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/scheduling",
    "output_node": false,
    "experimental": true
  },
  "CreateHookKeyframesInterpolated": {
    "input": {
      "required": {
        "strength_start": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.001
          }
        ],
        "strength_end": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.001
          }
        ],
        "interpolation": [
          [
            "linear",
            "ease_in",
            "ease_out",
            "ease_in_out"
          ]
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "keyframes_count": [
          "INT",
          {
            "default": 5,
            "min": 2,
            "max": 100,
            "step": 1
          }
        ],
        "print_keyframes": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "prev_hook_kf": [
          "HOOK_KEYFRAMES"
        ]
      }
    },
    "input_order": {
      "required": [
        "strength_start",
        "strength_end",
        "interpolation",
        "start_percent",
        "end_percent",
        "keyframes_count",
        "print_keyframes"
      ],
      "optional": [
        "prev_hook_kf"
      ]
    },
    "output": [
      "HOOK_KEYFRAMES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOK_KF"
    ],
    "name": "CreateHookKeyframesInterpolated",
    "display_name": "Create Hook Keyframes Interp.",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/scheduling",
    "output_node": false,
    "experimental": true
  },
  "CreateHookKeyframesFromFloats": {
    "input": {
      "required": {
        "floats_strength": [
          "FLOATS",
          {
            "default": -1,
            "min": -1,
            "step": 0.001,
            "forceInput": true
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "print_keyframes": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "prev_hook_kf": [
          "HOOK_KEYFRAMES"
        ]
      }
    },
    "input_order": {
      "required": [
        "floats_strength",
        "start_percent",
        "end_percent",
        "print_keyframes"
      ],
      "optional": [
        "prev_hook_kf"
      ]
    },
    "output": [
      "HOOK_KEYFRAMES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOK_KF"
    ],
    "name": "CreateHookKeyframesFromFloats",
    "display_name": "Create Hook Keyframes From Floats",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/scheduling",
    "output_node": false,
    "experimental": true
  },
  "CombineHooks2": {
    "input": {
      "required": {},
      "optional": {
        "hooks_A": [
          "HOOKS"
        ],
        "hooks_B": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "hooks_A",
        "hooks_B"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CombineHooks2",
    "display_name": "Combine Hooks [2]",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/combine",
    "output_node": false,
    "experimental": true
  },
  "CombineHooks4": {
    "input": {
      "required": {},
      "optional": {
        "hooks_A": [
          "HOOKS"
        ],
        "hooks_B": [
          "HOOKS"
        ],
        "hooks_C": [
          "HOOKS"
        ],
        "hooks_D": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "hooks_A",
        "hooks_B",
        "hooks_C",
        "hooks_D"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CombineHooks4",
    "display_name": "Combine Hooks [4]",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/combine",
    "output_node": false,
    "experimental": true
  },
  "CombineHooks8": {
    "input": {
      "required": {},
      "optional": {
        "hooks_A": [
          "HOOKS"
        ],
        "hooks_B": [
          "HOOKS"
        ],
        "hooks_C": [
          "HOOKS"
        ],
        "hooks_D": [
          "HOOKS"
        ],
        "hooks_E": [
          "HOOKS"
        ],
        "hooks_F": [
          "HOOKS"
        ],
        "hooks_G": [
          "HOOKS"
        ],
        "hooks_H": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "hooks_A",
        "hooks_B",
        "hooks_C",
        "hooks_D",
        "hooks_E",
        "hooks_F",
        "hooks_G",
        "hooks_H"
      ]
    },
    "output": [
      "HOOKS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "HOOKS"
    ],
    "name": "CombineHooks8",
    "display_name": "Combine Hooks [8]",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/combine",
    "output_node": false,
    "experimental": true
  },
  "ConditioningSetProperties": {
    "input": {
      "required": {
        "cond_NEW": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "set_cond_area": [
          [
            "default",
            "mask bounds"
          ]
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "hooks": [
          "HOOKS"
        ],
        "timesteps": [
          "TIMESTEPS_RANGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "cond_NEW",
        "strength",
        "set_cond_area"
      ],
      "optional": [
        "mask",
        "hooks",
        "timesteps"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetProperties",
    "display_name": "Cond Set Props",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond single",
    "output_node": false,
    "experimental": true
  },
  "ConditioningSetPropertiesAndCombine": {
    "input": {
      "required": {
        "cond": [
          "CONDITIONING"
        ],
        "cond_NEW": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "set_cond_area": [
          [
            "default",
            "mask bounds"
          ]
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "hooks": [
          "HOOKS"
        ],
        "timesteps": [
          "TIMESTEPS_RANGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "cond",
        "cond_NEW",
        "strength",
        "set_cond_area"
      ],
      "optional": [
        "mask",
        "hooks",
        "timesteps"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetPropertiesAndCombine",
    "display_name": "Cond Set Props Combine",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond single",
    "output_node": false,
    "experimental": true
  },
  "PairConditioningSetProperties": {
    "input": {
      "required": {
        "positive_NEW": [
          "CONDITIONING"
        ],
        "negative_NEW": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "set_cond_area": [
          [
            "default",
            "mask bounds"
          ]
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "hooks": [
          "HOOKS"
        ],
        "timesteps": [
          "TIMESTEPS_RANGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "positive_NEW",
        "negative_NEW",
        "strength",
        "set_cond_area"
      ],
      "optional": [
        "mask",
        "hooks",
        "timesteps"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "PairConditioningSetProperties",
    "display_name": "Cond Pair Set Props",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond pair",
    "output_node": false,
    "experimental": true
  },
  "PairConditioningSetPropertiesAndCombine": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "positive_NEW": [
          "CONDITIONING"
        ],
        "negative_NEW": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "set_cond_area": [
          [
            "default",
            "mask bounds"
          ]
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "hooks": [
          "HOOKS"
        ],
        "timesteps": [
          "TIMESTEPS_RANGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "positive_NEW",
        "negative_NEW",
        "strength",
        "set_cond_area"
      ],
      "optional": [
        "mask",
        "hooks",
        "timesteps"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "PairConditioningSetPropertiesAndCombine",
    "display_name": "Cond Pair Set Props Combine",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond pair",
    "output_node": false,
    "experimental": true
  },
  "ConditioningSetDefaultCombine": {
    "input": {
      "required": {
        "cond": [
          "CONDITIONING"
        ],
        "cond_DEFAULT": [
          "CONDITIONING"
        ]
      },
      "optional": {
        "hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "cond",
        "cond_DEFAULT"
      ],
      "optional": [
        "hooks"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningSetDefaultCombine",
    "display_name": "Cond Set Default Combine",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond single",
    "output_node": false,
    "experimental": true
  },
  "PairConditioningSetDefaultCombine": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "positive_DEFAULT": [
          "CONDITIONING"
        ],
        "negative_DEFAULT": [
          "CONDITIONING"
        ]
      },
      "optional": {
        "hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "positive_DEFAULT",
        "negative_DEFAULT"
      ],
      "optional": [
        "hooks"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "PairConditioningSetDefaultCombine",
    "display_name": "Cond Pair Set Default Combine",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond pair",
    "output_node": false,
    "experimental": true
  },
  "PairConditioningCombine": {
    "input": {
      "required": {
        "positive_A": [
          "CONDITIONING"
        ],
        "negative_A": [
          "CONDITIONING"
        ],
        "positive_B": [
          "CONDITIONING"
        ],
        "negative_B": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "positive_A",
        "negative_A",
        "positive_B",
        "negative_B"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "PairConditioningCombine",
    "display_name": "Cond Pair Combine",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/cond pair",
    "output_node": false,
    "experimental": true
  },
  "SetClipHooks": {
    "input": {
      "required": {
        "clip": [
          "CLIP"
        ],
        "apply_to_conds": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "schedule_clip": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "hooks": [
          "HOOKS"
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "apply_to_conds",
        "schedule_clip"
      ],
      "optional": [
        "hooks"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "SetClipHooks",
    "display_name": "Set CLIP Hooks",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks/clip",
    "output_node": false,
    "experimental": true
  },
  "ConditioningTimestepsRange": {
    "input": {
      "required": {
        "start_percent": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "TIMESTEPS_RANGE",
      "TIMESTEPS_RANGE",
      "TIMESTEPS_RANGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "TIMESTEPS_RANGE",
      "BEFORE_RANGE",
      "AFTER_RANGE"
    ],
    "name": "ConditioningTimestepsRange",
    "display_name": "Timesteps Range",
    "description": "",
    "python_module": "comfy_extras.nodes_hooks",
    "category": "advanced/hooks",
    "output_node": false,
    "experimental": true
  },
  "Load3D": {
    "input": {
      "required": {
        "model_file": [
          "COMBO",
          {
            "multiselect": false,
            "options": [],
            "file_upload": true
          }
        ],
        "image": [
          "LOAD_3D",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 1,
            "max": 4096,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 1,
            "max": 4096,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_file",
        "image",
        "width",
        "height"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "STRING",
      "IMAGE",
      "LOAD3D_CAMERA",
      "VIDEO"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "image",
      "mask",
      "mesh_path",
      "normal",
      "camera_info",
      "recording_video"
    ],
    "output_tooltips": [
      null,
      null,
      null,
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "Load3D",
    "display_name": "Load 3D & Animation",
    "description": "",
    "python_module": "comfy_extras.nodes_load_3d",
    "category": "3d",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "Preview3D": {
    "input": {
      "required": {
        "model_file": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "camera_info": [
          "LOAD3D_CAMERA",
          {}
        ],
        "bg_image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_file"
      ],
      "optional": [
        "camera_info",
        "bg_image"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "Preview3D",
    "display_name": "Preview 3D & Animation",
    "description": "",
    "python_module": "comfy_extras.nodes_load_3d",
    "category": "3d",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "EmptyCosmosLatentVideo": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1280,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 704,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 121,
            "min": 1,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "length",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyCosmosLatentVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cosmos",
    "category": "latent/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CosmosImageToVideoLatent": {
    "input": {
      "required": {
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 1280,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 704,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 121,
            "min": 1,
            "max": 16384,
            "step": 8
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ],
        "end_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "start_image",
        "end_image"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CosmosImageToVideoLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cosmos",
    "category": "conditioning/inpaint",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CosmosPredict2ImageToVideoLatent": {
    "input": {
      "required": {
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 848,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 93,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ],
        "end_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "start_image",
        "end_image"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CosmosPredict2ImageToVideoLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cosmos",
    "category": "conditioning/inpaint",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SaveWEBM": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {}
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI",
            "multiline": false
          }
        ],
        "codec": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "vp9",
              "av1"
            ]
          }
        ],
        "fps": [
          "FLOAT",
          {
            "default": 24.0,
            "min": 0.01,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "crf": [
          "FLOAT",
          {
            "tooltip": "Higher crf means lower quality with a smaller file size, lower crf means higher quality higher filesize.",
            "default": 32.0,
            "min": 0,
            "max": 63.0,
            "step": 1
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "filename_prefix",
        "codec",
        "fps",
        "crf"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveWEBM",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_video",
    "category": "image/video",
    "output_node": true,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "SaveVideo": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {
            "tooltip": "The video to save."
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.",
            "default": "video/ComfyUI",
            "multiline": false
          }
        ],
        "format": [
          "COMBO",
          {
            "tooltip": "The format to save the video as.",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "mp4"
            ]
          }
        ],
        "codec": [
          "COMBO",
          {
            "tooltip": "The codec to use for the video.",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "h264"
            ]
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "video",
        "filename_prefix",
        "format",
        "codec"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveVideo",
    "display_name": "Save Video",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "comfy_extras.nodes_video",
    "category": "image/video",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CreateVideo": {
    "input": {
      "required": {
        "images": [
          "IMAGE",
          {
            "tooltip": "The images to create a video from."
          }
        ],
        "fps": [
          "FLOAT",
          {
            "default": 30.0,
            "min": 1.0,
            "max": 120.0,
            "step": 1.0
          }
        ]
      },
      "optional": {
        "audio": [
          "AUDIO",
          {
            "tooltip": "The audio to add to the video."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "fps"
      ],
      "optional": [
        "audio"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CreateVideo",
    "display_name": "Create Video",
    "description": "Create a video from images.",
    "python_module": "comfy_extras.nodes_video",
    "category": "image/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "GetVideoComponents": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {
            "tooltip": "The video to extract components from."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "video"
      ]
    },
    "output": [
      "IMAGE",
      "AUDIO",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "images",
      "audio",
      "fps"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "GetVideoComponents",
    "display_name": "Get Video Components",
    "description": "Extracts all components from a video: frames, audio, and framerate.",
    "python_module": "comfy_extras.nodes_video",
    "category": "image/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LoadVideo": {
    "input": {
      "required": {
        "file": [
          "COMBO",
          {
            "multiselect": false,
            "options": [],
            "video_upload": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LoadVideo",
    "display_name": "Load Video",
    "description": "",
    "python_module": "comfy_extras.nodes_video",
    "category": "image/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeLumina2": {
    "input": {
      "required": {
        "system_prompt": [
          "COMBO",
          {
            "tooltip": "Lumina2 provide two types of system prompts:Superior: You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts. Alignment: You are an assistant designed to generate high-quality images with the highest degree of image-text alignment based on textual prompts.",
            "multiselect": false,
            "options": [
              "superior",
              "alignment"
            ]
          }
        ],
        "user_prompt": [
          "STRING",
          {
            "tooltip": "The text to be encoded.",
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "clip": [
          "CLIP",
          {
            "tooltip": "The CLIP model used for encoding the text."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "system_prompt",
        "user_prompt",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      "A conditioning containing the embedded text used to guide the diffusion model."
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeLumina2",
    "display_name": "CLIP Text Encode for Lumina2",
    "description": "Encodes a system prompt and a user prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "python_module": "comfy_extras.nodes_lumina2",
    "category": "conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RenormCFG": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "cfg_trunc": [
          "FLOAT",
          {
            "default": 100,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "renorm_cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "cfg_trunc",
        "renorm_cfg"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RenormCFG",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lumina2",
    "category": "advanced/model",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanTrackToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "tracks": [
          "STRING",
          {
            "default": "[]",
            "multiline": true
          }
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "temperature": [
          "FLOAT",
          {
            "default": 220.0,
            "min": 1.0,
            "max": 1000.0,
            "step": 0.1
          }
        ],
        "topk": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 10
          }
        ],
        "start_image": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "tracks",
        "width",
        "height",
        "length",
        "batch_size",
        "temperature",
        "topk",
        "start_image"
      ],
      "optional": [
        "clip_vision_output"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanTrackToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "clip_vision_output",
        "start_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanFunControlToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ],
        "control_video": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "clip_vision_output",
        "start_image",
        "control_video"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanFunControlToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Wan22FunControlToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "ref_image": [
          "IMAGE",
          {}
        ],
        "control_video": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "ref_image",
        "control_video"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "Wan22FunControlToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanFunInpaintToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ],
        "end_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "clip_vision_output",
        "start_image",
        "end_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanFunInpaintToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanFirstLastFrameToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "clip_vision_start_image": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "clip_vision_end_image": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ],
        "end_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "clip_vision_start_image",
        "clip_vision_end_image",
        "start_image",
        "end_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanFirstLastFrameToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanVaceToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "control_video": [
          "IMAGE",
          {}
        ],
        "control_masks": [
          "MASK",
          {}
        ],
        "reference_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size",
        "strength"
      ],
      "optional": [
        "control_video",
        "control_masks",
        "reference_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent",
      "trim_latent"
    ],
    "output_tooltips": [
      null,
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanVaceToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TrimVideoLatent": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "trim_amount": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 99999
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "trim_amount"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TrimVideoLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "latent/video",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanCameraImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "start_image": [
          "IMAGE",
          {}
        ],
        "camera_conditions": [
          "WAN_CAMERA_EMBEDDING",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "clip_vision_output",
        "start_image",
        "camera_conditions"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanCameraImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanPhantomSubjectToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "images"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative_text",
      "negative_img_text",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanPhantomSubjectToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanSoundImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 77,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "audio_encoder_output": [
          "AUDIO_ENCODER_OUTPUT",
          {}
        ],
        "ref_image": [
          "IMAGE",
          {}
        ],
        "control_video": [
          "IMAGE",
          {}
        ],
        "ref_motion": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "audio_encoder_output",
        "ref_image",
        "control_video",
        "ref_motion"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanSoundImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanSoundImageToVideoExtend": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "length": [
          "INT",
          {
            "default": 77,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "video_latent": [
          "LATENT",
          {}
        ]
      },
      "optional": {
        "audio_encoder_output": [
          "AUDIO_ENCODER_OUTPUT",
          {}
        ],
        "ref_image": [
          "IMAGE",
          {}
        ],
        "control_video": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "length",
        "video_latent"
      ],
      "optional": [
        "audio_encoder_output",
        "ref_image",
        "control_video"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanSoundImageToVideoExtend",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanHuMoImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 97,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "audio_encoder_output": [
          "AUDIO_ENCODER_OUTPUT",
          {}
        ],
        "ref_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "audio_encoder_output",
        "ref_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanHuMoImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "WanAnimateToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 77,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "continue_motion_max_frames": [
          "INT",
          {
            "default": 5,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "video_frame_offset": [
          "INT",
          {
            "tooltip": "The amount of frames to seek in all the input videos. Used for generating longer videos by chunk. Connect to the video_frame_offset output of the previous node for extending a video.",
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ]
      },
      "optional": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "reference_image": [
          "IMAGE",
          {}
        ],
        "face_video": [
          "IMAGE",
          {}
        ],
        "pose_video": [
          "IMAGE",
          {}
        ],
        "background_video": [
          "IMAGE",
          {}
        ],
        "character_mask": [
          "MASK",
          {}
        ],
        "continue_motion": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size",
        "continue_motion_max_frames",
        "video_frame_offset"
      ],
      "optional": [
        "clip_vision_output",
        "reference_image",
        "face_video",
        "pose_video",
        "background_video",
        "character_mask",
        "continue_motion"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent",
      "trim_latent",
      "trim_image",
      "video_frame_offset"
    ],
    "output_tooltips": [
      null,
      null,
      null,
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanAnimateToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "Wan22ImageToVideoLatent": {
    "input": {
      "required": {
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 1280,
            "min": 32,
            "max": 16384,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 704,
            "min": 32,
            "max": 16384,
            "step": 32
          }
        ],
        "length": [
          "INT",
          {
            "default": 49,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "start_image"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Wan22ImageToVideoLatent",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_wan",
    "category": "conditioning/inpaint",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LotusConditioning": {
    "input": {
      "required": {}
    },
    "input_order": {
      "required": []
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "conditioning"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LotusConditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_lotus",
    "category": "conditioning/lotus",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyLatentHunyuan3Dv2": {
    "input": {
      "required": {
        "resolution": [
          "INT",
          {
            "default": 3072,
            "min": 1,
            "max": 8192
          }
        ],
        "batch_size": [
          "INT",
          {
            "tooltip": "The number of latent images in the batch.",
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "resolution",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyLatentHunyuan3Dv2",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "latent/3d",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Hunyuan3Dv2Conditioning": {
    "input": {
      "required": {
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision_output"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "Hunyuan3Dv2Conditioning",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "Hunyuan3Dv2ConditioningMultiView": {
    "input": {
      "required": {},
      "optional": {
        "front": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "left": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "back": [
          "CLIP_VISION_OUTPUT",
          {}
        ],
        "right": [
          "CLIP_VISION_OUTPUT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "front",
        "left",
        "back",
        "right"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "Hunyuan3Dv2ConditioningMultiView",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VAEDecodeHunyuan3D": {
    "input": {
      "required": {
        "samples": [
          "LATENT",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "num_chunks": [
          "INT",
          {
            "default": 8000,
            "min": 1000,
            "max": 500000
          }
        ],
        "octree_resolution": [
          "INT",
          {
            "default": 256,
            "min": 16,
            "max": 512
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "vae",
        "num_chunks",
        "octree_resolution"
      ]
    },
    "output": [
      "VOXEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VOXEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VAEDecodeHunyuan3D",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "latent/3d",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VoxelToMeshBasic": {
    "input": {
      "required": {
        "voxel": [
          "VOXEL",
          {}
        ],
        "threshold": [
          "FLOAT",
          {
            "default": 0.6,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "voxel",
        "threshold"
      ]
    },
    "output": [
      "MESH"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MESH"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VoxelToMeshBasic",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "3d",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VoxelToMesh": {
    "input": {
      "required": {
        "voxel": [
          "VOXEL",
          {}
        ],
        "algorithm": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "surface net",
              "basic"
            ]
          }
        ],
        "threshold": [
          "FLOAT",
          {
            "default": 0.6,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "voxel",
        "algorithm",
        "threshold"
      ]
    },
    "output": [
      "MESH"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MESH"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VoxelToMesh",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "3d",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SaveGLB": {
    "input": {
      "required": {
        "mesh": [
          "MESH",
          {}
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "mesh/ComfyUI",
            "multiline": false
          }
        ]
      },
      "hidden": {
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "mesh",
        "filename_prefix"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "SaveGLB",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hunyuan3d",
    "category": "3d",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PrimitiveString": {
    "input": {
      "required": {
        "value": [
          "STRING",
          {
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PrimitiveString",
    "display_name": "String",
    "description": "",
    "python_module": "comfy_extras.nodes_primitive",
    "category": "utils/primitive",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PrimitiveStringMultiline": {
    "input": {
      "required": {
        "value": [
          "STRING",
          {
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PrimitiveStringMultiline",
    "display_name": "String (Multiline)",
    "description": "",
    "python_module": "comfy_extras.nodes_primitive",
    "category": "utils/primitive",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PrimitiveInt": {
    "input": {
      "required": {
        "value": [
          "INT",
          {
            "min": -9223372036854775807,
            "max": 9223372036854775807,
            "control_after_generate": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PrimitiveInt",
    "display_name": "Int",
    "description": "",
    "python_module": "comfy_extras.nodes_primitive",
    "category": "utils/primitive",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PrimitiveFloat": {
    "input": {
      "required": {
        "value": [
          "FLOAT",
          {
            "min": -9223372036854775807,
            "max": 9223372036854775807
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ]
    },
    "output": [
      "FLOAT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FLOAT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PrimitiveFloat",
    "display_name": "Float",
    "description": "",
    "python_module": "comfy_extras.nodes_primitive",
    "category": "utils/primitive",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PrimitiveBoolean": {
    "input": {
      "required": {
        "value": [
          "BOOLEAN",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PrimitiveBoolean",
    "display_name": "Boolean",
    "description": "",
    "python_module": "comfy_extras.nodes_primitive",
    "category": "utils/primitive",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CFGZeroStar": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "patched_model"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CFGZeroStar",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cfg",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CFGNorm": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "strength"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "patched_model"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CFGNorm",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_cfg",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "OptimalStepsScheduler": {
    "input": {
      "required": {
        "model_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "FLUX",
              "Wan",
              "Chroma"
            ]
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 3,
            "max": 1000
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_type",
        "steps",
        "denoise"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OptimalStepsScheduler",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_optimalsteps",
    "category": "sampling/custom_sampling/schedulers",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "QuadrupleCLIPLoader": {
    "input": {
      "required": {
        "clip_name1": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "clip_name2": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "clip_name3": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ],
        "clip_name4": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_name1",
        "clip_name2",
        "clip_name3",
        "clip_name4"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "QuadrupleCLIPLoader",
    "display_name": null,
    "description": "[Recipes]\n\nhidream: long clip-l, long clip-g, t5xxl, llama_8b_3.1_instruct",
    "python_module": "comfy_extras.nodes_hidream",
    "category": "advanced/loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeHiDream": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "clip_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "clip_g": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "t5xxl": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "llama": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "clip_l",
        "clip_g",
        "t5xxl",
        "llama"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeHiDream",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_hidream",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "FreSca": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scale_low": [
          "FLOAT",
          {
            "tooltip": "Scaling factor for low-frequency components",
            "default": 1.0,
            "min": 0,
            "max": 10,
            "step": 0.01
          }
        ],
        "scale_high": [
          "FLOAT",
          {
            "tooltip": "Scaling factor for high-frequency components",
            "default": 1.25,
            "min": 0,
            "max": 10,
            "step": 0.01
          }
        ],
        "freq_cutoff": [
          "INT",
          {
            "tooltip": "Number of frequency indices around center to consider as low-frequency",
            "default": 20,
            "min": 1,
            "max": 10000,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scale_low",
        "scale_high",
        "freq_cutoff"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FreSca",
    "display_name": "FreSca",
    "description": "Applies frequency-dependent scaling to the guidance",
    "python_module": "comfy_extras.nodes_fresca",
    "category": "_for_testing",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "APG": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "eta": [
          "FLOAT",
          {
            "tooltip": "Controls the scale of the parallel guidance vector. Default CFG behavior at a setting of 1.",
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "norm_threshold": [
          "FLOAT",
          {
            "tooltip": "Normalize guidance vector to this value, normalization disable at a setting of 0.",
            "default": 5.0,
            "min": 0.0,
            "max": 50.0,
            "step": 0.1
          }
        ],
        "momentum": [
          "FLOAT",
          {
            "tooltip": "Controls a running average of guidance during diffusion, disabled at a setting of 0.",
            "default": 0.0,
            "min": -5.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "eta",
        "norm_threshold",
        "momentum"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "APG",
    "display_name": "Adaptive Projected Guidance",
    "description": "",
    "python_module": "comfy_extras.nodes_apg",
    "category": "sampling/custom_sampling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PreviewAny": {
    "input": {
      "required": {
        "source": [
          "*",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "source"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "PreviewAny",
    "display_name": "Preview as Text",
    "description": "",
    "python_module": "comfy_extras.nodes_preview_any",
    "category": "utils",
    "output_node": true
  },
  "TextEncodeAceStepAudio": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "tags": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "lyrics": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "lyrics_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "tags",
        "lyrics",
        "lyrics_strength"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TextEncodeAceStepAudio",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_ace",
    "category": "conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyAceStepLatentAudio": {
    "input": {
      "required": {
        "seconds": [
          "FLOAT",
          {
            "default": 120.0,
            "min": 1.0,
            "max": 1000.0,
            "step": 0.1
          }
        ],
        "batch_size": [
          "INT",
          {
            "tooltip": "The number of latent images in the batch.",
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "seconds",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyAceStepLatentAudio",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_ace",
    "category": "latent/audio",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringConcatenate": {
    "input": {
      "required": {
        "string_a": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "string_b": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "delimiter": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string_a",
        "string_b",
        "delimiter"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringConcatenate",
    "display_name": "Concatenate",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringSubstring": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "start": [
          "INT",
          {}
        ],
        "end": [
          "INT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "start",
        "end"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringSubstring",
    "display_name": "Substring",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringLength": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "length"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringLength",
    "display_name": "Length",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CaseConverter": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "UPPERCASE",
              "lowercase",
              "Capitalize",
              "Title Case"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "mode"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CaseConverter",
    "display_name": "Case Converter",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringTrim": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "Both",
              "Left",
              "Right"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "mode"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringTrim",
    "display_name": "Trim",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringReplace": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "find": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "replace": [
          "STRING",
          {
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "find",
        "replace"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringReplace",
    "display_name": "Replace",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringContains": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "substring": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "case_sensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "substring",
        "case_sensitive"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "contains"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringContains",
    "display_name": "Contains",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StringCompare": {
    "input": {
      "required": {
        "string_a": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "string_b": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "Starts With",
              "Ends With",
              "Equal"
            ]
          }
        ],
        "case_sensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string_a",
        "string_b",
        "mode",
        "case_sensitive"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StringCompare",
    "display_name": "Compare",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RegexMatch": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "regex_pattern": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "case_insensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "multiline": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "dotall": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "regex_pattern",
        "case_insensitive",
        "multiline",
        "dotall"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "matches"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RegexMatch",
    "display_name": "Regex Match",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RegexExtract": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "regex_pattern": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "First Match",
              "All Matches",
              "First Group",
              "All Groups"
            ]
          }
        ],
        "case_insensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "multiline": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "dotall": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "group_index": [
          "INT",
          {
            "default": 1,
            "min": 0,
            "max": 100
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "regex_pattern",
        "mode",
        "case_insensitive",
        "multiline",
        "dotall",
        "group_index"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RegexExtract",
    "display_name": "Regex Extract",
    "description": "",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RegexReplace": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "regex_pattern": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "replace": [
          "STRING",
          {
            "multiline": true
          }
        ]
      },
      "optional": {
        "case_insensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "multiline": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "dotall": [
          "BOOLEAN",
          {
            "tooltip": "When enabled, the dot (.) character will match any character including newline characters. When disabled, dots won't match newlines.",
            "default": false
          }
        ],
        "count": [
          "INT",
          {
            "tooltip": "Maximum number of replacements to make. Set to 0 to replace all occurrences (default). Set to 1 to replace only the first match, 2 for the first two matches, etc.",
            "default": 0,
            "min": 0,
            "max": 100
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string",
        "regex_pattern",
        "replace"
      ],
      "optional": [
        "case_insensitive",
        "multiline",
        "dotall",
        "count"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RegexReplace",
    "display_name": "Regex Replace",
    "description": "Find and replace text using regex patterns.",
    "python_module": "comfy_extras.nodes_string",
    "category": "utils/string",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "WanCameraEmbedding": {
    "input": {
      "required": {
        "camera_pose": [
          "COMBO",
          {
            "default": "Static",
            "multiselect": false,
            "options": [
              "Static",
              "Pan Up",
              "Pan Down",
              "Pan Left",
              "Pan Right",
              "Zoom In",
              "Zoom Out",
              "Anti Clockwise (ACW)",
              "ClockWise (CW)"
            ]
          }
        ],
        "width": [
          "INT",
          {
            "default": 832,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 480,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ]
      },
      "optional": {
        "speed": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 10.0,
            "step": 0.1
          }
        ],
        "fx": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0,
            "max": 1,
            "step": 1e-09
          }
        ],
        "fy": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0,
            "max": 1,
            "step": 1e-09
          }
        ],
        "cx": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "cy": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "camera_pose",
        "width",
        "height",
        "length"
      ],
      "optional": [
        "speed",
        "fx",
        "fy",
        "cx",
        "cy"
      ]
    },
    "output": [
      "WAN_CAMERA_EMBEDDING",
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "camera_embedding",
      "width",
      "height",
      "length"
    ],
    "output_tooltips": [
      null,
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "WanCameraEmbedding",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_camera_trajectory",
    "category": "camera",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ReferenceLatent": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING",
          {}
        ]
      },
      "optional": {
        "latent": [
          "LATENT",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning"
      ],
      "optional": [
        "latent"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ReferenceLatent",
    "display_name": null,
    "description": "This node sets the guiding latent for an edit model. If the model supports it you can chain multiple to set multiple reference images.",
    "python_module": "comfy_extras.nodes_edit_model",
    "category": "advanced/conditioning/edit_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TCFG": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "patched_model"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TCFG",
    "display_name": "Tangential Damping CFG",
    "description": "TCFG  Tangential Damping CFG (2503.18137)\n\nRefine the uncond (negative) to align with the cond (positive) for improving quality.",
    "python_module": "comfy_extras.nodes_tcfg",
    "category": "advanced/guidance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ContextWindowsManual": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model to apply context windows to during sampling."
          }
        ],
        "context_length": [
          "INT",
          {
            "tooltip": "The length of the context window.",
            "default": 16,
            "min": 1
          }
        ],
        "context_overlap": [
          "INT",
          {
            "tooltip": "The overlap of the context window.",
            "default": 4,
            "min": 0
          }
        ],
        "context_schedule": [
          "COMBO",
          {
            "tooltip": "The stride of the context window.",
            "multiselect": false,
            "options": [
              "standard_static",
              "standard_uniform",
              "looped_uniform",
              "batched"
            ]
          }
        ],
        "context_stride": [
          "INT",
          {
            "tooltip": "The stride of the context window; only applicable to uniform schedules.",
            "default": 1,
            "min": 1
          }
        ],
        "closed_loop": [
          "BOOLEAN",
          {
            "tooltip": "Whether to close the context window loop; only applicable to looped schedules.",
            "default": false
          }
        ],
        "fuse_method": [
          "COMBO",
          {
            "tooltip": "The method to use to fuse the context windows.",
            "default": "pyramid",
            "multiselect": false,
            "options": [
              "pyramid",
              "relative",
              "flat",
              "overlap-linear"
            ]
          }
        ],
        "dim": [
          "INT",
          {
            "tooltip": "The dimension to apply the context windows to.",
            "default": 0,
            "min": 0,
            "max": 5
          }
        ],
        "freenoise": [
          "BOOLEAN",
          {
            "tooltip": "Whether to apply FreeNoise noise shuffling, improves window blending.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "context_length",
        "context_overlap",
        "context_schedule",
        "context_stride",
        "closed_loop",
        "fuse_method",
        "dim",
        "freenoise"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      "The model with context windows applied during sampling."
    ],
    "output_matchtypes": null,
    "name": "ContextWindowsManual",
    "display_name": "Context Windows (Manual)",
    "description": "Manually set context windows.",
    "python_module": "comfy_extras.nodes_context_windows",
    "category": "context",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "WanContextWindowsManual": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model to apply context windows to during sampling."
          }
        ],
        "context_length": [
          "INT",
          {
            "tooltip": "The length of the context window.",
            "default": 81,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "context_overlap": [
          "INT",
          {
            "tooltip": "The overlap of the context window.",
            "default": 30,
            "min": 0
          }
        ],
        "context_schedule": [
          "COMBO",
          {
            "tooltip": "The stride of the context window.",
            "multiselect": false,
            "options": [
              "standard_static",
              "standard_uniform",
              "looped_uniform",
              "batched"
            ]
          }
        ],
        "context_stride": [
          "INT",
          {
            "tooltip": "The stride of the context window; only applicable to uniform schedules.",
            "default": 1,
            "min": 1
          }
        ],
        "closed_loop": [
          "BOOLEAN",
          {
            "tooltip": "Whether to close the context window loop; only applicable to looped schedules.",
            "default": false
          }
        ],
        "fuse_method": [
          "COMBO",
          {
            "tooltip": "The method to use to fuse the context windows.",
            "default": "pyramid",
            "multiselect": false,
            "options": [
              "pyramid",
              "relative",
              "flat",
              "overlap-linear"
            ]
          }
        ],
        "freenoise": [
          "BOOLEAN",
          {
            "tooltip": "Whether to apply FreeNoise noise shuffling, improves window blending.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "context_length",
        "context_overlap",
        "context_schedule",
        "context_stride",
        "closed_loop",
        "fuse_method",
        "freenoise"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      "The model with context windows applied during sampling."
    ],
    "output_matchtypes": null,
    "name": "WanContextWindowsManual",
    "display_name": "WAN Context Windows (Manual)",
    "description": "Manually set context windows for WAN-like models (dim=2).",
    "python_module": "comfy_extras.nodes_context_windows",
    "category": "context",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "TextEncodeQwenImageEdit": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "vae": [
          "VAE",
          {}
        ],
        "image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "prompt"
      ],
      "optional": [
        "vae",
        "image"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TextEncodeQwenImageEdit",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_qwen",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "TextEncodeQwenImageEditPlus": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "vae": [
          "VAE",
          {}
        ],
        "image1": [
          "IMAGE",
          {}
        ],
        "image2": [
          "IMAGE",
          {}
        ],
        "image3": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "prompt"
      ],
      "optional": [
        "vae",
        "image1",
        "image2",
        "image3"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TextEncodeQwenImageEditPlus",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_qwen",
    "category": "advanced/conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "EmptyChromaRadianceLatentImage": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "batch_size"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "EmptyChromaRadianceLatentImage",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_chroma_radiance",
    "category": "latent/chroma_radiance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ChromaRadianceOptions": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "preserve_wrapper": [
          "BOOLEAN",
          {
            "tooltip": "When enabled, will delegate to an existing model function wrapper if it exists. Generally should be left enabled.",
            "default": true
          }
        ],
        "start_sigma": [
          "FLOAT",
          {
            "tooltip": "First sigma that these options will be in effect.",
            "default": 1.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "end_sigma": [
          "FLOAT",
          {
            "tooltip": "Last sigma that these options will be in effect.",
            "default": 0.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "nerf_tile_size": [
          "INT",
          {
            "tooltip": "Allows overriding the default NeRF tile size. -1 means use the default (32). 0 means use non-tiling mode (may require a lot of VRAM).",
            "default": -1,
            "min": -1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "preserve_wrapper",
        "start_sigma",
        "end_sigma",
        "nerf_tile_size"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ChromaRadianceOptions",
    "display_name": null,
    "description": "Allows setting advanced options for the Chroma Radiance model.",
    "python_module": "comfy_extras.nodes_chroma_radiance",
    "category": "model_patches/chroma_radiance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ModelPatchLoader": {
    "input": {
      "required": {
        "name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "name"
      ]
    },
    "output": [
      "MODEL_PATCH"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL_PATCH"
    ],
    "name": "ModelPatchLoader",
    "display_name": "ModelPatchLoader",
    "description": "",
    "python_module": "comfy_extras.nodes_model_patch",
    "category": "advanced/loaders",
    "output_node": false,
    "experimental": true
  },
  "QwenImageDiffsynthControlnet": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "model_patch": [
          "MODEL_PATCH"
        ],
        "vae": [
          "VAE"
        ],
        "image": [
          "IMAGE"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "model_patch",
        "vae",
        "image",
        "strength"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "QwenImageDiffsynthControlnet",
    "display_name": "QwenImageDiffsynthControlnet",
    "description": "",
    "python_module": "comfy_extras.nodes_model_patch",
    "category": "advanced/loaders/qwen",
    "output_node": false,
    "experimental": true
  },
  "USOStyleReference": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "model_patch": [
          "MODEL_PATCH"
        ],
        "clip_vision_output": [
          "CLIP_VISION_OUTPUT"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "model_patch",
        "clip_vision_output"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "USOStyleReference",
    "display_name": "USOStyleReference",
    "description": "",
    "python_module": "comfy_extras.nodes_model_patch",
    "category": "advanced/model_patches/flux",
    "output_node": false,
    "experimental": true
  },
  "EasyCache": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model to add EasyCache to."
          }
        ],
        "reuse_threshold": [
          "FLOAT",
          {
            "tooltip": "The threshold for reusing cached steps.",
            "default": 0.2,
            "min": 0.0,
            "max": 3.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "tooltip": "The relative sampling step to begin use of EasyCache.",
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "tooltip": "The relative sampling step to end use of EasyCache.",
            "default": 0.95,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "verbose": [
          "BOOLEAN",
          {
            "tooltip": "Whether to log verbose information.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "reuse_threshold",
        "start_percent",
        "end_percent",
        "verbose"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      "The model with EasyCache."
    ],
    "output_matchtypes": null,
    "name": "EasyCache",
    "display_name": "EasyCache",
    "description": "Native EasyCache implementation.",
    "python_module": "comfy_extras.nodes_easycache",
    "category": "advanced/debug/model",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "LazyCache": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {
            "tooltip": "The model to add LazyCache to."
          }
        ],
        "reuse_threshold": [
          "FLOAT",
          {
            "tooltip": "The threshold for reusing cached steps.",
            "default": 0.2,
            "min": 0.0,
            "max": 3.0,
            "step": 0.01
          }
        ],
        "start_percent": [
          "FLOAT",
          {
            "tooltip": "The relative sampling step to begin use of LazyCache.",
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "tooltip": "The relative sampling step to end use of LazyCache.",
            "default": 0.95,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "verbose": [
          "BOOLEAN",
          {
            "tooltip": "Whether to log verbose information.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "reuse_threshold",
        "start_percent",
        "end_percent",
        "verbose"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      "The model with LazyCache."
    ],
    "output_matchtypes": null,
    "name": "LazyCache",
    "display_name": "LazyCache",
    "description": "A homebrew version of EasyCache - even 'easier' version of EasyCache to implement. Overall works worse than EasyCache, but better in some rare cases AND universal compatibility with everything in ComfyUI.",
    "python_module": "comfy_extras.nodes_easycache",
    "category": "advanced/debug/model",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "AudioEncoderLoader": {
    "input": {
      "required": {
        "audio_encoder_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": []
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio_encoder_name"
      ]
    },
    "output": [
      "AUDIO_ENCODER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO_ENCODER"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AudioEncoderLoader",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_audio_encoder",
    "category": "loaders",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "AudioEncoderEncode": {
    "input": {
      "required": {
        "audio_encoder": [
          "AUDIO_ENCODER",
          {}
        ],
        "audio": [
          "AUDIO",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "audio_encoder",
        "audio"
      ]
    },
    "output": [
      "AUDIO_ENCODER_OUTPUT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO_ENCODER_OUTPUT"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "AudioEncoderEncode",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_audio_encoder",
    "category": "conditioning",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ScaleROPE": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ],
        "scale_x": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "shift_x": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -256.0,
            "max": 256.0,
            "step": 0.1
          }
        ],
        "scale_y": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "shift_y": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -256.0,
            "max": 256.0,
            "step": 0.1
          }
        ],
        "scale_t": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "shift_t": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -256.0,
            "max": 256.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "scale_x",
        "shift_x",
        "scale_y",
        "shift_y",
        "scale_t",
        "shift_t"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ScaleROPE",
    "display_name": null,
    "description": "Scale and shift the ROPE of the model.",
    "python_module": "comfy_extras.nodes_rope",
    "category": "advanced/model_patches",
    "output_node": false,
    "deprecated": false,
    "experimental": true,
    "api_node": false
  },
  "wanBlockSwap": {
    "input": {
      "required": {
        "model": [
          "MODEL",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "wanBlockSwap",
    "display_name": null,
    "description": "NOP",
    "python_module": "comfy_extras.nodes_nop",
    "category": "",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": false
  },
  "Kandinsky5ImageToVideo": {
    "input": {
      "required": {
        "positive": [
          "CONDITIONING",
          {}
        ],
        "negative": [
          "CONDITIONING",
          {}
        ],
        "vae": [
          "VAE",
          {}
        ],
        "width": [
          "INT",
          {
            "default": 768,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 16,
            "max": 16384,
            "step": 16
          }
        ],
        "length": [
          "INT",
          {
            "default": 121,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ]
      },
      "optional": {
        "start_image": [
          "IMAGE",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "positive",
        "negative",
        "vae",
        "width",
        "height",
        "length",
        "batch_size"
      ],
      "optional": [
        "start_image"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "LATENT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative",
      "latent",
      "cond_latent"
    ],
    "output_tooltips": [
      null,
      null,
      "Empty video latent",
      "Clean encoded start images, used to replace the noisy start of the model output latents"
    ],
    "output_matchtypes": null,
    "name": "Kandinsky5ImageToVideo",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_kandinsky5",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "NormalizeVideoLatentStart": {
    "input": {
      "required": {
        "latent": [
          "LATENT",
          {}
        ],
        "start_frame_count": [
          "INT",
          {
            "tooltip": "Number of latent frames to normalize, counted from the start",
            "default": 4,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "reference_frame_count": [
          "INT",
          {
            "tooltip": "Number of latent frames after the start frames to use as reference",
            "default": 5,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent",
        "start_frame_count",
        "reference_frame_count"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "latent"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "NormalizeVideoLatentStart",
    "display_name": null,
    "description": "Normalizes the initial frames of a video latent to match the mean and standard deviation of subsequent reference frames. Helps reduce differences between the starting frames and the rest of the video.",
    "python_module": "comfy_extras.nodes_kandinsky5",
    "category": "conditioning/video_models",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "CLIPTextEncodeKandinsky5": {
    "input": {
      "required": {
        "clip": [
          "CLIP",
          {}
        ],
        "clip_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "qwen25_7b": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "clip_l",
        "qwen25_7b"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "CLIPTextEncodeKandinsky5",
    "display_name": null,
    "description": "",
    "python_module": "comfy_extras.nodes_kandinsky5",
    "category": "advanced/conditioning/kandinsky5",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "IdeogramV1": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "turbo": [
          "BOOLEAN",
          {
            "tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)",
            "default": false
          }
        ]
      },
      "optional": {
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio for image generation.",
            "default": "1:1",
            "multiselect": false,
            "options": [
              "1:1",
              "4:3",
              "3:4",
              "16:9",
              "9:16",
              "2:1",
              "1:2",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ]
          }
        ],
        "magic_prompt_option": [
          "COMBO",
          {
            "tooltip": "Determine if MagicPrompt should be used in generation",
            "default": "AUTO",
            "multiselect": false,
            "options": [
              "AUTO",
              "ON",
              "OFF"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Description of what to exclude from the image",
            "default": "",
            "multiline": true
          }
        ],
        "num_images": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "turbo"
      ],
      "optional": [
        "aspect_ratio",
        "magic_prompt_option",
        "seed",
        "negative_prompt",
        "num_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "IdeogramV1",
    "display_name": "Ideogram V1",
    "description": "Generates images using the Ideogram V1 model.",
    "python_module": "comfy_api_nodes.nodes_ideogram",
    "category": "api node/image/Ideogram",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "IdeogramV2": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "turbo": [
          "BOOLEAN",
          {
            "tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)",
            "default": false
          }
        ]
      },
      "optional": {
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to AUTO.",
            "default": "1:1",
            "multiselect": false,
            "options": [
              "1:1",
              "4:3",
              "3:4",
              "16:9",
              "9:16",
              "2:1",
              "1:2",
              "3:2",
              "2:3",
              "4:5",
              "5:4"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution for image generation. If not set to AUTO, this overrides the aspect_ratio setting.",
            "default": "Auto",
            "multiselect": false,
            "options": [
              "Auto",
              "512 x 1536",
              "576 x 1408",
              "576 x 1472",
              "576 x 1536",
              "640 x 1024",
              "640 x 1344",
              "640 x 1408",
              "640 x 1472",
              "640 x 1536",
              "704 x 1152",
              "704 x 1216",
              "704 x 1280",
              "704 x 1344",
              "704 x 1408",
              "704 x 1472",
              "720 x 1280",
              "736 x 1312",
              "768 x 1024",
              "768 x 1088",
              "768 x 1152",
              "768 x 1216",
              "768 x 1232",
              "768 x 1280",
              "768 x 1344",
              "832 x 960",
              "832 x 1024",
              "832 x 1088",
              "832 x 1152",
              "832 x 1216",
              "832 x 1248",
              "864 x 1152",
              "896 x 960",
              "896 x 1024",
              "896 x 1088",
              "896 x 1120",
              "896 x 1152",
              "960 x 832",
              "960 x 896",
              "960 x 1024",
              "960 x 1088",
              "1024 x 640",
              "1024 x 768",
              "1024 x 832",
              "1024 x 896",
              "1024 x 960",
              "1024 x 1024",
              "1088 x 768",
              "1088 x 832",
              "1088 x 896",
              "1088 x 960",
              "1120 x 896",
              "1152 x 704",
              "1152 x 768",
              "1152 x 832",
              "1152 x 864",
              "1152 x 896",
              "1216 x 704",
              "1216 x 768",
              "1216 x 832",
              "1232 x 768",
              "1248 x 832",
              "1280 x 704",
              "1280 x 720",
              "1280 x 768",
              "1280 x 800",
              "1312 x 736",
              "1344 x 640",
              "1344 x 704",
              "1344 x 768",
              "1408 x 576",
              "1408 x 640",
              "1408 x 704",
              "1472 x 576",
              "1472 x 640",
              "1472 x 704",
              "1536 x 512",
              "1536 x 576",
              "1536 x 640"
            ]
          }
        ],
        "magic_prompt_option": [
          "COMBO",
          {
            "tooltip": "Determine if MagicPrompt should be used in generation",
            "default": "AUTO",
            "multiselect": false,
            "options": [
              "AUTO",
              "ON",
              "OFF"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "style_type": [
          "COMBO",
          {
            "tooltip": "Style type for generation (V2 only)",
            "default": "NONE",
            "multiselect": false,
            "options": [
              "AUTO",
              "GENERAL",
              "REALISTIC",
              "DESIGN",
              "RENDER_3D",
              "ANIME"
            ]
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Description of what to exclude from the image",
            "default": "",
            "multiline": true
          }
        ],
        "num_images": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "turbo"
      ],
      "optional": [
        "aspect_ratio",
        "resolution",
        "magic_prompt_option",
        "seed",
        "style_type",
        "negative_prompt",
        "num_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "IdeogramV2",
    "display_name": "Ideogram V2",
    "description": "Generates images using the Ideogram V2 model.",
    "python_module": "comfy_api_nodes.nodes_ideogram",
    "category": "api node/image/Ideogram",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "IdeogramV3": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation or editing",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image for image editing."
          }
        ],
        "mask": [
          "MASK",
          {
            "tooltip": "Optional mask for inpainting (white areas will be replaced)"
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to Auto.",
            "default": "1:1",
            "multiselect": false,
            "options": [
              "1:3",
              "3:1",
              "1:2",
              "2:1",
              "9:16",
              "16:9",
              "10:16",
              "16:10",
              "2:3",
              "3:2",
              "3:4",
              "4:3",
              "4:5",
              "5:4",
              "1:1"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution for image generation. If not set to Auto, this overrides the aspect_ratio setting.",
            "default": "Auto",
            "multiselect": false,
            "options": [
              "Auto",
              "512x1536",
              "576x1408",
              "576x1472",
              "576x1536",
              "640x1344",
              "640x1408",
              "640x1472",
              "640x1536",
              "704x1152",
              "704x1216",
              "704x1280",
              "704x1344",
              "704x1408",
              "704x1472",
              "736x1312",
              "768x1088",
              "768x1216",
              "768x1280",
              "768x1344",
              "800x1280",
              "832x960",
              "832x1024",
              "832x1088",
              "832x1152",
              "832x1216",
              "832x1248",
              "864x1152",
              "896x960",
              "896x1024",
              "896x1088",
              "896x1120",
              "896x1152",
              "960x832",
              "960x896",
              "960x1024",
              "960x1088",
              "1024x832",
              "1024x896",
              "1024x960",
              "1024x1024",
              "1088x768",
              "1088x832",
              "1088x896",
              "1088x960",
              "1120x896",
              "1152x704",
              "1152x832",
              "1152x864",
              "1152x896",
              "1216x704",
              "1216x768",
              "1216x832",
              "1248x832",
              "1280x704",
              "1280x768",
              "1280x800",
              "1312x736",
              "1344x640",
              "1344x704",
              "1344x768",
              "1408x576",
              "1408x640",
              "1408x704",
              "1472x576",
              "1472x640",
              "1472x704",
              "1536x512",
              "1536x576",
              "1536x640"
            ]
          }
        ],
        "magic_prompt_option": [
          "COMBO",
          {
            "tooltip": "Determine if MagicPrompt should be used in generation",
            "default": "AUTO",
            "multiselect": false,
            "options": [
              "AUTO",
              "ON",
              "OFF"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "num_images": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ],
        "rendering_speed": [
          "COMBO",
          {
            "tooltip": "Controls the trade-off between generation speed and quality",
            "default": "DEFAULT",
            "multiselect": false,
            "options": [
              "DEFAULT",
              "TURBO",
              "QUALITY"
            ]
          }
        ],
        "character_image": [
          "IMAGE",
          {
            "tooltip": "Image to use as character reference."
          }
        ],
        "character_mask": [
          "MASK",
          {
            "tooltip": "Optional mask for character reference image."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "image",
        "mask",
        "aspect_ratio",
        "resolution",
        "magic_prompt_option",
        "seed",
        "num_images",
        "rendering_speed",
        "character_image",
        "character_mask"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "IdeogramV3",
    "display_name": "Ideogram V3",
    "description": "Generates images using the Ideogram V3 model. Supports both regular image generation from text prompts and image editing with mask.",
    "python_module": "comfy_api_nodes.nodes_ideogram",
    "category": "api node/image/Ideogram",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIDalle2": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for DALLE",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "not implemented yet in backend",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "size": [
          "COMBO",
          {
            "tooltip": "Image size",
            "default": "1024x1024",
            "multiselect": false,
            "options": [
              "256x256",
              "512x512",
              "1024x1024"
            ]
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "How many images to generate",
            "default": 1,
            "min": 1,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image for image editing."
          }
        ],
        "mask": [
          "MASK",
          {
            "tooltip": "Optional mask for inpainting (white areas will be replaced)"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "seed",
        "size",
        "n",
        "image",
        "mask"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIDalle2",
    "display_name": "OpenAI DALLE 2",
    "description": "Generates images synchronously via OpenAI's DALLE 2 endpoint.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/image/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIDalle3": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for DALLE",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "not implemented yet in backend",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "quality": [
          "COMBO",
          {
            "tooltip": "Image quality",
            "default": "standard",
            "multiselect": false,
            "options": [
              "standard",
              "hd"
            ]
          }
        ],
        "style": [
          "COMBO",
          {
            "tooltip": "Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.",
            "default": "natural",
            "multiselect": false,
            "options": [
              "natural",
              "vivid"
            ]
          }
        ],
        "size": [
          "COMBO",
          {
            "tooltip": "Image size",
            "default": "1024x1024",
            "multiselect": false,
            "options": [
              "1024x1024",
              "1024x1792",
              "1792x1024"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "seed",
        "quality",
        "style",
        "size"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIDalle3",
    "display_name": "OpenAI DALLE 3",
    "description": "Generates images synchronously via OpenAI's DALLE 3 endpoint.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/image/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIGPTImage1": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for GPT Image 1",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "not implemented yet in backend",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "quality": [
          "COMBO",
          {
            "tooltip": "Image quality, affects cost and generation time.",
            "default": "low",
            "multiselect": false,
            "options": [
              "low",
              "medium",
              "high"
            ]
          }
        ],
        "background": [
          "COMBO",
          {
            "tooltip": "Return image with or without background",
            "default": "opaque",
            "multiselect": false,
            "options": [
              "opaque",
              "transparent"
            ]
          }
        ],
        "size": [
          "COMBO",
          {
            "tooltip": "Image size",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "1024x1024",
              "1024x1536",
              "1536x1024"
            ]
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "How many images to generate",
            "default": 1,
            "min": 1,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image for image editing."
          }
        ],
        "mask": [
          "MASK",
          {
            "tooltip": "Optional mask for inpainting (white areas will be replaced)"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "seed",
        "quality",
        "background",
        "size",
        "n",
        "image",
        "mask"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIGPTImage1",
    "display_name": "OpenAI GPT Image 1",
    "description": "Generates images synchronously via OpenAI's GPT Image 1 endpoint.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/image/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIChatNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text inputs to the model, used to generate a response.",
            "default": "",
            "multiline": true
          }
        ],
        "persist_context": [
          "BOOLEAN",
          {
            "tooltip": "This parameter is deprecated and has no effect.",
            "default": false
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "The model used to generate the response",
            "multiselect": false,
            "options": [
              "o4-mini",
              "o1",
              "o3",
              "o1-pro",
              "gpt-4o",
              "gpt-4.1",
              "gpt-4.1-mini",
              "gpt-4.1-nano",
              "gpt-5",
              "gpt-5-mini",
              "gpt-5-nano"
            ]
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."
          }
        ],
        "files": [
          "OPENAI_INPUT_FILES",
          {
            "tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the OpenAI Chat Input Files node."
          }
        ],
        "advanced_options": [
          "OPENAI_CHAT_CONFIG",
          {
            "tooltip": "Optional configuration for the model. Accepts inputs from the OpenAI Chat Advanced Options node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "persist_context",
        "model"
      ],
      "optional": [
        "images",
        "files",
        "advanced_options"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIChatNode",
    "display_name": "OpenAI ChatGPT",
    "description": "Generate text responses from an OpenAI model.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/text/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIInputFiles": {
    "input": {
      "required": {
        "file": [
          "COMBO",
          {
            "tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.",
            "multiselect": false,
            "options": []
          }
        ]
      },
      "optional": {
        "OPENAI_INPUT_FILES": [
          "OPENAI_INPUT_FILES",
          {
            "tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file"
      ],
      "optional": [
        "OPENAI_INPUT_FILES"
      ]
    },
    "output": [
      "OPENAI_INPUT_FILES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "OPENAI_INPUT_FILES"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIInputFiles",
    "display_name": "OpenAI ChatGPT Input Files",
    "description": "Loads and prepares input files (text, pdf, etc.) to include as inputs for the OpenAI Chat Node. The files will be read by the OpenAI model when generating a response.  TIP: Can be chained together with other OpenAI Input File nodes.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/text/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "OpenAIChatConfig": {
    "input": {
      "required": {
        "truncation": [
          "COMBO",
          {
            "tooltip": "The truncation strategy to use for the model response. auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.disabled: If a model response will exceed the context window size for a model, the request will fail with a 400 error",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "disabled"
            ]
          }
        ]
      },
      "optional": {
        "max_output_tokens": [
          "INT",
          {
            "tooltip": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens",
            "default": 4096,
            "min": 16,
            "max": 16384
          }
        ],
        "instructions": [
          "STRING",
          {
            "tooltip": "Instructions for the model on how to generate the response",
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "truncation"
      ],
      "optional": [
        "max_output_tokens",
        "instructions"
      ]
    },
    "output": [
      "OPENAI_CHAT_CONFIG"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "OPENAI_CHAT_CONFIG"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIChatConfig",
    "display_name": "OpenAI ChatGPT Advanced Options",
    "description": "Allows specifying advanced configuration options for the OpenAI Chat Nodes.",
    "python_module": "comfy_api_nodes.nodes_openai",
    "category": "api node/text/OpenAI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "MinimaxTextToVideoNode": {
    "input": {
      "required": {
        "prompt_text": [
          "STRING",
          {
            "tooltip": "Text prompt to guide the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use for video generation",
            "default": "T2V-01",
            "multiselect": false,
            "options": [
              "T2V-01",
              "T2V-01-Director"
            ]
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "step": 1,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_text",
        "model"
      ],
      "optional": [
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MinimaxTextToVideoNode",
    "display_name": "MiniMax Text to Video",
    "description": "Generates videos synchronously based on a prompt, and optional parameters.",
    "python_module": "comfy_api_nodes.nodes_minimax",
    "category": "api node/video/MiniMax",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "MinimaxImageToVideoNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Image to use as first frame of video generation"
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "tooltip": "Text prompt to guide the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use for video generation",
            "default": "I2V-01",
            "multiselect": false,
            "options": [
              "I2V-01-Director",
              "I2V-01",
              "I2V-01-live"
            ]
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "step": 1,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt_text",
        "model"
      ],
      "optional": [
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MinimaxImageToVideoNode",
    "display_name": "MiniMax Image to Video",
    "description": "Generates videos synchronously based on an image and prompt, and optional parameters.",
    "python_module": "comfy_api_nodes.nodes_minimax",
    "category": "api node/video/MiniMax",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "MinimaxHailuoVideoNode": {
    "input": {
      "required": {
        "prompt_text": [
          "STRING",
          {
            "tooltip": "Text prompt to guide the video generation.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "step": 1,
            "control_after_generate": true
          }
        ],
        "first_frame_image": [
          "IMAGE",
          {
            "tooltip": "Optional image to use as the first frame to generate a video."
          }
        ],
        "prompt_optimizer": [
          "BOOLEAN",
          {
            "tooltip": "Optimize prompt to improve generation quality when needed.",
            "default": true
          }
        ],
        "duration": [
          "COMBO",
          {
            "tooltip": "The length of the output video in seconds.",
            "default": 6,
            "multiselect": false,
            "options": [
              6,
              10
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The dimensions of the video display. 1080p is 1920x1080, 768p is 1366x768.",
            "default": "768P",
            "multiselect": false,
            "options": [
              "768P",
              "1080P"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_text"
      ],
      "optional": [
        "seed",
        "first_frame_image",
        "prompt_optimizer",
        "duration",
        "resolution"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MinimaxHailuoVideoNode",
    "display_name": "MiniMax Hailuo Video",
    "description": "Generates videos from prompt, with optional start frame using the new MiniMax Hailuo-02 model.",
    "python_module": "comfy_api_nodes.nodes_minimax",
    "category": "api node/video/MiniMax",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "VeoVideoGenerationNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text description of the video",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Aspect ratio of the output video",
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16"
            ]
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid in the video",
            "default": "",
            "multiline": true
          }
        ],
        "duration_seconds": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 5,
            "min": 5,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ],
        "enhance_prompt": [
          "BOOLEAN",
          {
            "tooltip": "Whether to enhance the prompt with AI assistance",
            "default": true
          }
        ],
        "person_generation": [
          "COMBO",
          {
            "tooltip": "Whether to allow generating people in the video",
            "default": "ALLOW",
            "multiselect": false,
            "options": [
              "ALLOW",
              "BLOCK"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image to guide video generation"
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "Veo 2 model to use for video generation",
            "default": "veo-2.0-generate-001",
            "multiselect": false,
            "options": [
              "veo-2.0-generate-001"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio"
      ],
      "optional": [
        "negative_prompt",
        "duration_seconds",
        "enhance_prompt",
        "person_generation",
        "seed",
        "image",
        "model"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "VeoVideoGenerationNode",
    "display_name": "Google Veo 2 Video Generation",
    "description": "Generates videos from text prompts using Google's Veo 2 API",
    "python_module": "comfy_api_nodes.nodes_veo2",
    "category": "api node/video/Veo",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Veo3VideoGenerationNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text description of the video",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Aspect ratio of the output video",
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16"
            ]
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid in the video",
            "default": "",
            "multiline": true
          }
        ],
        "duration_seconds": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds (Veo 3 only supports 8 seconds)",
            "default": 8,
            "min": 8,
            "max": 8,
            "step": 1,
            "display": "number"
          }
        ],
        "enhance_prompt": [
          "BOOLEAN",
          {
            "tooltip": "Whether to enhance the prompt with AI assistance",
            "default": true
          }
        ],
        "person_generation": [
          "COMBO",
          {
            "tooltip": "Whether to allow generating people in the video",
            "default": "ALLOW",
            "multiselect": false,
            "options": [
              "ALLOW",
              "BLOCK"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image to guide video generation"
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "Veo 3 model to use for video generation",
            "default": "veo-3.0-generate-001",
            "multiselect": false,
            "options": [
              "veo-3.1-generate",
              "veo-3.1-fast-generate",
              "veo-3.0-generate-001",
              "veo-3.0-fast-generate-001"
            ]
          }
        ],
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "Generate audio for the video. Supported by all Veo 3 models.",
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio"
      ],
      "optional": [
        "negative_prompt",
        "duration_seconds",
        "enhance_prompt",
        "person_generation",
        "seed",
        "image",
        "model",
        "generate_audio"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Veo3VideoGenerationNode",
    "display_name": "Google Veo 3 Video Generation",
    "description": "Generates videos from text prompts using Google's Veo 3 API",
    "python_module": "comfy_api_nodes.nodes_veo2",
    "category": "api node/video/Veo",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Veo3FirstLastFrameNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text description of the video",
            "default": "",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid in the video",
            "default": "",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "720p",
              "1080p"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Aspect ratio of the output video",
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 8,
            "min": 4,
            "max": 8,
            "step": 2,
            "display": "slider"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "first_frame": [
          "IMAGE",
          {
            "tooltip": "Start frame"
          }
        ],
        "last_frame": [
          "IMAGE",
          {
            "tooltip": "End frame"
          }
        ],
        "model": [
          "COMBO",
          {
            "default": "veo-3.1-fast-generate",
            "multiselect": false,
            "options": [
              "veo-3.1-generate",
              "veo-3.1-fast-generate"
            ]
          }
        ],
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "Generate audio for the video.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "seed",
        "first_frame",
        "last_frame",
        "model",
        "generate_audio"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Veo3FirstLastFrameNode",
    "display_name": "Google Veo 3 First-Last-Frame to Video",
    "description": "Generate video using prompt and first and last frames.",
    "python_module": "comfy_api_nodes.nodes_veo2",
    "category": "api node/video/Veo",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingCameraControls": {
    "input": {
      "required": {
        "camera_control_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "simple",
              "down_back",
              "forward_up",
              "right_turn_forward",
              "left_turn_forward"
            ]
          }
        ],
        "horizontal_movement": [
          "FLOAT",
          {
            "tooltip": "Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right",
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ],
        "vertical_movement": [
          "FLOAT",
          {
            "tooltip": "Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward.",
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ],
        "pan": [
          "FLOAT",
          {
            "tooltip": "Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation.",
            "default": 0.5,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ],
        "tilt": [
          "FLOAT",
          {
            "tooltip": "Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation.",
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ],
        "roll": [
          "FLOAT",
          {
            "tooltip": "Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise.",
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ],
        "zoom": [
          "FLOAT",
          {
            "tooltip": "Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view.",
            "default": 0.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.25,
            "display": "slider"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "camera_control_type",
        "horizontal_movement",
        "vertical_movement",
        "pan",
        "tilt",
        "roll",
        "zoom"
      ]
    },
    "output": [
      "CAMERA_CONTROL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "camera_control"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingCameraControls",
    "display_name": "Kling Camera Controls",
    "description": "Allows specifying configuration options for Kling Camera Controls and motion control effects.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "KlingTextToVideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "mode": [
          "COMBO",
          {
            "tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.",
            "default": "standard mode / 5s duration / kling-v1-6",
            "multiselect": false,
            "options": [
              "standard mode / 5s duration / kling-v1",
              "standard mode / 10s duration / kling-v1",
              "pro mode / 5s duration / kling-v1",
              "pro mode / 10s duration / kling-v1",
              "standard mode / 5s duration / kling-v1-6",
              "standard mode / 10s duration / kling-v1-6",
              "pro mode / 5s duration / kling-v2-master",
              "pro mode / 10s duration / kling-v2-master",
              "standard mode / 5s duration / kling-v2-master",
              "standard mode / 10s duration / kling-v2-master",
              "pro mode / 5s duration / kling-v2-1-master",
              "pro mode / 10s duration / kling-v2-1-master",
              "pro mode / 5s duration / kling-v2-5-turbo",
              "pro mode / 10s duration / kling-v2-5-turbo"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "cfg_scale",
        "aspect_ratio",
        "mode"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingTextToVideoNode",
    "display_name": "Kling Text to Video",
    "description": "Kling Text to Video Node",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingImage2VideoNode": {
    "input": {
      "required": {
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "The reference image used to generate the video."
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "model_name": [
          "COMBO",
          {
            "default": "kling-v2-master",
            "multiselect": false,
            "options": [
              "kling-v1",
              "kling-v1-5",
              "kling-v1-6",
              "kling-v2-master",
              "kling-v2-1",
              "kling-v2-1-master",
              "kling-v2-5-turbo"
            ]
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "mode": [
          "COMBO",
          {
            "default": "std",
            "multiselect": false,
            "options": [
              "std",
              "pro"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": "5",
            "multiselect": false,
            "options": [
              "5",
              "10"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "start_frame",
        "prompt",
        "negative_prompt",
        "model_name",
        "cfg_scale",
        "mode",
        "aspect_ratio",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingImage2VideoNode",
    "display_name": "Kling Image to Video",
    "description": "Kling Image to Video Node",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingCameraControlI2VNode": {
    "input": {
      "required": {
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 0.75,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "camera_control": [
          "CAMERA_CONTROL",
          {
            "tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "start_frame",
        "prompt",
        "negative_prompt",
        "cfg_scale",
        "aspect_ratio",
        "camera_control"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingCameraControlI2VNode",
    "display_name": "Kling Image to Video (Camera Control)",
    "description": "Transform still images into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original image.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingCameraControlT2VNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 0.75,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "camera_control": [
          "CAMERA_CONTROL",
          {
            "tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "cfg_scale",
        "aspect_ratio",
        "camera_control"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingCameraControlT2VNode",
    "display_name": "Kling Text to Video (Camera Control)",
    "description": "Transform text into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original text.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingStartEndFrameNode": {
    "input": {
      "required": {
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."
          }
        ],
        "end_frame": [
          "IMAGE",
          {
            "tooltip": "Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix."
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "mode": [
          "COMBO",
          {
            "tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.",
            "default": "pro mode / 5s duration / kling-v2-5-turbo",
            "multiselect": false,
            "options": [
              "standard mode / 5s duration / kling-v1",
              "pro mode / 5s duration / kling-v1",
              "pro mode / 5s duration / kling-v1-5",
              "pro mode / 10s duration / kling-v1-5",
              "pro mode / 5s duration / kling-v1-6",
              "pro mode / 10s duration / kling-v1-6",
              "pro mode / 5s duration / kling-v2-1",
              "pro mode / 10s duration / kling-v2-1",
              "pro mode / 5s duration / kling-v2-5-turbo",
              "pro mode / 10s duration / kling-v2-5-turbo"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "start_frame",
        "end_frame",
        "prompt",
        "negative_prompt",
        "cfg_scale",
        "aspect_ratio",
        "mode"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingStartEndFrameNode",
    "display_name": "Kling Start-End Frame to Video",
    "description": "Generate a video sequence that transitions between your provided start and end images. The node creates all frames in between, producing a smooth transformation from the first frame to the last.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingVideoExtendNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt for guiding the video extension",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt for elements to avoid in the extended video",
            "multiline": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "video_id": [
          "STRING",
          {
            "tooltip": "The ID of the video to be extended. Supports videos generated by text-to-video, image-to-video, and previous video extension operations. Cannot exceed 3 minutes total duration after extension.",
            "forceInput": true,
            "multiline": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "cfg_scale",
        "video_id"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingVideoExtendNode",
    "display_name": "Kling Video Extend",
    "description": "Kling Video Extend Node. Extend videos made by other Kling nodes. The video_id is created by using other Kling Nodes.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingLipSyncAudioToVideoNode": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {}
        ],
        "audio": [
          "AUDIO",
          {}
        ],
        "voice_language": [
          "COMBO",
          {
            "default": "en",
            "multiselect": false,
            "options": [
              "zh",
              "en"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "video",
        "audio",
        "voice_language"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingLipSyncAudioToVideoNode",
    "display_name": "Kling Lip Sync Video with Audio",
    "description": "Kling Lip Sync Audio to Video Node. Syncs mouth movements in a video file to the audio content of an audio file. When using, ensure that the audio contains clearly distinguishable vocals and that the video contains a distinct face. The audio file should not be larger than 5MB. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingLipSyncTextToVideoNode": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {}
        ],
        "text": [
          "STRING",
          {
            "tooltip": "Text Content for Lip-Sync Video Generation. Required when mode is text2video. Maximum length is 120 characters.",
            "multiline": true
          }
        ],
        "voice": [
          "COMBO",
          {
            "default": "Melody",
            "multiselect": false,
            "options": [
              "Melody",
              "Sunny",
              "Sage",
              "Ace",
              "Blossom",
              "Peppy",
              "Dove",
              "Shine",
              "Anchor",
              "Lyric",
              "Tender",
              "Siren",
              "Zippy",
              "Bud",
              "Sprite",
              "Candy",
              "Beacon",
              "Rock",
              "Titan",
              "Grace",
              "Helen",
              "Lore",
              "Crag",
              "Prattle",
              "Hearth",
              "The Reader",
              "Commercial Lady",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              "",
              ""
            ]
          }
        ],
        "voice_speed": [
          "FLOAT",
          {
            "tooltip": "Speech Rate. Valid range: 0.8~2.0, accurate to one decimal place.",
            "default": 1,
            "min": 0.8,
            "max": 2.0,
            "display": "slider"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "video",
        "text",
        "voice",
        "voice_speed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingLipSyncTextToVideoNode",
    "display_name": "Kling Lip Sync Video with Text",
    "description": "Kling Lip Sync Text to Video Node. Syncs mouth movements in a video file to a text prompt. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingVirtualTryOnNode": {
    "input": {
      "required": {
        "human_image": [
          "IMAGE",
          {}
        ],
        "cloth_image": [
          "IMAGE",
          {}
        ],
        "model_name": [
          "COMBO",
          {
            "default": "kolors-virtual-try-on-v1",
            "multiselect": false,
            "options": [
              "kolors-virtual-try-on-v1",
              "kolors-virtual-try-on-v1-5"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "human_image",
        "cloth_image",
        "model_name"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingVirtualTryOnNode",
    "display_name": "Kling Virtual Try On",
    "description": "Kling Virtual Try On Node. Input a human image and a cloth image to try on the cloth on the human. You can merge multiple clothing item pictures into one image with a white background.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/image/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingImageGenerationNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Positive text prompt",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt",
            "multiline": true
          }
        ],
        "image_type": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "subject",
              "face"
            ]
          }
        ],
        "image_fidelity": [
          "FLOAT",
          {
            "tooltip": "Reference intensity for user-uploaded images",
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "display": "slider"
          }
        ],
        "human_fidelity": [
          "FLOAT",
          {
            "tooltip": "Subject reference similarity",
            "default": 0.45,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "display": "slider"
          }
        ],
        "model_name": [
          "COMBO",
          {
            "default": "kling-v1",
            "multiselect": false,
            "options": [
              "kling-v1",
              "kling-v1-5",
              "kling-v2"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "3:2",
              "2:3",
              "21:9"
            ]
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "Number of generated images",
            "default": 1,
            "min": 1,
            "max": 9
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "image_type",
        "image_fidelity",
        "human_fidelity",
        "model_name",
        "aspect_ratio",
        "n"
      ],
      "optional": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingImageGenerationNode",
    "display_name": "Kling Image Generation",
    "description": "Kling Image Generation Node. Generate an image from a text prompt with an optional reference image.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/image/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingSingleImageVideoEffectNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": " Reference Image. URL or Base64 encoded string (without data:image prefix). File size cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1"
          }
        ],
        "effect_scene": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "bloombloom",
              "dizzydizzy",
              "fuzzyfuzzy",
              "squish",
              "expansion"
            ]
          }
        ],
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-v1-6"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "5",
              "10"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "effect_scene",
        "model_name",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "video_id",
      "duration"
    ],
    "output_tooltips": [
      null,
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingSingleImageVideoEffectNode",
    "display_name": "Kling Video Effects",
    "description": "Achieve different special effects when generating a video based on the effect_scene.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingDualCharacterVideoEffectNode": {
    "input": {
      "required": {
        "image_left": [
          "IMAGE",
          {
            "tooltip": "Left side image"
          }
        ],
        "image_right": [
          "IMAGE",
          {
            "tooltip": "Right side image"
          }
        ],
        "effect_scene": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "hug",
              "kiss",
              "heart_gesture"
            ]
          }
        ],
        "model_name": [
          "COMBO",
          {
            "default": "kling-v1",
            "multiselect": false,
            "options": [
              "kling-v1",
              "kling-v1-5",
              "kling-v1-6"
            ]
          }
        ],
        "mode": [
          "COMBO",
          {
            "default": "std",
            "multiselect": false,
            "options": [
              "std",
              "pro"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "5",
              "10"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image_left",
        "image_right",
        "effect_scene",
        "model_name",
        "mode",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "VIDEO",
      "duration"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "KlingDualCharacterVideoEffectNode",
    "display_name": "Kling Dual Character Video Effects",
    "description": "Achieve different special effects when generating a video based on the effect_scene. First image will be positioned on left side, second on right side of the composite.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProTextToVideoNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-video-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the video content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "aspect_ratio",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProTextToVideoNode",
    "display_name": "Kling Omni Text to Video (Pro)",
    "description": "Use text prompts to generate videos with the latest Kling model.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProFirstLastFrameNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-video-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the video content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "5",
              "10"
            ]
          }
        ],
        "first_frame": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "end_frame": [
          "IMAGE",
          {
            "tooltip": "An optional end frame for the video. This cannot be used simultaneously with 'reference_images'."
          }
        ],
        "reference_images": [
          "IMAGE",
          {
            "tooltip": "Up to 6 additional reference images."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "duration",
        "first_frame"
      ],
      "optional": [
        "end_frame",
        "reference_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProFirstLastFrameNode",
    "display_name": "Kling Omni First-Last-Frame to Video (Pro)",
    "description": "Use a start frame, an optional end frame, or reference images with the latest Kling model.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProImageToVideoNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-video-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the video content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "default": 3,
            "min": 3,
            "max": 10,
            "display": "slider"
          }
        ],
        "reference_images": [
          "IMAGE",
          {
            "tooltip": "Up to 7 reference images."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "aspect_ratio",
        "duration",
        "reference_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProImageToVideoNode",
    "display_name": "Kling Omni Image to Video (Pro)",
    "description": "Use up to 7 reference images to generate a video with the latest Kling model.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProVideoToVideoNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-video-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the video content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "default": 3,
            "min": 3,
            "max": 10,
            "display": "slider"
          }
        ],
        "reference_video": [
          "VIDEO",
          {
            "tooltip": "Video to use as a reference."
          }
        ],
        "keep_original_sound": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      },
      "optional": {
        "reference_images": [
          "IMAGE",
          {
            "tooltip": "Up to 4 additional reference images."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "aspect_ratio",
        "duration",
        "reference_video",
        "keep_original_sound"
      ],
      "optional": [
        "reference_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProVideoToVideoNode",
    "display_name": "Kling Omni Video to Video (Pro)",
    "description": "Use a video and up to 4 reference images to generate a video with the latest Kling model.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProEditVideoNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-video-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the video content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "video": [
          "VIDEO",
          {
            "tooltip": "Video for editing. The output video length will be the same."
          }
        ],
        "keep_original_sound": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      },
      "optional": {
        "reference_images": [
          "IMAGE",
          {
            "tooltip": "Up to 4 additional reference images."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "video",
        "keep_original_sound"
      ],
      "optional": [
        "reference_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProEditVideoNode",
    "display_name": "Kling Omni Edit Video (Pro)",
    "description": "Edit an existing video with the latest model from Kling.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/video/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "KlingOmniProImageNode": {
    "input": {
      "required": {
        "model_name": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "kling-image-o1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A text prompt describing the image content. This can include both positive and negative descriptions.",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "1K",
              "2K"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1",
              "4:3",
              "3:4",
              "3:2",
              "2:3",
              "21:9"
            ]
          }
        ]
      },
      "optional": {
        "reference_images": [
          "IMAGE",
          {
            "tooltip": "Up to 10 additional reference images."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "prompt",
        "resolution",
        "aspect_ratio"
      ],
      "optional": [
        "reference_images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "KlingOmniProImageNode",
    "display_name": "Kling Omni Image (Pro)",
    "description": "Create or edit images with the latest model from Kling.",
    "python_module": "comfy_api_nodes.nodes_kling",
    "category": "api node/image/Kling",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "FluxProUltraImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "aspect_ratio": [
          "STRING",
          {
            "tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.",
            "default": "16:9",
            "multiline": false
          }
        ],
        "raw": [
          "BOOLEAN",
          {
            "tooltip": "When True, generate less processed, more natural-looking images.",
            "default": false
          }
        ]
      },
      "optional": {
        "image_prompt": [
          "IMAGE",
          {}
        ],
        "image_prompt_strength": [
          "FLOAT",
          {
            "tooltip": "Blend between the prompt and the image prompt.",
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "prompt_upsampling",
        "seed",
        "aspect_ratio",
        "raw"
      ],
      "optional": [
        "image_prompt",
        "image_prompt_strength"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxProUltraImageNode",
    "display_name": "Flux 1.1 [pro] Ultra Image",
    "description": "Generates images using Flux Pro 1.1 Ultra via api based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "FluxKontextProImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation - specify what and how to edit.",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "STRING",
          {
            "tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.",
            "default": "16:9",
            "multiline": false
          }
        ],
        "guidance": [
          "FLOAT",
          {
            "tooltip": "Guidance strength for the image generation process",
            "default": 3.0,
            "min": 0.1,
            "max": 99.0,
            "step": 0.1
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of steps for the image generation process",
            "default": 50,
            "min": 1,
            "max": 150
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 1234,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ]
      },
      "optional": {
        "input_image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio",
        "guidance",
        "steps",
        "seed",
        "prompt_upsampling"
      ],
      "optional": [
        "input_image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxKontextProImageNode",
    "display_name": "Flux.1 Kontext [pro] Image",
    "description": "Edits images using Flux.1 Kontext [pro] via api based on prompt and aspect ratio.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "FluxKontextMaxImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation - specify what and how to edit.",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "STRING",
          {
            "tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.",
            "default": "16:9",
            "multiline": false
          }
        ],
        "guidance": [
          "FLOAT",
          {
            "tooltip": "Guidance strength for the image generation process",
            "default": 3.0,
            "min": 0.1,
            "max": 99.0,
            "step": 0.1
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of steps for the image generation process",
            "default": 50,
            "min": 1,
            "max": 150
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 1234,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ]
      },
      "optional": {
        "input_image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio",
        "guidance",
        "steps",
        "seed",
        "prompt_upsampling"
      ],
      "optional": [
        "input_image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxKontextMaxImageNode",
    "display_name": "Flux.1 Kontext [max] Image",
    "description": "Edits images using Flux.1 Kontext [max] via api based on prompt and aspect ratio.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "FluxProExpandNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ],
        "top": [
          "INT",
          {
            "tooltip": "Number of pixels to expand at the top of the image",
            "default": 0,
            "min": 0,
            "max": 2048
          }
        ],
        "bottom": [
          "INT",
          {
            "tooltip": "Number of pixels to expand at the bottom of the image",
            "default": 0,
            "min": 0,
            "max": 2048
          }
        ],
        "left": [
          "INT",
          {
            "tooltip": "Number of pixels to expand at the left of the image",
            "default": 0,
            "min": 0,
            "max": 2048
          }
        ],
        "right": [
          "INT",
          {
            "tooltip": "Number of pixels to expand at the right of the image",
            "default": 0,
            "min": 0,
            "max": 2048
          }
        ],
        "guidance": [
          "FLOAT",
          {
            "tooltip": "Guidance strength for the image generation process",
            "default": 60,
            "min": 1.5,
            "max": 100
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of steps for the image generation process",
            "default": 50,
            "min": 15,
            "max": 50
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "prompt_upsampling",
        "top",
        "bottom",
        "left",
        "right",
        "guidance",
        "steps",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxProExpandNode",
    "display_name": "Flux.1 Expand Image",
    "description": "Outpaints image based on prompt.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "FluxProFillNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "mask": [
          "MASK",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ],
        "guidance": [
          "FLOAT",
          {
            "tooltip": "Guidance strength for the image generation process",
            "default": 60,
            "min": 1.5,
            "max": 100
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of steps for the image generation process",
            "default": 50,
            "min": 15,
            "max": 50
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mask",
        "prompt",
        "prompt_upsampling",
        "guidance",
        "steps",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "FluxProFillNode",
    "display_name": "Flux.1 Fill Image",
    "description": "Inpaints image based on mask and prompt.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Flux2ProImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation or edit",
            "default": "",
            "multiline": true
          }
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 256,
            "max": 2048,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 768,
            "min": 256,
            "max": 2048,
            "step": 32
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "prompt_upsampling": [
          "BOOLEAN",
          {
            "tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).",
            "default": false
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Up to 4 images to be used as references."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "width",
        "height",
        "seed",
        "prompt_upsampling"
      ],
      "optional": [
        "images"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Flux2ProImageNode",
    "display_name": "Flux.2 [pro] Image",
    "description": "Generates images synchronously based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_bfl",
    "category": "api node/image/BFL",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceImageNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "seedream-3-0-t2i-250415"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "The text prompt used to generate the image",
            "multiline": true
          }
        ],
        "size_preset": [
          "COMBO",
          {
            "tooltip": "Pick a recommended size. Select Custom to use the width and height below",
            "multiselect": false,
            "options": [
              "1024x1024 (1:1)",
              "864x1152 (3:4)",
              "1152x864 (4:3)",
              "1280x720 (16:9)",
              "720x1280 (9:16)",
              "832x1248 (2:3)",
              "1248x832 (3:2)",
              "1512x648 (21:9)",
              "2048x2048 (1:1)",
              "Custom"
            ]
          }
        ],
        "width": [
          "INT",
          {
            "tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`",
            "default": 1024,
            "min": 512,
            "max": 2048,
            "step": 64
          }
        ],
        "height": [
          "INT",
          {
            "tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`",
            "default": 1024,
            "min": 512,
            "max": 2048,
            "step": 64
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "tooltip": "Higher value makes the image follow the prompt more closely",
            "default": 2.5,
            "min": 1.0,
            "max": 10.0,
            "step": 0.01,
            "display": "number"
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the image",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "size_preset",
        "width",
        "height"
      ],
      "optional": [
        "seed",
        "guidance_scale",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceImageNode",
    "display_name": "ByteDance Image",
    "description": "Generate images using ByteDance models via api based on prompt",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/image/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceImageEditNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "seededit-3-0-i2i-250628"
            ]
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "The base image to edit"
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Instruction to edit image",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "tooltip": "Higher value makes the image follow the prompt more closely",
            "default": 5.5,
            "min": 1.0,
            "max": 10.0,
            "step": 0.01,
            "display": "number"
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the image",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "image",
        "prompt"
      ],
      "optional": [
        "seed",
        "guidance_scale",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceImageEditNode",
    "display_name": "ByteDance Image Edit",
    "description": "Edit images using ByteDance models via api based on prompt",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/image/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceSeedreamNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model name",
            "multiselect": false,
            "options": [
              "seedream-4-5-251128",
              "seedream-4-0-250828"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for creating or editing an image.",
            "default": "",
            "multiline": true
          }
        ],
        "size_preset": [
          "COMBO",
          {
            "tooltip": "Pick a recommended size. Select Custom to use the width and height below.",
            "multiselect": false,
            "options": [
              "2048x2048 (1:1)",
              "2304x1728 (4:3)",
              "1728x2304 (3:4)",
              "2560x1440 (16:9)",
              "1440x2560 (9:16)",
              "2496x1664 (3:2)",
              "1664x2496 (2:3)",
              "3024x1296 (21:9)",
              "4096x4096 (1:1)",
              "Custom"
            ]
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Input image(s) for image-to-image generation. List of 1-10 images for single or multi-reference generation."
          }
        ],
        "width": [
          "INT",
          {
            "tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`",
            "default": 2048,
            "min": 1024,
            "max": 4096,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`",
            "default": 2048,
            "min": 1024,
            "max": 4096,
            "step": 8
          }
        ],
        "sequential_image_generation": [
          "COMBO",
          {
            "tooltip": "Group image generation mode. 'disabled' generates a single image. 'auto' lets the model decide whether to generate multiple related images (e.g., story scenes, character variations).",
            "multiselect": false,
            "options": [
              "disabled",
              "auto"
            ]
          }
        ],
        "max_images": [
          "INT",
          {
            "tooltip": "Maximum number of images to generate when sequential_image_generation='auto'. Total images (input + generated) cannot exceed 15.",
            "default": 1,
            "min": 1,
            "max": 15,
            "step": 1,
            "display": "number"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the image.",
            "default": true
          }
        ],
        "fail_on_partial": [
          "BOOLEAN",
          {
            "tooltip": "If enabled, abort execution if any requested images are missing or return an error.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "size_preset"
      ],
      "optional": [
        "image",
        "width",
        "height",
        "sequential_image_generation",
        "max_images",
        "seed",
        "watermark",
        "fail_on_partial"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceSeedreamNode",
    "display_name": "ByteDance Seedream 4",
    "description": "Unified text-to-image generation and precise single-sentence editing at up to 4K resolution.",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/image/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceTextToVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "default": "seedance-1-0-pro-fast-251015",
            "multiselect": false,
            "options": [
              "seedance-1-0-pro-250528",
              "seedance-1-0-lite-t2v-250428",
              "seedance-1-0-pro-fast-251015"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "The text prompt used to generate the video.",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution of the output video.",
            "multiselect": false,
            "options": [
              "480p",
              "720p",
              "1080p"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video.",
            "multiselect": false,
            "options": [
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "21:9"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "The duration of the output video in seconds.",
            "default": 5,
            "min": 3,
            "max": 12,
            "step": 1,
            "display": "slider"
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "camera_fixed": [
          "BOOLEAN",
          {
            "tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.",
            "default": false
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the video.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration"
      ],
      "optional": [
        "seed",
        "camera_fixed",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceTextToVideoNode",
    "display_name": "ByteDance Text to Video",
    "description": "Generate video using ByteDance models via api based on prompt",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/video/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceImageToVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "default": "seedance-1-0-pro-fast-251015",
            "multiselect": false,
            "options": [
              "seedance-1-0-pro-250528",
              "seedance-1-0-lite-t2v-250428",
              "seedance-1-0-pro-fast-251015"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "The text prompt used to generate the video.",
            "multiline": true
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "First frame to be used for the video."
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution of the output video.",
            "multiselect": false,
            "options": [
              "480p",
              "720p",
              "1080p"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video.",
            "multiselect": false,
            "options": [
              "adaptive",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "21:9"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "The duration of the output video in seconds.",
            "default": 5,
            "min": 3,
            "max": 12,
            "step": 1,
            "display": "slider"
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "camera_fixed": [
          "BOOLEAN",
          {
            "tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.",
            "default": false
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the video.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "image",
        "resolution",
        "aspect_ratio",
        "duration"
      ],
      "optional": [
        "seed",
        "camera_fixed",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceImageToVideoNode",
    "display_name": "ByteDance Image to Video",
    "description": "Generate video using ByteDance models via api based on image and prompt",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/video/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceFirstLastFrameNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "default": "seedance-1-0-lite-i2v-250428",
            "multiselect": false,
            "options": [
              "seedance-1-0-pro-250528",
              "seedance-1-0-lite-i2v-250428"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "The text prompt used to generate the video.",
            "multiline": true
          }
        ],
        "first_frame": [
          "IMAGE",
          {
            "tooltip": "First frame to be used for the video."
          }
        ],
        "last_frame": [
          "IMAGE",
          {
            "tooltip": "Last frame to be used for the video."
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution of the output video.",
            "multiselect": false,
            "options": [
              "480p",
              "720p",
              "1080p"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video.",
            "multiselect": false,
            "options": [
              "adaptive",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "21:9"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "The duration of the output video in seconds.",
            "default": 5,
            "min": 3,
            "max": 12,
            "step": 1,
            "display": "slider"
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "camera_fixed": [
          "BOOLEAN",
          {
            "tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.",
            "default": false
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the video.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "first_frame",
        "last_frame",
        "resolution",
        "aspect_ratio",
        "duration"
      ],
      "optional": [
        "seed",
        "camera_fixed",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceFirstLastFrameNode",
    "display_name": "ByteDance First-Last-Frame to Video",
    "description": "Generate video using prompt and first and last frames.",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/video/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ByteDanceImageReferenceNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "default": "seedance-1-0-lite-i2v-250428",
            "multiselect": false,
            "options": [
              "seedance-1-0-pro-250528",
              "seedance-1-0-lite-i2v-250428"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "The text prompt used to generate the video.",
            "multiline": true
          }
        ],
        "images": [
          "IMAGE",
          {
            "tooltip": "One to four images."
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "The resolution of the output video.",
            "multiselect": false,
            "options": [
              "480p",
              "720p"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video.",
            "multiselect": false,
            "options": [
              "adaptive",
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16",
              "21:9"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "The duration of the output video in seconds.",
            "default": 5,
            "min": 3,
            "max": 12,
            "step": 1,
            "display": "slider"
          }
        ]
      },
      "optional": {
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the video.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "images",
        "resolution",
        "aspect_ratio",
        "duration"
      ],
      "optional": [
        "seed",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ByteDanceImageReferenceNode",
    "display_name": "ByteDance Reference Images to Video",
    "description": "Generate video using prompt and reference images.",
    "python_module": "comfy_api_nodes.nodes_bytedance",
    "category": "api node/video/ByteDance",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LtxvApiTextToVideo": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "LTX-2 (Pro)",
              "LTX-2 (Fast)"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 8,
            "multiselect": false,
            "options": [
              6,
              8,
              10,
              12,
              14,
              16,
              18,
              20
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "1920x1080",
              "2560x1440",
              "3840x2160"
            ]
          }
        ],
        "fps": [
          "COMBO",
          {
            "default": 25,
            "multiselect": false,
            "options": [
              25,
              50
            ]
          }
        ]
      },
      "optional": {
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "When true, the generated video will include AI-generated audio matching the scene.",
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "duration",
        "resolution",
        "fps"
      ],
      "optional": [
        "generate_audio"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LtxvApiTextToVideo",
    "display_name": "LTXV Text To Video",
    "description": "Professional-quality videos with customizable duration and resolution.",
    "python_module": "comfy_api_nodes.nodes_ltxv",
    "category": "api node/video/LTXV",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LtxvApiImageToVideo": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "First frame to be used for the video."
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "LTX-2 (Pro)",
              "LTX-2 (Fast)"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 8,
            "multiselect": false,
            "options": [
              6,
              8,
              10,
              12,
              14,
              16,
              18,
              20
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "1920x1080",
              "2560x1440",
              "3840x2160"
            ]
          }
        ],
        "fps": [
          "COMBO",
          {
            "default": 25,
            "multiselect": false,
            "options": [
              25,
              50
            ]
          }
        ]
      },
      "optional": {
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "When true, the generated video will include AI-generated audio matching the scene.",
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "model",
        "prompt",
        "duration",
        "resolution",
        "fps"
      ],
      "optional": [
        "generate_audio"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LtxvApiImageToVideo",
    "display_name": "LTXV Image To Video",
    "description": "Professional-quality videos with customizable duration and resolution based on start image.",
    "python_module": "comfy_api_nodes.nodes_ltxv",
    "category": "api node/video/LTXV",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LumaImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "photon-1",
              "photon-flash-1"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "1:1",
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "style_image_weight": [
          "FLOAT",
          {
            "tooltip": "Weight of style image. Ignored if no style_image provided.",
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "image_luma_ref": [
          "LUMA_REF",
          {
            "tooltip": "Luma Reference node connection to influence generation with input images; up to 4 images can be considered."
          }
        ],
        "style_image": [
          "IMAGE",
          {
            "tooltip": "Style reference image; only 1 image will be used."
          }
        ],
        "character_image": [
          "IMAGE",
          {
            "tooltip": "Character reference images; can be a batch of multiple, up to 4 images can be considered."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "aspect_ratio",
        "seed",
        "style_image_weight"
      ],
      "optional": [
        "image_luma_ref",
        "style_image",
        "character_image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaImageNode",
    "display_name": "Luma Text to Image",
    "description": "Generates images synchronously based on prompt and aspect ratio.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/image/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LumaImageModifyNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation",
            "default": "",
            "multiline": true
          }
        ],
        "image_weight": [
          "FLOAT",
          {
            "tooltip": "Weight of the image; the closer to 1.0, the less the image will be modified.",
            "default": 0.1,
            "min": 0.0,
            "max": 0.98,
            "step": 0.01
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "photon-1",
              "photon-flash-1"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "image_weight",
        "model",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaImageModifyNode",
    "display_name": "Luma Image to Image",
    "description": "Modifies images synchronously based on prompt and aspect ratio.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/image/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LumaVideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "ray-2",
              "ray-flash-2",
              "ray-1-6"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "default": "16:9",
            "multiselect": false,
            "options": [
              "1:1",
              "16:9",
              "9:16",
              "4:3",
              "3:4",
              "21:9",
              "9:21"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "540p",
            "multiselect": false,
            "options": [
              "540p",
              "720p",
              "1080p",
              "4k"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "5s",
              "9s"
            ]
          }
        ],
        "loop": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "luma_concepts": [
          "LUMA_CONCEPTS",
          {
            "tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "aspect_ratio",
        "resolution",
        "duration",
        "loop",
        "seed"
      ],
      "optional": [
        "luma_concepts"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaVideoNode",
    "display_name": "Luma Text to Video",
    "description": "Generates videos synchronously based on prompt and output_size.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/video/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LumaImageToVideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "ray-2",
              "ray-flash-2",
              "ray-1-6"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "540p",
            "multiselect": false,
            "options": [
              "540p",
              "720p",
              "1080p",
              "4k"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "5s",
              "9s"
            ]
          }
        ],
        "loop": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "first_image": [
          "IMAGE",
          {
            "tooltip": "First frame of generated video."
          }
        ],
        "last_image": [
          "IMAGE",
          {
            "tooltip": "Last frame of generated video."
          }
        ],
        "luma_concepts": [
          "LUMA_CONCEPTS",
          {
            "tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "resolution",
        "duration",
        "loop",
        "seed"
      ],
      "optional": [
        "first_image",
        "last_image",
        "luma_concepts"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaImageToVideoNode",
    "display_name": "Luma Image to Video",
    "description": "Generates videos synchronously based on prompt, input images, and output_size.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/video/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "LumaReferenceNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Image to use as reference."
          }
        ],
        "weight": [
          "FLOAT",
          {
            "tooltip": "Weight of image reference.",
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "luma_ref": [
          "LUMA_REF",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "weight"
      ],
      "optional": [
        "luma_ref"
      ]
    },
    "output": [
      "LUMA_REF"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "luma_ref"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaReferenceNode",
    "display_name": "Luma Reference",
    "description": "Holds an image and weight for use with Luma Generate Image node.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/image/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "LumaConceptsNode": {
    "input": {
      "required": {
        "concept1": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "truck_left",
              "pan_right",
              "pedestal_down",
              "low_angle",
              "pedestal_up",
              "selfie",
              "pan_left",
              "roll_right",
              "zoom_in",
              "over_the_shoulder",
              "orbit_right",
              "orbit_left",
              "static",
              "tiny_planet",
              "high_angle",
              "bolt_cam",
              "dolly_zoom",
              "overhead",
              "zoom_out",
              "handheld",
              "roll_left",
              "pov",
              "aerial_drone",
              "push_in",
              "crane_down",
              "truck_right",
              "tilt_down",
              "elevator_doors",
              "tilt_up",
              "ground_level",
              "pull_out",
              "aerial",
              "crane_up",
              "eye_level"
            ]
          }
        ],
        "concept2": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "truck_left",
              "pan_right",
              "pedestal_down",
              "low_angle",
              "pedestal_up",
              "selfie",
              "pan_left",
              "roll_right",
              "zoom_in",
              "over_the_shoulder",
              "orbit_right",
              "orbit_left",
              "static",
              "tiny_planet",
              "high_angle",
              "bolt_cam",
              "dolly_zoom",
              "overhead",
              "zoom_out",
              "handheld",
              "roll_left",
              "pov",
              "aerial_drone",
              "push_in",
              "crane_down",
              "truck_right",
              "tilt_down",
              "elevator_doors",
              "tilt_up",
              "ground_level",
              "pull_out",
              "aerial",
              "crane_up",
              "eye_level"
            ]
          }
        ],
        "concept3": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "truck_left",
              "pan_right",
              "pedestal_down",
              "low_angle",
              "pedestal_up",
              "selfie",
              "pan_left",
              "roll_right",
              "zoom_in",
              "over_the_shoulder",
              "orbit_right",
              "orbit_left",
              "static",
              "tiny_planet",
              "high_angle",
              "bolt_cam",
              "dolly_zoom",
              "overhead",
              "zoom_out",
              "handheld",
              "roll_left",
              "pov",
              "aerial_drone",
              "push_in",
              "crane_down",
              "truck_right",
              "tilt_down",
              "elevator_doors",
              "tilt_up",
              "ground_level",
              "pull_out",
              "aerial",
              "crane_up",
              "eye_level"
            ]
          }
        ],
        "concept4": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "truck_left",
              "pan_right",
              "pedestal_down",
              "low_angle",
              "pedestal_up",
              "selfie",
              "pan_left",
              "roll_right",
              "zoom_in",
              "over_the_shoulder",
              "orbit_right",
              "orbit_left",
              "static",
              "tiny_planet",
              "high_angle",
              "bolt_cam",
              "dolly_zoom",
              "overhead",
              "zoom_out",
              "handheld",
              "roll_left",
              "pov",
              "aerial_drone",
              "push_in",
              "crane_down",
              "truck_right",
              "tilt_down",
              "elevator_doors",
              "tilt_up",
              "ground_level",
              "pull_out",
              "aerial",
              "crane_up",
              "eye_level"
            ]
          }
        ]
      },
      "optional": {
        "luma_concepts": [
          "LUMA_CONCEPTS",
          {
            "tooltip": "Optional Camera Concepts to add to the ones chosen here."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "concept1",
        "concept2",
        "concept3",
        "concept4"
      ],
      "optional": [
        "luma_concepts"
      ]
    },
    "output": [
      "LUMA_CONCEPTS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "luma_concepts"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "LumaConceptsNode",
    "display_name": "Luma Concepts",
    "description": "Camera Concepts for use with Luma Text to Video and Luma Image to Video nodes.",
    "python_module": "comfy_api_nodes.nodes_luma",
    "category": "api node/video/Luma",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftTextToImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation.",
            "default": "",
            "multiline": true
          }
        ],
        "size": [
          "COMBO",
          {
            "tooltip": "The size of the generated image.",
            "default": "1024x1024",
            "multiselect": false,
            "options": [
              "1024x1024",
              "1365x1024",
              "1024x1365",
              "1536x1024",
              "1024x1536",
              "1820x1024",
              "1024x1820",
              "1024x2048",
              "2048x1024",
              "1434x1024",
              "1024x1434",
              "1024x1280",
              "1280x1024",
              "1024x1707",
              "1707x1024"
            ]
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "The number of images to generate.",
            "default": 1,
            "min": 1,
            "max": 6
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "recraft_style": [
          "RECRAFT_V3_STYLE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ],
        "recraft_controls": [
          "RECRAFT_CONTROLS",
          {
            "tooltip": "Optional additional controls over the generation via the Recraft Controls node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "size",
        "n",
        "seed"
      ],
      "optional": [
        "recraft_style",
        "negative_prompt",
        "recraft_controls"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftTextToImageNode",
    "display_name": "Recraft Text to Image",
    "description": "Generates images synchronously based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftImageToImageNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation.",
            "default": "",
            "multiline": true
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "The number of images to generate.",
            "default": 1,
            "min": 1,
            "max": 6
          }
        ],
        "strength": [
          "FLOAT",
          {
            "tooltip": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity.",
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "recraft_style": [
          "RECRAFT_V3_STYLE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ],
        "recraft_controls": [
          "RECRAFT_CONTROLS",
          {
            "tooltip": "Optional additional controls over the generation via the Recraft Controls node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "n",
        "strength",
        "seed"
      ],
      "optional": [
        "recraft_style",
        "negative_prompt",
        "recraft_controls"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftImageToImageNode",
    "display_name": "Recraft Image to Image",
    "description": "Modify image based on prompt and strength.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftImageInpaintingNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "mask": [
          "MASK",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation.",
            "default": "",
            "multiline": true
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "The number of images to generate.",
            "default": 1,
            "min": 1,
            "max": 6
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "recraft_style": [
          "RECRAFT_V3_STYLE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mask",
        "prompt",
        "n",
        "seed"
      ],
      "optional": [
        "recraft_style",
        "negative_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftImageInpaintingNode",
    "display_name": "Recraft Image Inpainting",
    "description": "Modify image based on prompt and mask.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftTextToVectorNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation.",
            "default": "",
            "multiline": true
          }
        ],
        "substyle": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "bold_stroke",
              "chemistry",
              "colored_stencil",
              "contour_pop_art",
              "cosmics",
              "cutout",
              "depressive",
              "editorial",
              "emotional_flat",
              "engraving",
              "infographical",
              "line_art",
              "line_circuit",
              "linocut",
              "marker_outline",
              "mosaic",
              "naivector",
              "roundish_flat",
              "seamless",
              "segmented_colors",
              "sharp_contrast",
              "thin",
              "vector_photo",
              "vivid_shapes"
            ]
          }
        ],
        "size": [
          "COMBO",
          {
            "tooltip": "The size of the generated image.",
            "default": "1024x1024",
            "multiselect": false,
            "options": [
              "1024x1024",
              "1365x1024",
              "1024x1365",
              "1536x1024",
              "1024x1536",
              "1820x1024",
              "1024x1820",
              "1024x2048",
              "2048x1024",
              "1434x1024",
              "1024x1434",
              "1024x1280",
              "1280x1024",
              "1024x1707",
              "1707x1024"
            ]
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "The number of images to generate.",
            "default": 1,
            "min": 1,
            "max": 6
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ],
        "recraft_controls": [
          "RECRAFT_CONTROLS",
          {
            "tooltip": "Optional additional controls over the generation via the Recraft Controls node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "substyle",
        "size",
        "n",
        "seed"
      ],
      "optional": [
        "negative_prompt",
        "recraft_controls"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "SVG"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SVG"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftTextToVectorNode",
    "display_name": "Recraft Text to Vector",
    "description": "Generates SVG synchronously based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftVectorizeImageNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "SVG"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SVG"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftVectorizeImageNode",
    "display_name": "Recraft Vectorize Image",
    "description": "Generates SVG synchronously from an input image.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftRemoveBackgroundNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftRemoveBackgroundNode",
    "display_name": "Recraft Remove Background",
    "description": "Remove background from image, and return processed image and mask.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftReplaceBackgroundNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the image generation.",
            "default": "",
            "multiline": true
          }
        ],
        "n": [
          "INT",
          {
            "tooltip": "The number of images to generate.",
            "default": 1,
            "min": 1,
            "max": 6
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "recraft_style": [
          "RECRAFT_V3_STYLE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "n",
        "seed"
      ],
      "optional": [
        "recraft_style",
        "negative_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftReplaceBackgroundNode",
    "display_name": "Recraft Replace Background",
    "description": "Replace background on image, based on provided prompt.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftCrispUpscaleNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftCrispUpscaleNode",
    "display_name": "Recraft Crisp Upscale Image",
    "description": "Upscale image synchronously.\nEnhances a given raster image using crisp upscale tool, increasing image resolution, making the image sharper and cleaner.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftCreativeUpscaleNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftCreativeUpscaleNode",
    "display_name": "Recraft Creative Upscale Image",
    "description": "Upscale image synchronously.\nEnhances a given raster image using creative upscale tool, boosting resolution with a focus on refining small details and faces.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RecraftStyleV3RealisticImage": {
    "input": {
      "required": {
        "substyle": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "b_and_w",
              "enterprise",
              "evening_light",
              "faded_nostalgia",
              "forest_life",
              "hard_flash",
              "hdr",
              "motion_blur",
              "mystic_naturalism",
              "natural_light",
              "natural_tones",
              "organic_calm",
              "real_life_glow",
              "retro_realism",
              "retro_snapshot",
              "studio_portrait",
              "urban_drama",
              "village_realism",
              "warm_folk"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "substyle"
      ]
    },
    "output": [
      "RECRAFT_V3_STYLE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_style"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftStyleV3RealisticImage",
    "display_name": "Recraft Style - Realistic Image",
    "description": "Select realistic_image style and optional substyle.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftStyleV3DigitalIllustration": {
    "input": {
      "required": {
        "substyle": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "None",
              "2d_art_poster",
              "2d_art_poster_2",
              "antiquarian",
              "bold_fantasy",
              "child_book",
              "child_books",
              "cover",
              "crosshatch",
              "digital_engraving",
              "engraving_color",
              "expressionism",
              "freehand_details",
              "grain",
              "grain_20",
              "graphic_intensity",
              "hand_drawn",
              "hand_drawn_outline",
              "handmade_3d",
              "hard_comics",
              "infantile_sketch",
              "long_shadow",
              "modern_folk",
              "multicolor",
              "neon_calm",
              "noir",
              "nostalgic_pastel",
              "outline_details",
              "pastel_gradient",
              "pastel_sketch",
              "pixel_art",
              "plastic",
              "pop_art",
              "pop_renaissance",
              "seamless",
              "street_art",
              "tablet_sketch",
              "urban_glow",
              "urban_sketching",
              "vanilla_dreams",
              "young_adult_book",
              "young_adult_book_2"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "substyle"
      ]
    },
    "output": [
      "RECRAFT_V3_STYLE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_style"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftStyleV3DigitalIllustration",
    "display_name": "Recraft Style - Digital Illustration",
    "description": "Select realistic_image style and optional substyle.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftStyleV3LogoRaster": {
    "input": {
      "required": {
        "substyle": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "emblem_graffiti",
              "emblem_pop_art",
              "emblem_punk",
              "emblem_stamp",
              "emblem_vintage"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "substyle"
      ]
    },
    "output": [
      "RECRAFT_V3_STYLE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_style"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftStyleV3LogoRaster",
    "display_name": "Recraft Style - Logo Raster",
    "description": "Select realistic_image style and optional substyle.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftStyleV3InfiniteStyleLibrary": {
    "input": {
      "required": {
        "style_id": [
          "STRING",
          {
            "tooltip": "UUID of style from Infinite Style Library.",
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "style_id"
      ]
    },
    "output": [
      "RECRAFT_V3_STYLE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_style"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftStyleV3InfiniteStyleLibrary",
    "display_name": "Recraft Style - Infinite Style Library",
    "description": "Select style based on preexisting UUID from Recraft's Infinite Style Library.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftColorRGB": {
    "input": {
      "required": {
        "r": [
          "INT",
          {
            "tooltip": "Red value of color.",
            "default": 0,
            "min": 0,
            "max": 255
          }
        ],
        "g": [
          "INT",
          {
            "tooltip": "Green value of color.",
            "default": 0,
            "min": 0,
            "max": 255
          }
        ],
        "b": [
          "INT",
          {
            "tooltip": "Blue value of color.",
            "default": 0,
            "min": 0,
            "max": 255
          }
        ]
      },
      "optional": {
        "recraft_color": [
          "RECRAFT_COLOR",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "r",
        "g",
        "b"
      ],
      "optional": [
        "recraft_color"
      ]
    },
    "output": [
      "RECRAFT_COLOR"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_color"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftColorRGB",
    "display_name": "Recraft Color RGB",
    "description": "Create Recraft Color by choosing specific RGB values.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "RecraftControls": {
    "input": {
      "required": {},
      "optional": {
        "colors": [
          "RECRAFT_COLOR",
          {}
        ],
        "background_color": [
          "RECRAFT_COLOR",
          {}
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "colors",
        "background_color"
      ]
    },
    "output": [
      "RECRAFT_CONTROLS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "recraft_controls"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RecraftControls",
    "display_name": "Recraft Controls",
    "description": "Create Recraft Controls for customizing Recraft generation.",
    "python_module": "comfy_api_nodes.nodes_recraft",
    "category": "api node/image/Recraft",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "PixverseTextToVideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "16:9",
              "4:3",
              "1:1",
              "3:4",
              "9:16"
            ]
          }
        ],
        "quality": [
          "COMBO",
          {
            "default": "540p",
            "multiselect": false,
            "options": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ]
          }
        ],
        "duration_seconds": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              8
            ]
          }
        ],
        "motion_mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "normal",
              "fast"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "multiline": true
          }
        ],
        "pixverse_template": [
          "PIXVERSE_TEMPLATE",
          {
            "tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio",
        "quality",
        "duration_seconds",
        "motion_mode",
        "seed"
      ],
      "optional": [
        "negative_prompt",
        "pixverse_template"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PixverseTextToVideoNode",
    "display_name": "PixVerse Text to Video",
    "description": "Generates videos based on prompt and output_size.",
    "python_module": "comfy_api_nodes.nodes_pixverse",
    "category": "api node/video/PixVerse",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "PixverseImageToVideoNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "quality": [
          "COMBO",
          {
            "default": "540p",
            "multiselect": false,
            "options": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ]
          }
        ],
        "duration_seconds": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              8
            ]
          }
        ],
        "motion_mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "normal",
              "fast"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "multiline": true
          }
        ],
        "pixverse_template": [
          "PIXVERSE_TEMPLATE",
          {
            "tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "quality",
        "duration_seconds",
        "motion_mode",
        "seed"
      ],
      "optional": [
        "negative_prompt",
        "pixverse_template"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PixverseImageToVideoNode",
    "display_name": "PixVerse Image to Video",
    "description": "Generates videos based on prompt and output_size.",
    "python_module": "comfy_api_nodes.nodes_pixverse",
    "category": "api node/video/PixVerse",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "PixverseTransitionVideoNode": {
    "input": {
      "required": {
        "first_frame": [
          "IMAGE",
          {}
        ],
        "last_frame": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt for the video generation",
            "default": "",
            "multiline": true
          }
        ],
        "quality": [
          "COMBO",
          {
            "default": "540p",
            "multiselect": false,
            "options": [
              "360p",
              "540p",
              "720p",
              "1080p"
            ]
          }
        ],
        "duration_seconds": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              8
            ]
          }
        ],
        "motion_mode": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "normal",
              "fast"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "An optional text description of undesired elements on an image.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "first_frame",
        "last_frame",
        "prompt",
        "quality",
        "duration_seconds",
        "motion_mode",
        "seed"
      ],
      "optional": [
        "negative_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PixverseTransitionVideoNode",
    "display_name": "PixVerse Transition Video",
    "description": "Generates videos based on prompt and output_size.",
    "python_module": "comfy_api_nodes.nodes_pixverse",
    "category": "api node/video/PixVerse",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "PixverseTemplateNode": {
    "input": {
      "required": {
        "template": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "Microwave",
              "Suit Swagger",
              "Anything, Robot",
              "Subject 3 Fever",
              "kiss kiss"
            ]
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "template"
      ]
    },
    "output": [
      "PIXVERSE_TEMPLATE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "pixverse_template"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PixverseTemplateNode",
    "display_name": "PixVerse Template",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_pixverse",
    "category": "api node/video/PixVerse",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "StabilityStableImageUltraNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defineselements, colors, and subjects will lead to better results. To control the weight of a given word use the format `(word:weight)`,where `word` is the word you'd like to control the weight of and `weight`is a value between 0 and 1. For example: `The sky was a crisp (blue:0.3) and (green:0.8)`would convey a sky that was blue and green, but more green than blue.",
            "default": "",
            "multiline": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Aspect ratio of generated image.",
            "default": "1:1",
            "multiselect": false,
            "options": [
              "1:1",
              "16:9",
              "9:16",
              "3:2",
              "2:3",
              "5:4",
              "4:5",
              "21:9",
              "9:21"
            ]
          }
        ],
        "style_preset": [
          "COMBO",
          {
            "tooltip": "Optional desired style of generated image.",
            "multiselect": false,
            "options": [
              "None",
              "3d-model",
              "analog-film",
              "anime",
              "cinematic",
              "comic-book",
              "digital-art",
              "enhance",
              "fantasy-art",
              "isometric",
              "line-art",
              "low-poly",
              "modeling-compound",
              "neon-punk",
              "origami",
              "photographic",
              "pixel-art",
              "tile-texture"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "A blurb of text describing what you do not wish to see in the output image. This is an advanced feature.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ],
        "image_denoise": [
          "FLOAT",
          {
            "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.",
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "aspect_ratio",
        "style_preset",
        "seed"
      ],
      "optional": [
        "image",
        "negative_prompt",
        "image_denoise"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityStableImageUltraNode",
    "display_name": "Stability AI Stable Image Ultra",
    "description": "Generates images synchronously based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/image/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityStableImageSD_3_5Node": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "sd3.5-large",
              "sd3.5-medium"
            ]
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Aspect ratio of generated image.",
            "default": "1:1",
            "multiselect": false,
            "options": [
              "1:1",
              "16:9",
              "9:16",
              "3:2",
              "2:3",
              "5:4",
              "4:5",
              "21:9",
              "9:21"
            ]
          }
        ],
        "style_preset": [
          "COMBO",
          {
            "tooltip": "Optional desired style of generated image.",
            "multiselect": false,
            "options": [
              "None",
              "3d-model",
              "analog-film",
              "anime",
              "cinematic",
              "comic-book",
              "digital-art",
              "enhance",
              "fantasy-art",
              "isometric",
              "line-art",
              "low-poly",
              "modeling-compound",
              "neon-punk",
              "origami",
              "photographic",
              "pixel-art",
              "tile-texture"
            ]
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "tooltip": "How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)",
            "default": 4.0,
            "min": 1.0,
            "max": 10.0,
            "step": 0.1
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {}
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ],
        "image_denoise": [
          "FLOAT",
          {
            "tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.",
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "aspect_ratio",
        "style_preset",
        "cfg_scale",
        "seed"
      ],
      "optional": [
        "image",
        "negative_prompt",
        "image_denoise"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityStableImageSD_3_5Node",
    "display_name": "Stability AI Stable Diffusion 3.5 Image",
    "description": "Generates images synchronously based on prompt and resolution.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/image/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityUpscaleConservativeNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.",
            "default": "",
            "multiline": true
          }
        ],
        "creativity": [
          "FLOAT",
          {
            "tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.",
            "default": 0.35,
            "min": 0.2,
            "max": 0.5,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "creativity",
        "seed"
      ],
      "optional": [
        "negative_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityUpscaleConservativeNode",
    "display_name": "Stability AI Upscale Conservative",
    "description": "Upscale image with minimal alterations to 4K resolution.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/image/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityUpscaleCreativeNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.",
            "default": "",
            "multiline": true
          }
        ],
        "creativity": [
          "FLOAT",
          {
            "tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.",
            "default": 0.3,
            "min": 0.1,
            "max": 0.5,
            "step": 0.01
          }
        ],
        "style_preset": [
          "COMBO",
          {
            "tooltip": "Optional desired style of generated image.",
            "multiselect": false,
            "options": [
              "None",
              "3d-model",
              "analog-film",
              "anime",
              "cinematic",
              "comic-book",
              "digital-art",
              "enhance",
              "fantasy-art",
              "isometric",
              "line-art",
              "low-poly",
              "modeling-compound",
              "neon-punk",
              "origami",
              "photographic",
              "pixel-art",
              "tile-texture"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for creating the noise.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.",
            "default": "",
            "forceInput": true,
            "multiline": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "creativity",
        "style_preset",
        "seed"
      ],
      "optional": [
        "negative_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityUpscaleCreativeNode",
    "display_name": "Stability AI Upscale Creative",
    "description": "Upscale image with minimal alterations to 4K resolution.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/image/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityUpscaleFastNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityUpscaleFastNode",
    "display_name": "Stability AI Upscale Fast",
    "description": "Quickly upscales an image via Stability API call to 4x its original size; intended for upscaling low-quality/compressed images.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/image/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityTextToAudio": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "stable-audio-2.5"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "duration": [
          "INT",
          {
            "tooltip": "Controls the duration in seconds of the generated audio.",
            "default": 190,
            "min": 1,
            "max": 190,
            "step": 1
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for generation.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Controls the number of sampling steps.",
            "default": 8,
            "min": 4,
            "max": 8,
            "step": 1
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt"
      ],
      "optional": [
        "duration",
        "seed",
        "steps"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityTextToAudio",
    "display_name": "Stability AI Text To Audio",
    "description": "Generates high-quality music and sound effects from text descriptions.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/audio/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityAudioToAudio": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "stable-audio-2.5"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "audio": [
          "AUDIO",
          {
            "tooltip": "Audio must be between 6 and 190 seconds long."
          }
        ]
      },
      "optional": {
        "duration": [
          "INT",
          {
            "tooltip": "Controls the duration in seconds of the generated audio.",
            "default": 190,
            "min": 1,
            "max": 190,
            "step": 1
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for generation.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Controls the number of sampling steps.",
            "default": 8,
            "min": 4,
            "max": 8,
            "step": 1
          }
        ],
        "strength": [
          "FLOAT",
          {
            "tooltip": "Parameter controls how much influence the audio parameter has on the generated audio.",
            "default": 1,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01,
            "display": "slider"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "audio"
      ],
      "optional": [
        "duration",
        "seed",
        "steps",
        "strength"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityAudioToAudio",
    "display_name": "Stability AI Audio To Audio",
    "description": "Transforms existing audio samples into new high-quality compositions using text instructions.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/audio/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "StabilityAudioInpaint": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "stable-audio-2.5"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "audio": [
          "AUDIO",
          {
            "tooltip": "Audio must be between 6 and 190 seconds long."
          }
        ]
      },
      "optional": {
        "duration": [
          "INT",
          {
            "tooltip": "Controls the duration in seconds of the generated audio.",
            "default": 190,
            "min": 1,
            "max": 190,
            "step": 1
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "The random seed used for generation.",
            "default": 0,
            "min": 0,
            "max": 4294967294,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Controls the number of sampling steps.",
            "default": 8,
            "min": 4,
            "max": 8,
            "step": 1
          }
        ],
        "mask_start": [
          "INT",
          {
            "default": 30,
            "min": 0,
            "max": 190,
            "step": 1
          }
        ],
        "mask_end": [
          "INT",
          {
            "default": 190,
            "min": 0,
            "max": 190,
            "step": 1
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "audio"
      ],
      "optional": [
        "duration",
        "seed",
        "steps",
        "mask_start",
        "mask_end"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "AUDIO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "StabilityAudioInpaint",
    "display_name": "Stability AI Audio Inpaint",
    "description": "Transforms part of existing audio sample using text instructions.",
    "python_module": "comfy_api_nodes.nodes_stability",
    "category": "api node/audio/Stability AI",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "PikaImageToVideoNode2_2": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "The image to convert to video"
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p",
              "720p"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 5,
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt_text",
        "negative_prompt",
        "seed",
        "resolution",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PikaImageToVideoNode2_2",
    "display_name": "Pika Image to Video",
    "description": "Sends an image and prompt to the Pika API v2.2 to generate a video.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "PikaTextToVideoNode2_2": {
    "input": {
      "required": {
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p",
              "720p"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 5,
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ],
        "aspect_ratio": [
          "FLOAT",
          {
            "tooltip": "Aspect ratio (width / height)",
            "default": 1.7777777777777777,
            "min": 0.4,
            "max": 2.5,
            "step": 0.001
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_text",
        "negative_prompt",
        "seed",
        "resolution",
        "duration",
        "aspect_ratio"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PikaTextToVideoNode2_2",
    "display_name": "Pika Text to Video",
    "description": "Sends a text prompt to the Pika API v2.2 to generate a video.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "PikaScenesV2_2": {
    "input": {
      "required": {
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p",
              "720p"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 5,
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ],
        "ingredients_mode": [
          "COMBO",
          {
            "default": "creative",
            "multiselect": false,
            "options": [
              "creative",
              "precise"
            ]
          }
        ],
        "aspect_ratio": [
          "FLOAT",
          {
            "tooltip": "Aspect ratio (width / height)",
            "default": 1.7777777777777777,
            "min": 0.4,
            "max": 2.5,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "image_ingredient_1": [
          "IMAGE",
          {
            "tooltip": "Image that will be used as ingredient to create a video."
          }
        ],
        "image_ingredient_2": [
          "IMAGE",
          {
            "tooltip": "Image that will be used as ingredient to create a video."
          }
        ],
        "image_ingredient_3": [
          "IMAGE",
          {
            "tooltip": "Image that will be used as ingredient to create a video."
          }
        ],
        "image_ingredient_4": [
          "IMAGE",
          {
            "tooltip": "Image that will be used as ingredient to create a video."
          }
        ],
        "image_ingredient_5": [
          "IMAGE",
          {
            "tooltip": "Image that will be used as ingredient to create a video."
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_text",
        "negative_prompt",
        "seed",
        "resolution",
        "duration",
        "ingredients_mode",
        "aspect_ratio"
      ],
      "optional": [
        "image_ingredient_1",
        "image_ingredient_2",
        "image_ingredient_3",
        "image_ingredient_4",
        "image_ingredient_5"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PikaScenesV2_2",
    "display_name": "Pika Scenes (Video Image Composition)",
    "description": "Combine your images to create a video with the objects in them. Upload multiple images as ingredients and generate a high-quality video that incorporates all of them.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "Pikadditions": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {
            "tooltip": "The video to add an image to."
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "The image to add to the video."
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "video",
        "image",
        "prompt_text",
        "negative_prompt",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Pikadditions",
    "display_name": "Pikadditions (Video Object Insertion)",
    "description": "Add any object or image into your video. Upload a video and specify what you'd like to add to create a seamlessly integrated result.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "Pikaswaps": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {
            "tooltip": "The video to swap an object in."
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {
            "tooltip": "The image used to replace the masked object in the video."
          }
        ],
        "mask": [
          "MASK",
          {
            "tooltip": "Use the mask to define areas in the video to replace."
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ],
        "region_to_modify": [
          "STRING",
          {
            "tooltip": "Plaintext description of the object / region to modify.",
            "multiline": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "video"
      ],
      "optional": [
        "image",
        "mask",
        "prompt_text",
        "negative_prompt",
        "seed",
        "region_to_modify"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Pikaswaps",
    "display_name": "Pika Swaps (Video Object Replacement)",
    "description": "Swap out any object or region of your video with a new image or object. Define areas to replace either with a mask or coordinates.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "Pikaffects": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "The reference image to apply the Pikaffect to."
          }
        ],
        "pikaffect": [
          "COMBO",
          {
            "default": "Cake-ify",
            "multiselect": false,
            "options": [
              "Cake-ify",
              "Crumble",
              "Crush",
              "Decapitate",
              "Deflate",
              "Dissolve",
              "Explode",
              "Eye-pop",
              "Inflate",
              "Levitate",
              "Melt",
              "Peel",
              "Poke",
              "Squish",
              "Ta-da",
              "Tear"
            ]
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "pikaffect",
        "prompt_text",
        "negative_prompt",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Pikaffects",
    "display_name": "Pikaffects (Video Effects)",
    "description": "Generate a video with a specific Pikaffect. Supported Pikaffects: Cake-ify, Crumble, Crush, Decapitate, Deflate, Dissolve, Explode, Eye-pop, Inflate, Levitate, Melt, Peel, Poke, Squish, Ta-da, Tear",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "PikaStartEndFrameNode2_2": {
    "input": {
      "required": {
        "image_start": [
          "IMAGE",
          {
            "tooltip": "The first image to combine."
          }
        ],
        "image_end": [
          "IMAGE",
          {
            "tooltip": "The last image to combine."
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "min": 0,
            "max": 4294967295,
            "control_after_generate": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p",
              "720p"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 5,
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image_start",
        "image_end",
        "prompt_text",
        "negative_prompt",
        "seed",
        "resolution",
        "duration"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "PikaStartEndFrameNode2_2",
    "display_name": "Pika Start and End Frame to Video",
    "description": "Generate a video by combining your first and last frame. Upload two images to define the start and end points, and let the AI create a smooth transition between them.",
    "python_module": "comfy_api_nodes.nodes_pika",
    "category": "api node/video/Pika",
    "output_node": false,
    "deprecated": true,
    "experimental": false,
    "api_node": true
  },
  "RunwayFirstLastFrameNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for the generation",
            "default": "",
            "multiline": true
          }
        ],
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "Start frame to be used for the video"
          }
        ],
        "end_frame": [
          "IMAGE",
          {
            "tooltip": "End frame to be used for the video. Supported for gen3a_turbo only."
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ],
        "ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "768:1280",
              "1280:768"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed for generation",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "start_frame",
        "end_frame",
        "duration",
        "ratio",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RunwayFirstLastFrameNode",
    "display_name": "Runway First-Last-Frame to Video",
    "description": "Upload first and last keyframes, draft a prompt, and generate a video. More complex transitions, such as cases where the Last frame is completely different from the First frame, may benefit from the longer 10s duration. This would give the generation more time to smoothly transition between the two inputs. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/34170748696595-Creating-with-Keyframes-on-Gen-3.",
    "python_module": "comfy_api_nodes.nodes_runway",
    "category": "api node/video/Runway",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RunwayImageToVideoNodeGen3a": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for the generation",
            "default": "",
            "multiline": true
          }
        ],
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "Start frame to be used for the video"
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ],
        "ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "768:1280",
              "1280:768"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed for generation",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "start_frame",
        "duration",
        "ratio",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RunwayImageToVideoNodeGen3a",
    "display_name": "Runway Image to Video (Gen3a Turbo)",
    "description": "Generate a video from a single starting frame using Gen3a Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/33927968552339-Creating-with-Act-One-on-Gen-3-Alpha-and-Turbo.",
    "python_module": "comfy_api_nodes.nodes_runway",
    "category": "api node/video/Runway",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RunwayImageToVideoNodeGen4": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for the generation",
            "default": "",
            "multiline": true
          }
        ],
        "start_frame": [
          "IMAGE",
          {
            "tooltip": "Start frame to be used for the video"
          }
        ],
        "duration": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              5,
              10
            ]
          }
        ],
        "ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "1280:720",
              "720:1280",
              "1104:832",
              "832:1104",
              "960:960",
              "1584:672"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed for generation",
            "default": 0,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "start_frame",
        "duration",
        "ratio",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RunwayImageToVideoNodeGen4",
    "display_name": "Runway Image to Video (Gen4 Turbo)",
    "description": "Generate a video from a single starting frame using Gen4 Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/37327109429011-Creating-with-Gen-4-Video.",
    "python_module": "comfy_api_nodes.nodes_runway",
    "category": "api node/video/Runway",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "RunwayTextToImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for the generation",
            "default": "",
            "multiline": true
          }
        ],
        "ratio": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "1920:1080",
              "1080:1920",
              "1024:1024",
              "1360:768",
              "1080:1080",
              "1168:880",
              "1440:1080",
              "1080:1440",
              "1808:768",
              "2112:912"
            ]
          }
        ]
      },
      "optional": {
        "reference_image": [
          "IMAGE",
          {
            "tooltip": "Optional reference image to guide the generation"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "ratio"
      ],
      "optional": [
        "reference_image"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "RunwayTextToImageNode",
    "display_name": "Runway Text to Image",
    "description": "Generate an image from a text prompt using Runway's Gen 4 model. You can also include reference image to guide the generation.",
    "python_module": "comfy_api_nodes.nodes_runway",
    "category": "api node/image/Runway",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "OpenAIVideoSora2": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "default": "sora-2",
            "multiselect": false,
            "options": [
              "sora-2",
              "sora-2-pro"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Guiding text; may be empty if an input image is present.",
            "default": "",
            "multiline": true
          }
        ],
        "size": [
          "COMBO",
          {
            "default": "1280x720",
            "multiselect": false,
            "options": [
              "720x1280",
              "1280x720",
              "1024x1792",
              "1792x1024"
            ]
          }
        ],
        "duration": [
          "COMBO",
          {
            "default": 8,
            "multiselect": false,
            "options": [
              4,
              8,
              12
            ]
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE",
          {}
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt",
        "size",
        "duration"
      ],
      "optional": [
        "image",
        "seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "OpenAIVideoSora2",
    "display_name": "OpenAI Sora - Video",
    "description": "OpenAI video and audio generation.",
    "python_module": "comfy_api_nodes.nodes_sora",
    "category": "api node/video/Sora",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TopazImageEnhance": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "Reimagine"
            ]
          }
        ],
        "image": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Optional text prompt for creative upscaling guidance.",
            "default": "",
            "multiline": true
          }
        ],
        "subject_detection": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "All",
              "Foreground",
              "Background"
            ]
          }
        ],
        "face_enhancement": [
          "BOOLEAN",
          {
            "tooltip": "Enhance faces (if present) during processing.",
            "default": true
          }
        ],
        "face_enhancement_creativity": [
          "FLOAT",
          {
            "tooltip": "Set the creativity level for face enhancement.",
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "display": "number"
          }
        ],
        "face_enhancement_strength": [
          "FLOAT",
          {
            "tooltip": "Controls how sharp enhanced faces are relative to the background.",
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "display": "number"
          }
        ],
        "crop_to_fill": [
          "BOOLEAN",
          {
            "tooltip": "By default, the image is letterboxed when the output aspect ratio differs. Enable to crop the image to fill the output dimensions.",
            "default": false
          }
        ],
        "output_width": [
          "INT",
          {
            "tooltip": "Zero value means to calculate automatically (usually it will be original size or output_height if specified).",
            "default": 0,
            "min": 0,
            "max": 32000,
            "step": 1,
            "display": "number"
          }
        ],
        "output_height": [
          "INT",
          {
            "tooltip": "Zero value means to output in the same height as original or output width.",
            "default": 0,
            "min": 0,
            "max": 32000,
            "step": 1,
            "display": "number"
          }
        ],
        "creativity": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 9,
            "step": 1,
            "display": "slider"
          }
        ],
        "face_preservation": [
          "BOOLEAN",
          {
            "tooltip": "Preserve subjects' facial identity.",
            "default": true
          }
        ],
        "color_preservation": [
          "BOOLEAN",
          {
            "tooltip": "Preserve the original colors.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "image"
      ],
      "optional": [
        "prompt",
        "subject_detection",
        "face_enhancement",
        "face_enhancement_creativity",
        "face_enhancement_strength",
        "crop_to_fill",
        "output_width",
        "output_height",
        "creativity",
        "face_preservation",
        "color_preservation"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TopazImageEnhance",
    "display_name": "Topaz Image Enhance",
    "description": "Industry-standard upscaling and image enhancement.",
    "python_module": "comfy_api_nodes.nodes_topaz",
    "category": "api node/image/Topaz",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TopazVideoEnhance": {
    "input": {
      "required": {
        "video": [
          "VIDEO",
          {}
        ],
        "upscaler_enabled": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "upscaler_model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "Starlight (Astra) Fast",
              "Starlight (Astra) Creative"
            ]
          }
        ],
        "upscaler_resolution": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "FullHD (1080p)",
              "4K (2160p)"
            ]
          }
        ]
      },
      "optional": {
        "upscaler_creativity": [
          "COMBO",
          {
            "tooltip": "Creativity level (applies only to Starlight (Astra) Creative).",
            "default": "low",
            "multiselect": false,
            "options": [
              "low",
              "middle",
              "high"
            ]
          }
        ],
        "interpolation_enabled": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "interpolation_model": [
          "COMBO",
          {
            "default": "apo-8",
            "multiselect": false,
            "options": [
              "apo-8"
            ]
          }
        ],
        "interpolation_slowmo": [
          "INT",
          {
            "tooltip": "Slow-motion factor applied to the input video. For example, 2 makes the output twice as slow and doubles the duration.",
            "default": 1,
            "min": 1,
            "max": 16,
            "display": "number"
          }
        ],
        "interpolation_frame_rate": [
          "INT",
          {
            "tooltip": "Output frame rate.",
            "default": 60,
            "min": 15,
            "max": 240,
            "display": "number"
          }
        ],
        "interpolation_duplicate": [
          "BOOLEAN",
          {
            "tooltip": "Analyze the input for duplicate frames and remove them.",
            "default": false
          }
        ],
        "interpolation_duplicate_threshold": [
          "FLOAT",
          {
            "tooltip": "Detection sensitivity for duplicate frames.",
            "default": 0.01,
            "min": 0.001,
            "max": 0.1,
            "step": 0.001,
            "display": "number"
          }
        ],
        "dynamic_compression_level": [
          "COMBO",
          {
            "tooltip": "CQP level.",
            "default": "Low",
            "multiselect": false,
            "options": [
              "Low",
              "Mid",
              "High"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "video",
        "upscaler_enabled",
        "upscaler_model",
        "upscaler_resolution"
      ],
      "optional": [
        "upscaler_creativity",
        "interpolation_enabled",
        "interpolation_model",
        "interpolation_slowmo",
        "interpolation_frame_rate",
        "interpolation_duplicate",
        "interpolation_duplicate_threshold",
        "dynamic_compression_level"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "TopazVideoEnhance",
    "display_name": "Topaz Video Enhance",
    "description": "Breathe new life into video with powerful upscaling and recovery technology.",
    "python_module": "comfy_api_nodes.nodes_topaz",
    "category": "api node/video/Topaz",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoTextToModelNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "multiline": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "model_version": [
          "COMBO",
          {
            "default": "v2.5-20250123",
            "multiselect": false,
            "options": [
              "v2.5-20250123",
              "v2.0-20240919",
              "v1.4-20240625"
            ]
          }
        ],
        "style": [
          "COMBO",
          {
            "default": "None",
            "multiselect": false,
            "options": [
              "person:person2cartoon",
              "animal:venom",
              "object:clay",
              "object:steampunk",
              "object:christmas",
              "object:barbie",
              "gold",
              "ancient_bronze",
              "None"
            ]
          }
        ],
        "texture": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "pbr": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "image_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "model_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_quality": [
          "COMBO",
          {
            "default": "standard",
            "multiselect": false,
            "options": [
              "standard",
              "detailed"
            ]
          }
        ],
        "face_limit": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 500000
          }
        ],
        "quad": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "negative_prompt",
        "model_version",
        "style",
        "texture",
        "pbr",
        "image_seed",
        "model_seed",
        "texture_seed",
        "texture_quality",
        "face_limit",
        "quad"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "MODEL_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "model task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoTextToModelNode",
    "display_name": "Tripo: Text to Model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoImageToModelNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "model_version": [
          "COMBO",
          {
            "tooltip": "The model version to use for generation",
            "multiselect": false,
            "options": [
              "v2.5-20250123",
              "v2.0-20240919",
              "v1.4-20240625"
            ]
          }
        ],
        "style": [
          "COMBO",
          {
            "default": "None",
            "multiselect": false,
            "options": [
              "person:person2cartoon",
              "animal:venom",
              "object:clay",
              "object:steampunk",
              "object:christmas",
              "object:barbie",
              "gold",
              "ancient_bronze",
              "None"
            ]
          }
        ],
        "texture": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "pbr": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "model_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "orientation": [
          "COMBO",
          {
            "default": "default",
            "multiselect": false,
            "options": [
              "align_image",
              "default"
            ]
          }
        ],
        "texture_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_quality": [
          "COMBO",
          {
            "default": "standard",
            "multiselect": false,
            "options": [
              "standard",
              "detailed"
            ]
          }
        ],
        "texture_alignment": [
          "COMBO",
          {
            "default": "original_image",
            "multiselect": false,
            "options": [
              "original_image",
              "geometry"
            ]
          }
        ],
        "face_limit": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 500000
          }
        ],
        "quad": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "model_version",
        "style",
        "texture",
        "pbr",
        "model_seed",
        "orientation",
        "texture_seed",
        "texture_quality",
        "texture_alignment",
        "face_limit",
        "quad"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "MODEL_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "model task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoImageToModelNode",
    "display_name": "Tripo: Image to Model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoMultiviewToModelNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "image_left": [
          "IMAGE",
          {}
        ],
        "image_back": [
          "IMAGE",
          {}
        ],
        "image_right": [
          "IMAGE",
          {}
        ],
        "model_version": [
          "COMBO",
          {
            "tooltip": "The model version to use for generation",
            "multiselect": false,
            "options": [
              "v2.5-20250123",
              "v2.0-20240919",
              "v1.4-20240625"
            ]
          }
        ],
        "orientation": [
          "COMBO",
          {
            "default": "default",
            "multiselect": false,
            "options": [
              "align_image",
              "default"
            ]
          }
        ],
        "texture": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "pbr": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "model_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_quality": [
          "COMBO",
          {
            "default": "standard",
            "multiselect": false,
            "options": [
              "standard",
              "detailed"
            ]
          }
        ],
        "texture_alignment": [
          "COMBO",
          {
            "default": "original_image",
            "multiselect": false,
            "options": [
              "original_image",
              "geometry"
            ]
          }
        ],
        "face_limit": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 500000
          }
        ],
        "quad": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "image_left",
        "image_back",
        "image_right",
        "model_version",
        "orientation",
        "texture",
        "pbr",
        "model_seed",
        "texture_seed",
        "texture_quality",
        "texture_alignment",
        "face_limit",
        "quad"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "MODEL_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "model task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoMultiviewToModelNode",
    "display_name": "Tripo: Multiview to Model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoTextureNode": {
    "input": {
      "required": {
        "model_task_id": [
          "MODEL_TASK_ID",
          {}
        ]
      },
      "optional": {
        "texture": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "pbr": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "texture_seed": [
          "INT",
          {
            "default": 42
          }
        ],
        "texture_quality": [
          "COMBO",
          {
            "default": "standard",
            "multiselect": false,
            "options": [
              "standard",
              "detailed"
            ]
          }
        ],
        "texture_alignment": [
          "COMBO",
          {
            "default": "original_image",
            "multiselect": false,
            "options": [
              "original_image",
              "geometry"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_task_id"
      ],
      "optional": [
        "texture",
        "pbr",
        "texture_seed",
        "texture_quality",
        "texture_alignment"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "MODEL_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "model task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoTextureNode",
    "display_name": "Tripo: Texture model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoRefineNode": {
    "input": {
      "required": {
        "model_task_id": [
          "MODEL_TASK_ID",
          {
            "tooltip": "Must be a v1.4 Tripo model"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_task_id"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "MODEL_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "model task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoRefineNode",
    "display_name": "Tripo: Refine Draft model",
    "description": "Refine a draft model created by v1.4 Tripo models only.",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoRigNode": {
    "input": {
      "required": {
        "original_model_task_id": [
          "MODEL_TASK_ID",
          {}
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "original_model_task_id"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "RIG_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "rig task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoRigNode",
    "display_name": "Tripo: Rig model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoRetargetNode": {
    "input": {
      "required": {
        "original_model_task_id": [
          "RIG_TASK_ID",
          {}
        ],
        "animation": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "preset:idle",
              "preset:walk",
              "preset:climb",
              "preset:jump",
              "preset:slash",
              "preset:shoot",
              "preset:hurt",
              "preset:fall",
              "preset:turn"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "original_model_task_id",
        "animation"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "STRING",
      "RETARGET_TASK_ID"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model_file",
      "retarget task_id"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "TripoRetargetNode",
    "display_name": "Tripo: Retarget rigged model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "TripoConversionNode": {
    "input": {
      "required": {
        "original_model_task_id": [
          "MODEL_TASK_ID,RIG_TASK_ID,RETARGET_TASK_ID",
          {}
        ],
        "format": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "GLTF",
              "USDZ",
              "FBX",
              "OBJ",
              "STL",
              "3MF"
            ]
          }
        ]
      },
      "optional": {
        "quad": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "face_limit": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 500000
          }
        ],
        "texture_size": [
          "INT",
          {
            "default": 4096,
            "min": 128,
            "max": 4096
          }
        ],
        "texture_format": [
          "COMBO",
          {
            "default": "JPEG",
            "multiselect": false,
            "options": [
              "BMP",
              "DPX",
              "HDR",
              "JPEG",
              "OPEN_EXR",
              "PNG",
              "TARGA",
              "TIFF",
              "WEBP"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ],
        "prompt": [
          "PROMPT"
        ],
        "extra_pnginfo": [
          "EXTRA_PNGINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "original_model_task_id",
        "format"
      ],
      "optional": [
        "quad",
        "face_limit",
        "texture_size",
        "texture_format"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id",
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "output_tooltips": [],
    "output_matchtypes": null,
    "name": "TripoConversionNode",
    "display_name": "Tripo: Convert model",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_tripo",
    "category": "api node/3d/Tripo",
    "output_node": true,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "MoonvalleyImg2VideoNode": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "The reference image used to generate the video"
          }
        ],
        "prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative prompt text",
            "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Resolution of the output video",
            "default": "16:9 (1920 x 1080)",
            "multiselect": false,
            "options": [
              "16:9 (1920 x 1080)",
              "9:16 (1080 x 1920)",
              "1:1 (1152 x 1152)",
              "4:3 (1536 x 1152)",
              "3:4 (1152 x 1536)"
            ]
          }
        ],
        "prompt_adherence": [
          "FLOAT",
          {
            "tooltip": "Guidance scale for generation control",
            "default": 4.5,
            "min": 1.0,
            "max": 20.0,
            "step": 1.0
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed value",
            "default": 9,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of denoising steps",
            "default": 33,
            "min": 1,
            "max": 100,
            "step": 1
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "prompt",
        "negative_prompt",
        "resolution",
        "prompt_adherence",
        "seed",
        "steps"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MoonvalleyImg2VideoNode",
    "display_name": "Moonvalley Marey Image to Video",
    "description": "Moonvalley Marey Image to Video Node",
    "python_module": "comfy_api_nodes.nodes_moonvalley",
    "category": "api node/video/Moonvalley Marey",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "MoonvalleyTxt2VideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative prompt text",
            "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Resolution of the output video",
            "default": "16:9 (1920 x 1080)",
            "multiselect": false,
            "options": [
              "16:9 (1920 x 1080)",
              "9:16 (1080 x 1920)",
              "1:1 (1152 x 1152)",
              "4:3 (1536 x 1152)",
              "3:4 (1152 x 1536)",
              "21:9 (2560 x 1080)"
            ]
          }
        ],
        "prompt_adherence": [
          "FLOAT",
          {
            "tooltip": "Guidance scale for generation control",
            "default": 4.0,
            "min": 1.0,
            "max": 20.0,
            "step": 1.0
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed value",
            "default": 9,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Inference steps",
            "default": 33,
            "min": 1,
            "max": 100,
            "step": 1
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "resolution",
        "prompt_adherence",
        "seed",
        "steps"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MoonvalleyTxt2VideoNode",
    "display_name": "Moonvalley Marey Text to Video",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_moonvalley",
    "category": "api node/video/Moonvalley Marey",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "MoonvalleyVideo2VideoNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Describes the video to generate",
            "multiline": true
          }
        ],
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative prompt text",
            "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring",
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed value",
            "default": 9,
            "min": 0,
            "max": 4294967295,
            "step": 1,
            "control_after_generate": false,
            "display": "number"
          }
        ],
        "video": [
          "VIDEO",
          {
            "tooltip": "The reference video used to generate the output video. Must be at least 5 seconds long. Videos longer than 5s will be automatically trimmed. Only MP4 format supported."
          }
        ],
        "steps": [
          "INT",
          {
            "tooltip": "Number of inference steps",
            "default": 33,
            "min": 1,
            "max": 100,
            "step": 1,
            "display": "number"
          }
        ]
      },
      "optional": {
        "control_type": [
          "COMBO",
          {
            "default": "Motion Transfer",
            "multiselect": false,
            "options": [
              "Motion Transfer",
              "Pose Transfer"
            ]
          }
        ],
        "motion_intensity": [
          "INT",
          {
            "tooltip": "Only used if control_type is 'Motion Transfer'",
            "default": 100,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "negative_prompt",
        "seed",
        "video",
        "steps"
      ],
      "optional": [
        "control_type",
        "motion_intensity"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "MoonvalleyVideo2VideoNode",
    "display_name": "Moonvalley Marey Video to Video",
    "description": "",
    "python_module": "comfy_api_nodes.nodes_moonvalley",
    "category": "api node/video/Moonvalley Marey",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Rodin3D_Regular": {
    "input": {
      "required": {
        "Images": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "Seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 65535,
            "display": "number"
          }
        ],
        "Material_Type": [
          "COMBO",
          {
            "default": "PBR",
            "multiselect": false,
            "options": [
              "PBR",
              "Shaded"
            ]
          }
        ],
        "Polygon_count": [
          "COMBO",
          {
            "default": "18K-Quad",
            "multiselect": false,
            "options": [
              "4K-Quad",
              "8K-Quad",
              "18K-Quad",
              "50K-Quad",
              "200K-Triangle"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "Images"
      ],
      "optional": [
        "Seed",
        "Material_Type",
        "Polygon_count"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "3D Model Path"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Rodin3D_Regular",
    "display_name": "Rodin 3D Generate - Regular Generate",
    "description": "Generate 3D Assets using Rodin API",
    "python_module": "comfy_api_nodes.nodes_rodin",
    "category": "api node/3d/Rodin",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Rodin3D_Detail": {
    "input": {
      "required": {
        "Images": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "Seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 65535,
            "display": "number"
          }
        ],
        "Material_Type": [
          "COMBO",
          {
            "default": "PBR",
            "multiselect": false,
            "options": [
              "PBR",
              "Shaded"
            ]
          }
        ],
        "Polygon_count": [
          "COMBO",
          {
            "default": "18K-Quad",
            "multiselect": false,
            "options": [
              "4K-Quad",
              "8K-Quad",
              "18K-Quad",
              "50K-Quad",
              "200K-Triangle"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "Images"
      ],
      "optional": [
        "Seed",
        "Material_Type",
        "Polygon_count"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "3D Model Path"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Rodin3D_Detail",
    "display_name": "Rodin 3D Generate - Detail Generate",
    "description": "Generate 3D Assets using Rodin API",
    "python_module": "comfy_api_nodes.nodes_rodin",
    "category": "api node/3d/Rodin",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Rodin3D_Smooth": {
    "input": {
      "required": {
        "Images": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "Seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 65535,
            "display": "number"
          }
        ],
        "Material_Type": [
          "COMBO",
          {
            "default": "PBR",
            "multiselect": false,
            "options": [
              "PBR",
              "Shaded"
            ]
          }
        ],
        "Polygon_count": [
          "COMBO",
          {
            "default": "18K-Quad",
            "multiselect": false,
            "options": [
              "4K-Quad",
              "8K-Quad",
              "18K-Quad",
              "50K-Quad",
              "200K-Triangle"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "Images"
      ],
      "optional": [
        "Seed",
        "Material_Type",
        "Polygon_count"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "3D Model Path"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Rodin3D_Smooth",
    "display_name": "Rodin 3D Generate - Smooth Generate",
    "description": "Generate 3D Assets using Rodin API",
    "python_module": "comfy_api_nodes.nodes_rodin",
    "category": "api node/3d/Rodin",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Rodin3D_Sketch": {
    "input": {
      "required": {
        "Images": [
          "IMAGE",
          {}
        ]
      },
      "optional": {
        "Seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 65535,
            "display": "number"
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "Images"
      ],
      "optional": [
        "Seed"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "3D Model Path"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Rodin3D_Sketch",
    "display_name": "Rodin 3D Generate - Sketch Generate",
    "description": "Generate 3D Assets using Rodin API",
    "python_module": "comfy_api_nodes.nodes_rodin",
    "category": "api node/3d/Rodin",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "Rodin3D_Gen2": {
    "input": {
      "required": {
        "Images": [
          "IMAGE",
          {}
        ],
        "TAPose": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "Seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 65535,
            "display": "number"
          }
        ],
        "Material_Type": [
          "COMBO",
          {
            "default": "PBR",
            "multiselect": false,
            "options": [
              "PBR",
              "Shaded"
            ]
          }
        ],
        "Polygon_count": [
          "COMBO",
          {
            "default": "500K-Triangle",
            "multiselect": false,
            "options": [
              "4K-Quad",
              "8K-Quad",
              "18K-Quad",
              "50K-Quad",
              "2K-Triangle",
              "20K-Triangle",
              "150K-Triangle",
              "500K-Triangle"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "Images",
        "TAPose"
      ],
      "optional": [
        "Seed",
        "Material_Type",
        "Polygon_count"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "3D Model Path"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "Rodin3D_Gen2",
    "display_name": "Rodin 3D Generate - Gen-2 Generate",
    "description": "Generate 3D Assets using Rodin API",
    "python_module": "comfy_api_nodes.nodes_rodin",
    "category": "api node/3d/Rodin",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "GeminiNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text inputs to the model, used to generate a response. You can include detailed instructions, questions, or context for the model.",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "The Gemini model to use for generating responses.",
            "default": "gemini-2.5-pro",
            "multiselect": false,
            "options": [
              "gemini-2.5-pro-preview-05-06",
              "gemini-2.5-flash-preview-04-17",
              "gemini-2.5-pro",
              "gemini-2.5-flash",
              "gemini-3-pro-preview"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.",
            "default": 42,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."
          }
        ],
        "audio": [
          "AUDIO",
          {
            "tooltip": "Optional audio to use as context for the model."
          }
        ],
        "video": [
          "VIDEO",
          {
            "tooltip": "Optional video to use as context for the model."
          }
        ],
        "files": [
          "GEMINI_INPUT_FILES",
          {
            "tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."
          }
        ],
        "system_prompt": [
          "STRING",
          {
            "tooltip": "Foundational instructions that dictate an AI's behavior.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "seed"
      ],
      "optional": [
        "images",
        "audio",
        "video",
        "files",
        "system_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "GeminiNode",
    "display_name": "Google Gemini",
    "description": "Generate text responses with Google's Gemini AI model. You can provide multiple types of inputs (text, images, audio, video) as context for generating more relevant and meaningful responses.",
    "python_module": "comfy_api_nodes.nodes_gemini",
    "category": "api node/text/Gemini",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "GeminiImageNode": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt for generation",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "tooltip": "The Gemini model to use for generating responses.",
            "default": "gemini-2.5-flash-image",
            "multiselect": false,
            "options": [
              "gemini-2.5-flash-image-preview",
              "gemini-2.5-flash-image"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.",
            "default": 42,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."
          }
        ],
        "files": [
          "GEMINI_INPUT_FILES",
          {
            "tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "Defaults to matching the output image size to that of your input image, or otherwise generates 1:1 squares.",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "1:1",
              "2:3",
              "3:2",
              "3:4",
              "4:3",
              "4:5",
              "5:4",
              "9:16",
              "16:9",
              "21:9"
            ]
          }
        ],
        "response_modalities": [
          "COMBO",
          {
            "tooltip": "Choose 'IMAGE' for image-only output, or 'IMAGE+TEXT' to return both the generated image and a text response.",
            "multiselect": false,
            "options": [
              "IMAGE+TEXT",
              "IMAGE"
            ]
          }
        ],
        "system_prompt": [
          "STRING",
          {
            "tooltip": "Foundational instructions that dictate an AI's behavior.",
            "default": "You are an expert image-generation engine. You must ALWAYS produce an image.\nInterpret all user inputregardless of format, intent, or abstractionas literal visual directives for image composition.\nIf a prompt is conversational or lacks specific visual details, you must creatively invent a concrete visual scenario that depicts the concept.\nPrioritize generating the visual representation above any text, formatting, or conversational requests.",
            "multiline": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "seed"
      ],
      "optional": [
        "images",
        "files",
        "aspect_ratio",
        "response_modalities",
        "system_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "STRING"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "GeminiImageNode",
    "display_name": "Nano Banana (Google Gemini Image)",
    "description": "Edit images synchronously via Google API.",
    "python_module": "comfy_api_nodes.nodes_gemini",
    "category": "api node/image/Gemini",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "GeminiImage2Node": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "tooltip": "Text prompt describing the image to generate or the edits to apply. Include any constraints, styles, or details the model should follow.",
            "default": "",
            "multiline": true
          }
        ],
        "model": [
          "COMBO",
          {
            "multiselect": false,
            "options": [
              "gemini-3-pro-image-preview"
            ]
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "When the seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.",
            "default": 42,
            "min": 0,
            "max": 18446744073709551615,
            "control_after_generate": true
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "If set to 'auto', matches your input image's aspect ratio; if no image is provided, a 16:9 square is usually generated.",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "1:1",
              "2:3",
              "3:2",
              "3:4",
              "4:3",
              "4:5",
              "5:4",
              "9:16",
              "16:9",
              "21:9"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Target output resolution. For 2K/4K the native Gemini upscaler is used.",
            "multiselect": false,
            "options": [
              "1K",
              "2K",
              "4K"
            ]
          }
        ],
        "response_modalities": [
          "COMBO",
          {
            "tooltip": "Choose 'IMAGE' for image-only output, or 'IMAGE+TEXT' to return both the generated image and a text response.",
            "multiselect": false,
            "options": [
              "IMAGE+TEXT",
              "IMAGE"
            ]
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE",
          {
            "tooltip": "Optional reference image(s). To include multiple images, use the Batch Images node (up to 14)."
          }
        ],
        "files": [
          "GEMINI_INPUT_FILES",
          {
            "tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."
          }
        ],
        "system_prompt": [
          "STRING",
          {
            "tooltip": "Foundational instructions that dictate an AI's behavior.",
            "default": "You are an expert image-generation engine. You must ALWAYS produce an image.\nInterpret all user inputregardless of format, intent, or abstractionas literal visual directives for image composition.\nIf a prompt is conversational or lacks specific visual details, you must creatively invent a concrete visual scenario that depicts the concept.\nPrioritize generating the visual representation above any text, formatting, or conversational requests.",
            "multiline": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt",
        "model",
        "seed",
        "aspect_ratio",
        "resolution",
        "response_modalities"
      ],
      "optional": [
        "images",
        "files",
        "system_prompt"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "STRING"
    ],
    "output_tooltips": [
      null,
      null
    ],
    "output_matchtypes": null,
    "name": "GeminiImage2Node",
    "display_name": "Nano Banana Pro (Google Gemini Image)",
    "description": "Generate or edit images synchronously via Google Vertex API.",
    "python_module": "comfy_api_nodes.nodes_gemini",
    "category": "api node/image/Gemini",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "GeminiInputFiles": {
    "input": {
      "required": {
        "file": [
          "COMBO",
          {
            "tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.",
            "multiselect": false,
            "options": []
          }
        ]
      },
      "optional": {
        "GEMINI_INPUT_FILES": [
          "GEMINI_INPUT_FILES",
          {
            "tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file"
      ],
      "optional": [
        "GEMINI_INPUT_FILES"
      ]
    },
    "output": [
      "GEMINI_INPUT_FILES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "GEMINI_INPUT_FILES"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "GeminiInputFiles",
    "display_name": "Gemini Input Files",
    "description": "Loads and prepares input files to include as inputs for Gemini LLM nodes. The files will be read by the Gemini model when generating a response. The contents of the text file count toward the token limit.  TIP: Can be chained together with other Gemini Input File nodes.",
    "python_module": "comfy_api_nodes.nodes_gemini",
    "category": "api node/text/Gemini",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "ViduTextToVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model name",
            "default": "viduq1",
            "multiselect": false,
            "options": [
              "viduq1"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A textual description for video generation",
            "multiline": true
          }
        ]
      },
      "optional": {
        "duration": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 5,
            "min": 5,
            "max": 5,
            "step": 1,
            "display": "number"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video",
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Supported values may vary by model & duration",
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p"
            ]
          }
        ],
        "movement_amplitude": [
          "COMBO",
          {
            "tooltip": "The movement amplitude of objects in the frame",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "small",
              "medium",
              "large"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt"
      ],
      "optional": [
        "duration",
        "seed",
        "aspect_ratio",
        "resolution",
        "movement_amplitude"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ViduTextToVideoNode",
    "display_name": "Vidu Text To Video Generation",
    "description": "Generate video from text prompt",
    "python_module": "comfy_api_nodes.nodes_vidu",
    "category": "api node/video/Vidu",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ViduImageToVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model name",
            "default": "viduq1",
            "multiselect": false,
            "options": [
              "viduq1"
            ]
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "An image to be used as the start frame of the generated video"
          }
        ]
      },
      "optional": {
        "prompt": [
          "STRING",
          {
            "tooltip": "A textual description for video generation",
            "default": "",
            "multiline": true
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 5,
            "min": 5,
            "max": 5,
            "step": 1,
            "display": "number"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Supported values may vary by model & duration",
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p"
            ]
          }
        ],
        "movement_amplitude": [
          "COMBO",
          {
            "tooltip": "The movement amplitude of objects in the frame",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "small",
              "medium",
              "large"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "image"
      ],
      "optional": [
        "prompt",
        "duration",
        "seed",
        "resolution",
        "movement_amplitude"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ViduImageToVideoNode",
    "display_name": "Vidu Image To Video Generation",
    "description": "Generate video from image and optional prompt",
    "python_module": "comfy_api_nodes.nodes_vidu",
    "category": "api node/video/Vidu",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ViduReferenceVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model name",
            "default": "viduq1",
            "multiselect": false,
            "options": [
              "viduq1"
            ]
          }
        ],
        "images": [
          "IMAGE",
          {
            "tooltip": "Images to use as references to generate a video with consistent subjects (max 7 images)."
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "A textual description for video generation",
            "multiline": true
          }
        ]
      },
      "optional": {
        "duration": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 5,
            "min": 5,
            "max": 5,
            "step": 1,
            "display": "number"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "aspect_ratio": [
          "COMBO",
          {
            "tooltip": "The aspect ratio of the output video",
            "default": "16:9",
            "multiselect": false,
            "options": [
              "16:9",
              "9:16",
              "1:1"
            ]
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Supported values may vary by model & duration",
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p"
            ]
          }
        ],
        "movement_amplitude": [
          "COMBO",
          {
            "tooltip": "The movement amplitude of objects in the frame",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "small",
              "medium",
              "large"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "images",
        "prompt"
      ],
      "optional": [
        "duration",
        "seed",
        "aspect_ratio",
        "resolution",
        "movement_amplitude"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ViduReferenceVideoNode",
    "display_name": "Vidu Reference To Video Generation",
    "description": "Generate video from multiple images and prompt",
    "python_module": "comfy_api_nodes.nodes_vidu",
    "category": "api node/video/Vidu",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "ViduStartEndToVideoNode": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model name",
            "default": "viduq1",
            "multiselect": false,
            "options": [
              "viduq1"
            ]
          }
        ],
        "first_frame": [
          "IMAGE",
          {
            "tooltip": "Start frame"
          }
        ],
        "end_frame": [
          "IMAGE",
          {
            "tooltip": "End frame"
          }
        ]
      },
      "optional": {
        "prompt": [
          "STRING",
          {
            "tooltip": "A textual description for video generation",
            "multiline": true
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "Duration of the output video in seconds",
            "default": 5,
            "min": 5,
            "max": 5,
            "step": 1,
            "display": "number"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed for video generation (0 for random)",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "resolution": [
          "COMBO",
          {
            "tooltip": "Supported values may vary by model & duration",
            "default": "1080p",
            "multiselect": false,
            "options": [
              "1080p"
            ]
          }
        ],
        "movement_amplitude": [
          "COMBO",
          {
            "tooltip": "The movement amplitude of objects in the frame",
            "default": "auto",
            "multiselect": false,
            "options": [
              "auto",
              "small",
              "medium",
              "large"
            ]
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "first_frame",
        "end_frame"
      ],
      "optional": [
        "prompt",
        "duration",
        "seed",
        "resolution",
        "movement_amplitude"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "ViduStartEndToVideoNode",
    "display_name": "Vidu Start End To Video Generation",
    "description": "Generate a video from start and end frames and a prompt",
    "python_module": "comfy_api_nodes.nodes_vidu",
    "category": "api node/video/Vidu",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "WanTextToImageApi": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use.",
            "default": "wan2.5-t2i-preview",
            "multiselect": false,
            "options": [
              "wan2.5-t2i-preview"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid.",
            "default": "",
            "multiline": true
          }
        ],
        "width": [
          "INT",
          {
            "default": 1024,
            "min": 768,
            "max": 1440,
            "step": 32
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024,
            "min": 768,
            "max": 1440,
            "step": 32
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "prompt_extend": [
          "BOOLEAN",
          {
            "tooltip": "Whether to enhance the prompt with AI assistance.",
            "default": true
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the result.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt"
      ],
      "optional": [
        "negative_prompt",
        "width",
        "height",
        "seed",
        "prompt_extend",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "WanTextToImageApi",
    "display_name": "Wan Text to Image",
    "description": "Generates image based on text prompt.",
    "python_module": "comfy_api_nodes.nodes_wan",
    "category": "api node/image/Wan",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "WanImageToImageApi": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use.",
            "default": "wan2.5-i2i-preview",
            "multiselect": false,
            "options": [
              "wan2.5-i2i-preview"
            ]
          }
        ],
        "image": [
          "IMAGE",
          {
            "tooltip": "Single-image editing or multi-image fusion, maximum 2 images."
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid.",
            "default": "",
            "multiline": true
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the result.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "image",
        "prompt"
      ],
      "optional": [
        "negative_prompt",
        "seed",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "WanImageToImageApi",
    "display_name": "Wan Image to Image",
    "description": "Generates an image from one or two input images and a text prompt. The output image is currently fixed at 1.6 MP; its aspect ratio matches the input image(s).",
    "python_module": "comfy_api_nodes.nodes_wan",
    "category": "api node/image/Wan",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "WanTextToVideoApi": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use.",
            "default": "wan2.5-t2v-preview",
            "multiselect": false,
            "options": [
              "wan2.5-t2v-preview"
            ]
          }
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid.",
            "default": "",
            "multiline": true
          }
        ],
        "size": [
          "COMBO",
          {
            "default": "480p: 1:1 (624x624)",
            "multiselect": false,
            "options": [
              "480p: 1:1 (624x624)",
              "480p: 16:9 (832x480)",
              "480p: 9:16 (480x832)",
              "720p: 1:1 (960x960)",
              "720p: 16:9 (1280x720)",
              "720p: 9:16 (720x1280)",
              "720p: 4:3 (1088x832)",
              "720p: 3:4 (832x1088)",
              "1080p: 1:1 (1440x1440)",
              "1080p: 16:9 (1920x1080)",
              "1080p: 9:16 (1080x1920)",
              "1080p: 4:3 (1632x1248)",
              "1080p: 3:4 (1248x1632)"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "Available durations: 5 and 10 seconds",
            "default": 5,
            "min": 5,
            "max": 10,
            "step": 5,
            "display": "number"
          }
        ],
        "audio": [
          "AUDIO",
          {
            "tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "If there is no audio input, generate audio automatically.",
            "default": false
          }
        ],
        "prompt_extend": [
          "BOOLEAN",
          {
            "tooltip": "Whether to enhance the prompt with AI assistance.",
            "default": true
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the result.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "prompt"
      ],
      "optional": [
        "negative_prompt",
        "size",
        "duration",
        "audio",
        "seed",
        "generate_audio",
        "prompt_extend",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "WanTextToVideoApi",
    "display_name": "Wan Text to Video",
    "description": "Generates video based on text prompt.",
    "python_module": "comfy_api_nodes.nodes_wan",
    "category": "api node/video/Wan",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "WanImageToVideoApi": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "Model to use.",
            "default": "wan2.5-i2v-preview",
            "multiselect": false,
            "options": [
              "wan2.5-i2v-preview"
            ]
          }
        ],
        "image": [
          "IMAGE",
          {}
        ],
        "prompt": [
          "STRING",
          {
            "tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.",
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "negative_prompt": [
          "STRING",
          {
            "tooltip": "Negative text prompt to guide what to avoid.",
            "default": "",
            "multiline": true
          }
        ],
        "resolution": [
          "COMBO",
          {
            "default": "480P",
            "multiselect": false,
            "options": [
              "480P",
              "720P",
              "1080P"
            ]
          }
        ],
        "duration": [
          "INT",
          {
            "tooltip": "Available durations: 5 and 10 seconds",
            "default": 5,
            "min": 5,
            "max": 10,
            "step": 5,
            "display": "number"
          }
        ],
        "audio": [
          "AUDIO",
          {
            "tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Seed to use for generation.",
            "default": 0,
            "min": 0,
            "max": 2147483647,
            "step": 1,
            "control_after_generate": true,
            "display": "number"
          }
        ],
        "generate_audio": [
          "BOOLEAN",
          {
            "tooltip": "If there is no audio input, generate audio automatically.",
            "default": false
          }
        ],
        "prompt_extend": [
          "BOOLEAN",
          {
            "tooltip": "Whether to enhance the prompt with AI assistance.",
            "default": true
          }
        ],
        "watermark": [
          "BOOLEAN",
          {
            "tooltip": "Whether to add an \"AI generated\" watermark to the result.",
            "default": true
          }
        ]
      },
      "hidden": {
        "auth_token_comfy_org": [
          "AUTH_TOKEN_COMFY_ORG"
        ],
        "api_key_comfy_org": [
          "API_KEY_COMFY_ORG"
        ],
        "unique_id": [
          "UNIQUE_ID"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "image",
        "prompt"
      ],
      "optional": [
        "negative_prompt",
        "resolution",
        "duration",
        "audio",
        "seed",
        "generate_audio",
        "prompt_extend",
        "watermark"
      ],
      "hidden": [
        "auth_token_comfy_org",
        "api_key_comfy_org",
        "unique_id"
      ]
    },
    "output": [
      "VIDEO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VIDEO"
    ],
    "output_tooltips": [
      null
    ],
    "output_matchtypes": null,
    "name": "WanImageToVideoApi",
    "display_name": "Wan Image to Video",
    "description": "Generates video based on the first frame and text prompt.",
    "python_module": "comfy_api_nodes.nodes_wan",
    "category": "api node/video/Wan",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": true
  },
  "SaveImageWebsocket": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SaveImageWebsocket",
    "display_name": "SaveImageWebsocket",
    "description": "",
    "python_module": "custom_nodes.websocket_image_save",
    "category": "api/image",
    "output_node": true
  },
  "Primitive boolean [Crystools]": {
    "input": {
      "required": {
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "boolean"
    ],
    "name": "Primitive boolean [Crystools]",
    "display_name": " Primitive boolean",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Primitive",
    "output_node": false
  },
  "Primitive string [Crystools]": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "string"
    ],
    "name": "Primitive string [Crystools]",
    "display_name": " Primitive string",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Primitive",
    "output_node": false
  },
  "Primitive string multiline [Crystools]": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {
            "multiline": true,
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "string"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "string"
    ],
    "name": "Primitive string multiline [Crystools]",
    "display_name": " Primitive string multiline",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Primitive",
    "output_node": false
  },
  "Primitive integer [Crystools]": {
    "input": {
      "required": {
        "int": [
          "INT",
          {
            "default": 1,
            "min": -9223372036854775807,
            "max": 9223372036854775807,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "int"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "int"
    ],
    "name": "Primitive integer [Crystools]",
    "display_name": " Primitive integer",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Primitive",
    "output_node": false
  },
  "Primitive float [Crystools]": {
    "input": {
      "required": {
        "float": [
          "FLOAT",
          {
            "default": 1,
            "min": -1.7976931348623157e+308,
            "max": 1.7976931348623157e+308,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "float"
      ]
    },
    "output": [
      "FLOAT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "float"
    ],
    "name": "Primitive float [Crystools]",
    "display_name": " Primitive float",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Primitive",
    "output_node": false
  },
  "Show any [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "any_value": [
          "*"
        ],
        "console": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "display": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "prefix": [
          "STRING",
          {
            "default": ""
          }
        ]
      },
      "hidden": {}
    },
    "input_order": {
      "required": [],
      "optional": [
        "any_value",
        "console",
        "display",
        "prefix"
      ],
      "hidden": []
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Show any [Crystools]",
    "display_name": " Show any value to console/display",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Debugger",
    "output_node": true
  },
  "Show any to JSON [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "any_value": [
          "*"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "any_value"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "string"
    ],
    "name": "Show any to JSON [Crystools]",
    "display_name": " Show any to JSON",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Debugger",
    "output_node": true
  },
  "List of any [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "any_1": [
          "*"
        ],
        "any_2": [
          "*"
        ],
        "any_3": [
          "*"
        ],
        "any_4": [
          "*"
        ],
        "any_5": [
          "*"
        ],
        "any_6": [
          "*"
        ],
        "any_7": [
          "*"
        ],
        "any_8": [
          "*"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "any_1",
        "any_2",
        "any_3",
        "any_4",
        "any_5",
        "any_6",
        "any_7",
        "any_8"
      ]
    },
    "output": [
      [
        "*"
      ]
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "any_list"
    ],
    "name": "List of any [Crystools]",
    "display_name": " List of any",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /List",
    "output_node": false
  },
  "List of strings [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "string_1": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_2": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_3": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_4": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_5": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_6": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_7": [
          "STRING",
          {
            "default": ""
          }
        ],
        "string_8": [
          "STRING",
          {
            "default": ""
          }
        ],
        "delimiter": [
          "STRING",
          {
            "default": " "
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "string_1",
        "string_2",
        "string_3",
        "string_4",
        "string_5",
        "string_6",
        "string_7",
        "string_8",
        "delimiter"
      ]
    },
    "output": [
      "STRING",
      "ListString"
    ],
    "output_is_list": [
      false,
      true
    ],
    "output_name": [
      "concatenated",
      "list_string"
    ],
    "name": "List of strings [Crystools]",
    "display_name": " List of strings",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /List",
    "output_node": false
  },
  "Switch from any [Crystools]": {
    "input": {
      "required": {
        "any": [
          "*"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "any",
        "boolean"
      ]
    },
    "output": [
      "*",
      "*"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "on_true",
      "on_false"
    ],
    "name": "Switch from any [Crystools]",
    "display_name": " Switch from any",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch any [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "*",
          {
            "lazy": true
          }
        ],
        "on_false": [
          "*",
          {
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "*"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "*"
    ],
    "name": "Switch any [Crystools]",
    "display_name": " Switch any",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch latent [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "LATENT",
          {
            "lazy": true
          }
        ],
        "on_false": [
          "LATENT",
          {
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "latent"
    ],
    "name": "Switch latent [Crystools]",
    "display_name": " Switch latent",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch conditioning [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "CONDITIONING",
          {
            "lazy": true
          }
        ],
        "on_false": [
          "CONDITIONING",
          {
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "conditioning"
    ],
    "name": "Switch conditioning [Crystools]",
    "display_name": " Switch conditioning",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch image [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "IMAGE",
          {
            "lazy": true
          }
        ],
        "on_false": [
          "IMAGE",
          {
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Switch image [Crystools]",
    "display_name": " Switch image",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch mask [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "MASK",
          {
            "lazy": true
          }
        ],
        "on_false": [
          "MASK",
          {
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "mask"
    ],
    "name": "Switch mask [Crystools]",
    "display_name": " Switch mask",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Switch string [Crystools]": {
    "input": {
      "required": {
        "on_true": [
          "STRING",
          {
            "default": "",
            "lazy": true
          }
        ],
        "on_false": [
          "STRING",
          {
            "default": "",
            "lazy": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "on_true",
        "on_false",
        "boolean"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "string"
    ],
    "name": "Switch string [Crystools]",
    "display_name": " Switch string",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Switch",
    "output_node": false
  },
  "Pipe to/edit any [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "CPipeAny": [
          "CPipeAny"
        ],
        "any_1": [
          "*"
        ],
        "any_2": [
          "*"
        ],
        "any_3": [
          "*"
        ],
        "any_4": [
          "*"
        ],
        "any_5": [
          "*"
        ],
        "any_6": [
          "*"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "CPipeAny",
        "any_1",
        "any_2",
        "any_3",
        "any_4",
        "any_5",
        "any_6"
      ]
    },
    "output": [
      "CPipeAny"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CPipeAny"
    ],
    "name": "Pipe to/edit any [Crystools]",
    "display_name": " Pipe to/edit any",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Pipe",
    "output_node": false
  },
  "Pipe from any [Crystools]": {
    "input": {
      "required": {
        "CPipeAny": [
          "CPipeAny"
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "CPipeAny"
      ],
      "optional": []
    },
    "output": [
      "CPipeAny",
      "*",
      "*",
      "*",
      "*",
      "*",
      "*"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CPipeAny",
      "any_1",
      "any_2",
      "any_3",
      "any_4",
      "any_5",
      "any_6"
    ],
    "name": "Pipe from any [Crystools]",
    "display_name": " Pipe from any",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Pipe",
    "output_node": false
  },
  "Load image with metadata [Crystools]": {
    "input": {
      "required": {
        "image": [
          [],
          {
            "image_upload": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "JSON",
      "METADATA_RAW"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "image",
      "mask",
      "prompt",
      "Metadata RAW"
    ],
    "name": "Load image with metadata [Crystools]",
    "display_name": " Load image with metadata",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Image",
    "output_node": true
  },
  "Get resolution [Crystools]": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "hidden": [
        "unique_id",
        "extra_pnginfo"
      ]
    },
    "output": [
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "width",
      "height"
    ],
    "name": "Get resolution [Crystools]",
    "display_name": " Get resolution",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Image",
    "output_node": true
  },
  "Preview from image [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "image": [
          "IMAGE"
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "image"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "METADATA_RAW"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Metadata RAW"
    ],
    "name": "Preview from image [Crystools]",
    "display_name": " Preview from image",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Image",
    "output_node": true
  },
  "Preview from metadata [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "metadata_raw": [
          "METADATA_RAW",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "metadata_raw"
      ]
    },
    "output": [
      "METADATA_RAW"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Metadata RAW"
    ],
    "name": "Preview from metadata [Crystools]",
    "display_name": " Preview from metadata",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Image",
    "output_node": true
  },
  "Save image with extra metadata [Crystools]": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI"
          }
        ],
        "with_workflow": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      },
      "optional": {
        "metadata_extra": [
          "STRING",
          {
            "multiline": true,
            "default": "{\n  \"Title\": \"Image generated by Crystian\",\n  \"Description\": \"More info: https:\\/\\/www.instagram.com\\/crystian.ia\",\n  \"Author\": \"crystian.ia\",\n  \"Software\": \"ComfyUI\",\n  \"Category\": \"StableDiffusion\",\n  \"Rating\": 5,\n  \"UserComment\": \"\",\n  \"Keywords\": [\n    \"\"\n  ],\n  \"Copyrights\": \"\"\n}"
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "image",
        "filename_prefix",
        "with_workflow"
      ],
      "optional": [
        "metadata_extra"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "METADATA_RAW"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Metadata RAW"
    ],
    "name": "Save image with extra metadata [Crystools]",
    "display_name": " Save image with extra metadata",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Image",
    "output_node": true
  },
  "Metadata extractor [Crystools]": {
    "input": {
      "required": {
        "metadata_raw": [
          "METADATA_RAW",
          {
            "forceInput": true
          }
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "metadata_raw"
      ],
      "optional": []
    },
    "output": [
      "JSON",
      "JSON",
      "JSON",
      "JSON",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "prompt",
      "workflow",
      "file info",
      "raw to JSON",
      "raw to property",
      "raw to csv"
    ],
    "name": "Metadata extractor [Crystools]",
    "display_name": " Metadata extractor",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Metadata",
    "output_node": false
  },
  "Metadata comparator [Crystools]": {
    "input": {
      "required": {
        "metadata_raw_old": [
          "METADATA_RAW",
          {
            "forceInput": true
          }
        ],
        "metadata_raw_new": [
          "METADATA_RAW",
          {
            "forceInput": true
          }
        ],
        "what": [
          [
            "Prompt",
            "Workflow",
            "Fileinfo"
          ]
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "metadata_raw_old",
        "metadata_raw_new",
        "what"
      ],
      "optional": []
    },
    "output": [
      "JSON"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "diff"
    ],
    "name": "Metadata comparator [Crystools]",
    "display_name": " Metadata comparator",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Metadata",
    "output_node": true
  },
  "JSON comparator [Crystools]": {
    "input": {
      "required": {
        "json_old": [
          "JSON",
          {
            "forceInput": true
          }
        ],
        "json_new": [
          "JSON",
          {
            "forceInput": true
          }
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "json_old",
        "json_new"
      ],
      "optional": []
    },
    "output": [
      "JSON"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "json_compared"
    ],
    "name": "JSON comparator [Crystools]",
    "display_name": " JSON comparator",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Utils",
    "output_node": true
  },
  "Stats system [Crystools]": {
    "input": {
      "required": {
        "latent": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "latent"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "latent"
    ],
    "name": "Stats system [Crystools]",
    "display_name": " Stats system (powered by WAS)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Utils",
    "output_node": false
  },
  "Read JSON file [Crystools]": {
    "input": {
      "required": {},
      "optional": {
        "path_to_json": [
          "STRING",
          {
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "path_to_json"
      ]
    },
    "output": [
      "JSON"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "json"
    ],
    "name": "Read JSON file [Crystools]",
    "display_name": " Read JSON file (BETA)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Utils",
    "output_node": false
  },
  "JSON extractor [Crystools]": {
    "input": {
      "required": {
        "json": [
          "JSON",
          {
            "forceInput": true
          }
        ]
      },
      "optional": {
        "key": [
          "STRING",
          {
            "default": ""
          }
        ],
        "default": [
          "STRING",
          {
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "json"
      ],
      "optional": [
        "key",
        "default"
      ]
    },
    "output": [
      "*",
      "STRING",
      "INT",
      "FLOAT",
      "BOOLEAN"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "any",
      "string",
      "int",
      "float",
      "boolean"
    ],
    "name": "JSON extractor [Crystools]",
    "display_name": " JSON extractor (BETA)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-Crystools",
    "category": "crystools /Utils",
    "output_node": false
  },
  "Context Big (rgthree)": {
    "input": {
      "required": {},
      "optional": {
        "base_ctx": [
          "RGTHREE_CONTEXT"
        ],
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "vae": [
          "VAE"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "latent": [
          "LATENT"
        ],
        "images": [
          "IMAGE"
        ],
        "seed": [
          "INT",
          {
            "forceInput": true
          }
        ],
        "steps": [
          "INT",
          {
            "forceInput": true
          }
        ],
        "step_refiner": [
          "INT",
          {
            "forceInput": true
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "forceInput": true
          }
        ],
        "ckpt_name": [
          [],
          {
            "forceInput": true
          }
        ],
        "sampler": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ],
          {
            "forceInput": true
          }
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ],
          {
            "forceInput": true
          }
        ],
        "clip_width": [
          "INT",
          {
            "forceInput": true
          }
        ],
        "clip_height": [
          "INT",
          {
            "forceInput": true
          }
        ],
        "text_pos_g": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_pos_l": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_neg_g": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_neg_l": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "mask": [
          "MASK"
        ],
        "control_net": [
          "CONTROL_NET"
        ]
      },
      "hidden": {}
    },
    "input_order": {
      "required": [],
      "optional": [
        "base_ctx",
        "model",
        "clip",
        "vae",
        "positive",
        "negative",
        "latent",
        "images",
        "seed",
        "steps",
        "step_refiner",
        "cfg",
        "ckpt_name",
        "sampler",
        "scheduler",
        "clip_width",
        "clip_height",
        "text_pos_g",
        "text_pos_l",
        "text_neg_g",
        "text_neg_l",
        "mask",
        "control_net"
      ],
      "hidden": []
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT",
      "INT",
      "INT",
      "FLOAT",
      [],
      [
        "euler",
        "euler_cfg_pp",
        "euler_ancestral",
        "euler_ancestral_cfg_pp",
        "heun",
        "heunpp2",
        "dpm_2",
        "dpm_2_ancestral",
        "lms",
        "dpm_fast",
        "dpm_adaptive",
        "dpmpp_2s_ancestral",
        "dpmpp_2s_ancestral_cfg_pp",
        "dpmpp_sde",
        "dpmpp_sde_gpu",
        "dpmpp_2m",
        "dpmpp_2m_cfg_pp",
        "dpmpp_2m_sde",
        "dpmpp_2m_sde_gpu",
        "dpmpp_2m_sde_heun",
        "dpmpp_2m_sde_heun_gpu",
        "dpmpp_3m_sde",
        "dpmpp_3m_sde_gpu",
        "ddpm",
        "lcm",
        "ipndm",
        "ipndm_v",
        "deis",
        "res_multistep",
        "res_multistep_cfg_pp",
        "res_multistep_ancestral",
        "res_multistep_ancestral_cfg_pp",
        "gradient_estimation",
        "gradient_estimation_cfg_pp",
        "er_sde",
        "seeds_2",
        "seeds_3",
        "sa_solver",
        "sa_solver_pece",
        "ddim",
        "uni_pc",
        "uni_pc_bh2"
      ],
      [
        "simple",
        "sgm_uniform",
        "karras",
        "exponential",
        "ddim_uniform",
        "beta",
        "normal",
        "linear_quadratic",
        "kl_optimal"
      ],
      "INT",
      "INT",
      "STRING",
      "STRING",
      "STRING",
      "STRING",
      "MASK",
      "CONTROL_NET"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED",
      "STEPS",
      "STEP_REFINER",
      "CFG",
      "CKPT_NAME",
      "SAMPLER",
      "SCHEDULER",
      "CLIP_WIDTH",
      "CLIP_HEIGHT",
      "TEXT_POS_G",
      "TEXT_POS_L",
      "TEXT_NEG_G",
      "TEXT_NEG_L",
      "MASK",
      "CONTROL_NET"
    ],
    "name": "Context Big (rgthree)",
    "display_name": "Context Big (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Context (rgthree)": {
    "input": {
      "required": {},
      "optional": {
        "base_ctx": [
          "RGTHREE_CONTEXT"
        ],
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "vae": [
          "VAE"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "latent": [
          "LATENT"
        ],
        "images": [
          "IMAGE"
        ],
        "seed": [
          "INT",
          {
            "forceInput": true
          }
        ]
      },
      "hidden": {
        "version": "FLOAT"
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "base_ctx",
        "model",
        "clip",
        "vae",
        "positive",
        "negative",
        "latent",
        "images",
        "seed"
      ],
      "hidden": [
        "version"
      ]
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED"
    ],
    "name": "Context (rgthree)",
    "display_name": "Context (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Context Switch (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED"
    ],
    "name": "Context Switch (rgthree)",
    "display_name": "Context Switch (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Context Switch Big (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT",
      "INT",
      "INT",
      "FLOAT",
      [],
      [
        "euler",
        "euler_cfg_pp",
        "euler_ancestral",
        "euler_ancestral_cfg_pp",
        "heun",
        "heunpp2",
        "dpm_2",
        "dpm_2_ancestral",
        "lms",
        "dpm_fast",
        "dpm_adaptive",
        "dpmpp_2s_ancestral",
        "dpmpp_2s_ancestral_cfg_pp",
        "dpmpp_sde",
        "dpmpp_sde_gpu",
        "dpmpp_2m",
        "dpmpp_2m_cfg_pp",
        "dpmpp_2m_sde",
        "dpmpp_2m_sde_gpu",
        "dpmpp_2m_sde_heun",
        "dpmpp_2m_sde_heun_gpu",
        "dpmpp_3m_sde",
        "dpmpp_3m_sde_gpu",
        "ddpm",
        "lcm",
        "ipndm",
        "ipndm_v",
        "deis",
        "res_multistep",
        "res_multistep_cfg_pp",
        "res_multistep_ancestral",
        "res_multistep_ancestral_cfg_pp",
        "gradient_estimation",
        "gradient_estimation_cfg_pp",
        "er_sde",
        "seeds_2",
        "seeds_3",
        "sa_solver",
        "sa_solver_pece",
        "ddim",
        "uni_pc",
        "uni_pc_bh2"
      ],
      [
        "simple",
        "sgm_uniform",
        "karras",
        "exponential",
        "ddim_uniform",
        "beta",
        "normal",
        "linear_quadratic",
        "kl_optimal"
      ],
      "INT",
      "INT",
      "STRING",
      "STRING",
      "STRING",
      "STRING",
      "MASK",
      "CONTROL_NET"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED",
      "STEPS",
      "STEP_REFINER",
      "CFG",
      "CKPT_NAME",
      "SAMPLER",
      "SCHEDULER",
      "CLIP_WIDTH",
      "CLIP_HEIGHT",
      "TEXT_POS_G",
      "TEXT_POS_L",
      "TEXT_NEG_G",
      "TEXT_NEG_L",
      "MASK",
      "CONTROL_NET"
    ],
    "name": "Context Switch Big (rgthree)",
    "display_name": "Context Switch Big (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Context Merge (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED"
    ],
    "name": "Context Merge (rgthree)",
    "display_name": "Context Merge (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Context Merge Big (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "RGTHREE_CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING",
      "LATENT",
      "IMAGE",
      "INT",
      "INT",
      "INT",
      "FLOAT",
      [],
      [
        "euler",
        "euler_cfg_pp",
        "euler_ancestral",
        "euler_ancestral_cfg_pp",
        "heun",
        "heunpp2",
        "dpm_2",
        "dpm_2_ancestral",
        "lms",
        "dpm_fast",
        "dpm_adaptive",
        "dpmpp_2s_ancestral",
        "dpmpp_2s_ancestral_cfg_pp",
        "dpmpp_sde",
        "dpmpp_sde_gpu",
        "dpmpp_2m",
        "dpmpp_2m_cfg_pp",
        "dpmpp_2m_sde",
        "dpmpp_2m_sde_gpu",
        "dpmpp_2m_sde_heun",
        "dpmpp_2m_sde_heun_gpu",
        "dpmpp_3m_sde",
        "dpmpp_3m_sde_gpu",
        "ddpm",
        "lcm",
        "ipndm",
        "ipndm_v",
        "deis",
        "res_multistep",
        "res_multistep_cfg_pp",
        "res_multistep_ancestral",
        "res_multistep_ancestral_cfg_pp",
        "gradient_estimation",
        "gradient_estimation_cfg_pp",
        "er_sde",
        "seeds_2",
        "seeds_3",
        "sa_solver",
        "sa_solver_pece",
        "ddim",
        "uni_pc",
        "uni_pc_bh2"
      ],
      [
        "simple",
        "sgm_uniform",
        "karras",
        "exponential",
        "ddim_uniform",
        "beta",
        "normal",
        "linear_quadratic",
        "kl_optimal"
      ],
      "INT",
      "INT",
      "STRING",
      "STRING",
      "STRING",
      "STRING",
      "MASK",
      "CONTROL_NET"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONTEXT",
      "MODEL",
      "CLIP",
      "VAE",
      "POSITIVE",
      "NEGATIVE",
      "LATENT",
      "IMAGE",
      "SEED",
      "STEPS",
      "STEP_REFINER",
      "CFG",
      "CKPT_NAME",
      "SAMPLER",
      "SCHEDULER",
      "CLIP_WIDTH",
      "CLIP_HEIGHT",
      "TEXT_POS_G",
      "TEXT_POS_L",
      "TEXT_NEG_G",
      "TEXT_NEG_L",
      "MASK",
      "CONTROL_NET"
    ],
    "name": "Context Merge Big (rgthree)",
    "display_name": "Context Merge Big (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Display Int (rgthree)": {
    "input": {
      "required": {
        "input": [
          "INT",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "input"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Display Int (rgthree)",
    "display_name": "Display Int (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": true
  },
  "Display Any (rgthree)": {
    "input": {
      "required": {
        "source": [
          "*",
          {}
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "source"
      ],
      "hidden": [
        "unique_id",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Display Any (rgthree)",
    "display_name": "Display Any (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": true
  },
  "Lora Loader Stack (rgthree)": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "lora_01": [
          [
            "None"
          ]
        ],
        "strength_01": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "lora_02": [
          [
            "None"
          ]
        ],
        "strength_02": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "lora_03": [
          [
            "None"
          ]
        ],
        "strength_03": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "lora_04": [
          [
            "None"
          ]
        ],
        "strength_04": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip",
        "lora_01",
        "strength_01",
        "lora_02",
        "strength_02",
        "lora_03",
        "strength_03",
        "lora_04",
        "strength_04"
      ]
    },
    "output": [
      "MODEL",
      "CLIP"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP"
    ],
    "name": "Lora Loader Stack (rgthree)",
    "display_name": "Lora Loader Stack (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Seed (rgthree)": {
    "input": {
      "required": {
        "seed": [
          "INT",
          {
            "default": 0,
            "min": -1125899906842624,
            "max": 1125899906842624
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "seed"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo",
        "unique_id"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SEED"
    ],
    "name": "Seed (rgthree)",
    "display_name": "Seed (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Image Inset Crop (rgthree)": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "measurement": [
          [
            "Pixels",
            "Percentage"
          ]
        ],
        "left": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "right": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "top": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "bottom": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "measurement",
        "left",
        "right",
        "top",
        "bottom"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Inset Crop (rgthree)",
    "display_name": "Image Inset Crop (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Power Prompt (rgthree)": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "opt_model": [
          "MODEL"
        ],
        "opt_clip": [
          "CLIP"
        ],
        "insert_lora": [
          [
            "CHOOSE",
            "DISABLE LORAS"
          ]
        ],
        "insert_embedding": [
          [
            "CHOOSE"
          ]
        ],
        "insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      },
      "hidden": {
        "values_insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "opt_model",
        "opt_clip",
        "insert_lora",
        "insert_embedding",
        "insert_saved"
      ],
      "hidden": [
        "values_insert_saved"
      ]
    },
    "output": [
      "CONDITIONING",
      "MODEL",
      "CLIP",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONDITIONING",
      "MODEL",
      "CLIP",
      "TEXT"
    ],
    "name": "Power Prompt (rgthree)",
    "display_name": "Power Prompt (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Power Prompt - Simple (rgthree)": {
    "input": {
      "required": {
        "prompt": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "opt_clip": [
          "CLIP"
        ],
        "insert_embedding": [
          [
            "CHOOSE"
          ]
        ],
        "insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      },
      "hidden": {
        "values_insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt"
      ],
      "optional": [
        "opt_clip",
        "insert_embedding",
        "insert_saved"
      ],
      "hidden": [
        "values_insert_saved"
      ]
    },
    "output": [
      "CONDITIONING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "CONDITIONING",
      "TEXT"
    ],
    "name": "Power Prompt - Simple (rgthree)",
    "display_name": "Power Prompt - Simple (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "KSampler Config (rgthree)": {
    "input": {
      "required": {
        "steps_total": [
          "INT",
          {
            "default": 30,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "refiner_step": [
          "INT",
          {
            "default": 24,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.5
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "steps_total",
        "refiner_step",
        "cfg",
        "sampler_name",
        "scheduler"
      ]
    },
    "output": [
      "INT",
      "INT",
      "FLOAT",
      [
        "euler",
        "euler_cfg_pp",
        "euler_ancestral",
        "euler_ancestral_cfg_pp",
        "heun",
        "heunpp2",
        "dpm_2",
        "dpm_2_ancestral",
        "lms",
        "dpm_fast",
        "dpm_adaptive",
        "dpmpp_2s_ancestral",
        "dpmpp_2s_ancestral_cfg_pp",
        "dpmpp_sde",
        "dpmpp_sde_gpu",
        "dpmpp_2m",
        "dpmpp_2m_cfg_pp",
        "dpmpp_2m_sde",
        "dpmpp_2m_sde_gpu",
        "dpmpp_2m_sde_heun",
        "dpmpp_2m_sde_heun_gpu",
        "dpmpp_3m_sde",
        "dpmpp_3m_sde_gpu",
        "ddpm",
        "lcm",
        "ipndm",
        "ipndm_v",
        "deis",
        "res_multistep",
        "res_multistep_cfg_pp",
        "res_multistep_ancestral",
        "res_multistep_ancestral_cfg_pp",
        "gradient_estimation",
        "gradient_estimation_cfg_pp",
        "er_sde",
        "seeds_2",
        "seeds_3",
        "sa_solver",
        "sa_solver_pece",
        "ddim",
        "uni_pc",
        "uni_pc_bh2"
      ],
      [
        "simple",
        "sgm_uniform",
        "karras",
        "exponential",
        "ddim_uniform",
        "beta",
        "normal",
        "linear_quadratic",
        "kl_optimal"
      ]
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "STEPS",
      "REFINER_STEP",
      "CFG",
      "SAMPLER",
      "SCHEDULER"
    ],
    "name": "KSampler Config (rgthree)",
    "display_name": "KSampler Config (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "SDXL Empty Latent Image (rgthree)": {
    "input": {
      "required": {
        "dimensions": [
          [
            "1536 x 640   (landscape)",
            "1344 x 768   (landscape)",
            "1216 x 832   (landscape)",
            "1152 x 896   (landscape)",
            "1024 x 1024  (square)",
            " 896 x 1152  (portrait)",
            " 832 x 1216  (portrait)",
            " 768 x 1344  (portrait)",
            " 640 x 1536  (portrait)"
          ],
          {
            "default": "1024 x 1024  (square)"
          }
        ],
        "clip_scale": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 1.0,
            "max": 10.0,
            "step": 0.5
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "dimensions",
        "clip_scale",
        "batch_size"
      ]
    },
    "output": [
      "LATENT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "CLIP_WIDTH",
      "CLIP_HEIGHT"
    ],
    "name": "SDXL Empty Latent Image (rgthree)",
    "display_name": "SDXL Empty Latent Image (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "SDXL Power Prompt - Positive (rgthree)": {
    "input": {
      "required": {
        "prompt_g": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "prompt_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "opt_model": [
          "MODEL"
        ],
        "opt_clip": [
          "CLIP"
        ],
        "opt_clip_width": [
          "INT",
          {
            "forceInput": true,
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "opt_clip_height": [
          "INT",
          {
            "forceInput": true,
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "insert_lora": [
          [
            "CHOOSE",
            "DISABLE LORAS"
          ]
        ],
        "insert_embedding": [
          [
            "CHOOSE"
          ]
        ],
        "insert_saved": [
          [
            "CHOOSE"
          ]
        ],
        "target_width": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "target_height": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "crop_width": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "crop_height": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ]
      },
      "hidden": {
        "values_insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_g",
        "prompt_l"
      ],
      "optional": [
        "opt_model",
        "opt_clip",
        "opt_clip_width",
        "opt_clip_height",
        "insert_lora",
        "insert_embedding",
        "insert_saved",
        "target_width",
        "target_height",
        "crop_width",
        "crop_height"
      ],
      "hidden": [
        "values_insert_saved"
      ]
    },
    "output": [
      "CONDITIONING",
      "MODEL",
      "CLIP",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "CONDITIONING",
      "MODEL",
      "CLIP",
      "TEXT_G",
      "TEXT_L"
    ],
    "name": "SDXL Power Prompt - Positive (rgthree)",
    "display_name": "SDXL Power Prompt - Positive (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "SDXL Power Prompt - Simple / Negative (rgthree)": {
    "input": {
      "required": {
        "prompt_g": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ],
        "prompt_l": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      },
      "optional": {
        "opt_clip": [
          "CLIP"
        ],
        "opt_clip_width": [
          "INT",
          {
            "forceInput": true,
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "opt_clip_height": [
          "INT",
          {
            "forceInput": true,
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "insert_embedding": [
          [
            "CHOOSE"
          ]
        ],
        "insert_saved": [
          [
            "CHOOSE"
          ]
        ],
        "target_width": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "target_height": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "crop_width": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ],
        "crop_height": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 16384
          }
        ]
      },
      "hidden": {
        "values_insert_saved": [
          [
            "CHOOSE"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "prompt_g",
        "prompt_l"
      ],
      "optional": [
        "opt_clip",
        "opt_clip_width",
        "opt_clip_height",
        "insert_embedding",
        "insert_saved",
        "target_width",
        "target_height",
        "crop_width",
        "crop_height"
      ],
      "hidden": [
        "values_insert_saved"
      ]
    },
    "output": [
      "CONDITIONING",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "CONDITIONING",
      "TEXT_G",
      "TEXT_L"
    ],
    "name": "SDXL Power Prompt - Simple / Negative (rgthree)",
    "display_name": "SDXL Power Prompt - Simple / Negative (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Any Switch (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "*"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "*"
    ],
    "name": "Any Switch (rgthree)",
    "display_name": "Any Switch (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Image Comparer (rgthree)": {
    "input": {
      "required": {},
      "optional": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "image_a",
        "image_b"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Image Comparer (rgthree)",
    "display_name": "Image Comparer (rgthree)",
    "description": "Compares two images with a hover slider, or click from properties.",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": true
  },
  "Power Lora Loader (rgthree)": {
    "input": {
      "required": {},
      "optional": {
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ]
      },
      "hidden": {}
    },
    "input_order": {
      "required": [],
      "optional": [
        "model",
        "clip"
      ],
      "hidden": []
    },
    "output": [
      "MODEL",
      "CLIP"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP"
    ],
    "name": "Power Lora Loader (rgthree)",
    "display_name": "Power Lora Loader (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Power Primitive (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "*"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "*"
    ],
    "name": "Power Primitive (rgthree)",
    "display_name": "Power Primitive (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Image or Latent Size (rgthree)": {
    "input": {
      "required": {},
      "optional": {}
    },
    "input_order": {
      "required": [],
      "optional": []
    },
    "output": [
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "WIDTH",
      "HEIGHT"
    ],
    "name": "Image or Latent Size (rgthree)",
    "display_name": "Image or Latent Size (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Image Resize (rgthree)": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "measurement": [
          [
            "pixels",
            "percentage"
          ]
        ],
        "width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1,
            "tooltip": "The width of the desired resize. A pixel value if measurement is 'pixels' or a 100% scale percentage value if measurement is 'percentage'. Passing '0' will calculate the dimension based on the height."
          }
        ],
        "height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "fit": [
          [
            "crop",
            "pad",
            "contain"
          ],
          {
            "tooltip": "'crop' resizes so the image covers the desired width and height, and center-crops the excess, returning exactly the desired width and height.\n'pad' resizes so the image fits inside the desired width and height, and fills the empty space returning exactly the desired width and height.\n'contain' resizes so the image fits inside the desired width and height, and returns the image with it's new size, with one side liekly smaller than the desired.\n\nNote, if either width or height is '0', the effective fit is 'contain'."
          }
        ],
        "method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "measurement",
        "width",
        "height",
        "fit",
        "method"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "WIDTH",
      "HEIGHT"
    ],
    "name": "Image Resize (rgthree)",
    "display_name": "Image Resize (rgthree)",
    "description": "Resize the image.",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "Power Puter (rgthree)": {
    "input": {
      "required": {},
      "optional": {},
      "hidden": {
        "unique_id": "UNIQUE_ID",
        "extra_pnginfo": "EXTRA_PNGINFO",
        "prompt": "PROMPT",
        "dynprompt": "DYNPROMPT"
      }
    },
    "input_order": {
      "required": [],
      "optional": [],
      "hidden": [
        "unique_id",
        "extra_pnginfo",
        "prompt",
        "dynprompt"
      ]
    },
    "output": [
      "*"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "*"
    ],
    "name": "Power Puter (rgthree)",
    "display_name": "Power Puter (rgthree)",
    "description": "",
    "python_module": "custom_nodes.rgthree-comfy",
    "category": "rgthree",
    "output_node": false
  },
  "DetailDaemonSamplerNode": {
    "input": {
      "required": {
        "sampler": [
          "SAMPLER"
        ],
        "detail_amount": [
          "FLOAT",
          {
            "default": 0.1,
            "min": -5.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "start": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "bias": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "exponent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.05
          }
        ],
        "start_offset": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end_offset": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "fade": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "smooth": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "cfg_scale_override": [
          "FLOAT",
          {
            "default": 0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.5,
            "round": 0.01,
            "tooltip": "If set to 0, the sampler will automatically determine the CFG scale (if possible). Set to some other value to override."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sampler",
        "detail_amount",
        "start",
        "end",
        "bias",
        "exponent",
        "start_offset",
        "end_offset",
        "fade",
        "smooth",
        "cfg_scale_override"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "name": "DetailDaemonSamplerNode",
    "display_name": "Detail Daemon Sampler",
    "description": "This sampler wrapper works by adjusting the sigma passed to the model, while the rest of sampling stays the same.",
    "python_module": "custom_nodes.comfyui-detail-daemon",
    "category": "sampling/custom_sampling/samplers",
    "output_node": false
  },
  "DetailDaemonGraphSigmasNode": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {
            "forceInput": true
          }
        ],
        "detail_amount": [
          "FLOAT",
          {
            "default": 0.1,
            "min": -5.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "start": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "bias": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "exponent": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.05
          }
        ],
        "start_offset": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end_offset": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "fade": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "smooth": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.5,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "detail_amount",
        "start",
        "end",
        "bias",
        "exponent",
        "start_offset",
        "end_offset",
        "fade",
        "smooth",
        "cfg_scale"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "DetailDaemonGraphSigmasNode",
    "display_name": "Detail Daemon Graph Sigmas",
    "description": "",
    "python_module": "custom_nodes.comfyui-detail-daemon",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": true
  },
  "MultiplySigmas": {
    "input": {
      "required": {
        "sigmas": [
          "SIGMAS",
          {
            "forceInput": true
          }
        ],
        "factor": [
          "FLOAT",
          {
            "default": 1,
            "min": 0,
            "max": 100,
            "step": 0.001
          }
        ],
        "start": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1,
            "step": 0.001
          }
        ],
        "end": [
          "FLOAT",
          {
            "default": 1,
            "min": 0,
            "max": 1,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sigmas",
        "factor",
        "start",
        "end"
      ]
    },
    "output": [
      "SIGMAS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SIGMAS"
    ],
    "name": "MultiplySigmas",
    "display_name": "Multiply Sigmas (stateless)",
    "description": "",
    "python_module": "custom_nodes.comfyui-detail-daemon",
    "category": "sampling/custom_sampling/sigmas",
    "output_node": false
  },
  "LyingSigmaSampler": {
    "input": {
      "required": {
        "sampler": [
          "SAMPLER"
        ],
        "dishonesty_factor": [
          "FLOAT",
          {
            "default": -0.05,
            "min": -0.999,
            "step": 0.01,
            "tooltip": "Multiplier for sigmas passed to the model. -0.05 means we reduce the sigma by 5%."
          }
        ]
      },
      "optional": {
        "start_percent": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "end_percent": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "sampler",
        "dishonesty_factor"
      ],
      "optional": [
        "start_percent",
        "end_percent"
      ]
    },
    "output": [
      "SAMPLER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAMPLER"
    ],
    "name": "LyingSigmaSampler",
    "display_name": "Lying Sigma Sampler",
    "description": "",
    "python_module": "custom_nodes.comfyui-detail-daemon",
    "category": "sampling/custom_sampling",
    "output_node": false
  },
  "PulidFluxModelLoader": {
    "input": {
      "required": {
        "pulid_file": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "pulid_file"
      ]
    },
    "output": [
      "PULIDFLUX"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "PULIDFLUX"
    ],
    "name": "PulidFluxModelLoader",
    "display_name": "Load PuLID Flux Model",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-PuLID-Flux-Enhanced",
    "category": "pulid",
    "output_node": false
  },
  "PulidFluxInsightFaceLoader": {
    "input": {
      "required": {
        "provider": [
          [
            "CPU",
            "CUDA",
            "ROCM"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "provider"
      ]
    },
    "output": [
      "FACEANALYSIS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FACEANALYSIS"
    ],
    "name": "PulidFluxInsightFaceLoader",
    "display_name": "Load InsightFace (PuLID Flux)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-PuLID-Flux-Enhanced",
    "category": "pulid",
    "output_node": false
  },
  "PulidFluxEvaClipLoader": {
    "input": {
      "required": {}
    },
    "input_order": {
      "required": []
    },
    "output": [
      "EVA_CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "EVA_CLIP"
    ],
    "name": "PulidFluxEvaClipLoader",
    "display_name": "Load Eva Clip (PuLID Flux)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-PuLID-Flux-Enhanced",
    "category": "pulid",
    "output_node": false
  },
  "ApplyPulidFlux": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "pulid_flux": [
          "PULIDFLUX"
        ],
        "eva_clip": [
          "EVA_CLIP"
        ],
        "face_analysis": [
          "FACEANALYSIS"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1.0,
            "max": 5.0,
            "step": 0.05
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "fusion": [
          [
            "mean",
            "concat",
            "max",
            "norm_id",
            "max_token",
            "auto_weight",
            "train_weight"
          ]
        ],
        "fusion_weight_max": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 20.0,
            "step": 0.1
          }
        ],
        "fusion_weight_min": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 20.0,
            "step": 0.1
          }
        ],
        "train_step": [
          "INT",
          {
            "default": 1000,
            "min": 0,
            "max": 20000,
            "step": 1
          }
        ],
        "use_gray": [
          "BOOLEAN",
          {
            "default": true,
            "label_on": "enabled",
            "label_off": "disabled"
          }
        ]
      },
      "optional": {
        "attn_mask": [
          "MASK"
        ],
        "prior_image": [
          "IMAGE"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "model",
        "pulid_flux",
        "eva_clip",
        "face_analysis",
        "image",
        "weight",
        "start_at",
        "end_at",
        "fusion",
        "fusion_weight_max",
        "fusion_weight_min",
        "train_step",
        "use_gray"
      ],
      "optional": [
        "attn_mask",
        "prior_image"
      ],
      "hidden": [
        "unique_id"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ApplyPulidFlux",
    "display_name": "Apply PuLID Flux",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-PuLID-Flux-Enhanced",
    "category": "pulid",
    "output_node": false
  },
  "InstantIDModelLoader": {
    "input": {
      "required": {
        "instantid_file": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "instantid_file"
      ]
    },
    "output": [
      "INSTANTID"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INSTANTID"
    ],
    "name": "InstantIDModelLoader",
    "display_name": "Load InstantID Model",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "InstantIDFaceAnalysis": {
    "input": {
      "required": {
        "provider": [
          [
            "CPU",
            "CUDA",
            "ROCM"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "provider"
      ]
    },
    "output": [
      "FACEANALYSIS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FACEANALYSIS"
    ],
    "name": "InstantIDFaceAnalysis",
    "display_name": "InstantID Face Analysis",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "ApplyInstantID": {
    "input": {
      "required": {
        "instantid": [
          "INSTANTID"
        ],
        "insightface": [
          "FACEANALYSIS"
        ],
        "control_net": [
          "CONTROL_NET"
        ],
        "image": [
          "IMAGE"
        ],
        "model": [
          "MODEL"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "image_kps": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "instantid",
        "insightface",
        "control_net",
        "image",
        "model",
        "positive",
        "negative",
        "weight",
        "start_at",
        "end_at"
      ],
      "optional": [
        "image_kps",
        "mask"
      ]
    },
    "output": [
      "MODEL",
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "positive",
      "negative"
    ],
    "name": "ApplyInstantID",
    "display_name": "Apply InstantID",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "ApplyInstantIDAdvanced": {
    "input": {
      "required": {
        "instantid": [
          "INSTANTID"
        ],
        "insightface": [
          "FACEANALYSIS"
        ],
        "control_net": [
          "CONTROL_NET"
        ],
        "image": [
          "IMAGE"
        ],
        "model": [
          "MODEL"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "ip_weight": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 3.0,
            "step": 0.01
          }
        ],
        "cn_strength": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "noise": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.1
          }
        ],
        "combine_embeds": [
          [
            "average",
            "norm average",
            "concat"
          ],
          {
            "default": "average"
          }
        ]
      },
      "optional": {
        "image_kps": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "instantid",
        "insightface",
        "control_net",
        "image",
        "model",
        "positive",
        "negative",
        "ip_weight",
        "cn_strength",
        "start_at",
        "end_at",
        "noise",
        "combine_embeds"
      ],
      "optional": [
        "image_kps",
        "mask"
      ]
    },
    "output": [
      "MODEL",
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "positive",
      "negative"
    ],
    "name": "ApplyInstantIDAdvanced",
    "display_name": "Apply InstantID Advanced",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "FaceKeypointsPreprocessor": {
    "input": {
      "required": {
        "faceanalysis": [
          "FACEANALYSIS"
        ],
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "faceanalysis",
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "FaceKeypointsPreprocessor",
    "display_name": "Face Keypoints Preprocessor",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "InstantIDAttentionPatch": {
    "input": {
      "required": {
        "instantid": [
          "INSTANTID"
        ],
        "insightface": [
          "FACEANALYSIS"
        ],
        "image": [
          "IMAGE"
        ],
        "model": [
          "MODEL"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1.0,
            "max": 3.0,
            "step": 0.01
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "noise": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.1
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "instantid",
        "insightface",
        "image",
        "model",
        "weight",
        "start_at",
        "end_at",
        "noise"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "MODEL",
      "FACE_EMBEDS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "FACE_EMBEDS"
    ],
    "name": "InstantIDAttentionPatch",
    "display_name": "InstantID Patch Attention",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "ApplyInstantIDControlNet": {
    "input": {
      "required": {
        "face_embeds": [
          "FACE_EMBEDS"
        ],
        "control_net": [
          "CONTROL_NET"
        ],
        "image_kps": [
          "IMAGE"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "face_embeds",
        "control_net",
        "image_kps",
        "positive",
        "negative",
        "strength",
        "start_at",
        "end_at"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive",
      "negative"
    ],
    "name": "ApplyInstantIDControlNet",
    "display_name": "InstantID Apply ControlNet",
    "description": "",
    "python_module": "custom_nodes.comfyui_instantid",
    "category": "InstantID",
    "output_node": false
  },
  "AILab_QwenVL": {
    "input": {
      "required": {
        "model_name": [
          [
            "Qwen3-VL-2B-Instruct",
            "Qwen3-VL-2B-Thinking",
            "Qwen3-VL-2B-Instruct-FP8",
            "Qwen3-VL-2B-Thinking-FP8",
            "Qwen3-VL-4B-Instruct",
            "Qwen3-VL-4B-Thinking",
            "Qwen3-VL-4B-Instruct-FP8",
            "Qwen3-VL-4B-Thinking-FP8",
            "Qwen3-VL-8B-Instruct",
            "Qwen3-VL-8B-Thinking",
            "Qwen3-VL-8B-Instruct-FP8",
            "Qwen3-VL-8B-Thinking-FP8",
            "Qwen3-VL-32B-Instruct",
            "Qwen3-VL-32B-Thinking",
            "Qwen3-VL-32B-Instruct-FP8",
            "Qwen3-VL-32B-Thinking-FP8",
            "Qwen2.5-VL-3B-Instruct",
            "Qwen2.5-VL-7B-Instruct",
            "Qwen3-VL-8B-Instruct-abliterated",
            "Qwen3-VL-8B-NSFW-Caption-V4.5"
          ],
          {
            "default": "Qwen3-VL-2B-Instruct",
            "tooltip": "Pick the Qwen-VL checkpoint. First run downloads weights into models/LLM/Qwen-VL, so leave disk space."
          }
        ],
        "quantization": [
          [
            "4-bit (VRAM-friendly)",
            "8-bit (Balanced)",
            "None (FP16)"
          ],
          {
            "default": "None (FP16)",
            "tooltip": "Precision vs VRAM. FP16 gives the best quality if memory allows; 8-bit suits 816 GB GPUs; 4-bit fits 6 GB or lower but is slower."
          }
        ],
        "attention_mode": [
          [
            "auto",
            "flash_attention_2",
            "sdpa"
          ],
          {
            "default": "auto",
            "tooltip": "auto tries flash-attn v2 when installed and falls back to SDPA. Only override when debugging attention backends."
          }
        ],
        "preset_prompt": [
          [
            " Tags",
            " Simple Description",
            " Detailed Description",
            " Ultra Detailed Description",
            " Cinematic Description",
            " Detailed Analysis",
            " Video Summary",
            " Short Story",
            " Prompt Refine & Expand"
          ],
          {
            "default": " Detailed Description",
            "tooltip": "Built-in instruction describing how Qwen-VL should analyze the media input."
          }
        ],
        "custom_prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "tooltip": "Optional overridewhen filled it completely replaces the preset template."
          }
        ],
        "max_tokens": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 2048,
            "tooltip": "Maximum number of new tokens to decode. Larger values yield longer answers but consume more time and memory."
          }
        ],
        "keep_model_loaded": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Keeps the model resident in VRAM/RAM after the run so the next prompt skips loading."
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4294967295,
            "tooltip": "Seed controlling sampling and frame picking; reuse it to reproduce results."
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ],
        "video": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "quantization",
        "attention_mode",
        "preset_prompt",
        "custom_prompt",
        "max_tokens",
        "keep_model_loaded",
        "seed"
      ],
      "optional": [
        "image",
        "video"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "RESPONSE"
    ],
    "name": "AILab_QwenVL",
    "display_name": "QwenVL",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-QwenVL",
    "category": "AILab/QwenVL",
    "output_node": false
  },
  "AILab_QwenVL_Advanced": {
    "input": {
      "required": {
        "model_name": [
          [
            "Qwen3-VL-2B-Instruct",
            "Qwen3-VL-2B-Thinking",
            "Qwen3-VL-2B-Instruct-FP8",
            "Qwen3-VL-2B-Thinking-FP8",
            "Qwen3-VL-4B-Instruct",
            "Qwen3-VL-4B-Thinking",
            "Qwen3-VL-4B-Instruct-FP8",
            "Qwen3-VL-4B-Thinking-FP8",
            "Qwen3-VL-8B-Instruct",
            "Qwen3-VL-8B-Thinking",
            "Qwen3-VL-8B-Instruct-FP8",
            "Qwen3-VL-8B-Thinking-FP8",
            "Qwen3-VL-32B-Instruct",
            "Qwen3-VL-32B-Thinking",
            "Qwen3-VL-32B-Instruct-FP8",
            "Qwen3-VL-32B-Thinking-FP8",
            "Qwen2.5-VL-3B-Instruct",
            "Qwen2.5-VL-7B-Instruct",
            "Qwen3-VL-8B-Instruct-abliterated",
            "Qwen3-VL-8B-NSFW-Caption-V4.5"
          ],
          {
            "default": "Qwen3-VL-2B-Instruct",
            "tooltip": "Pick the Qwen-VL checkpoint. First run downloads weights into models/LLM/Qwen-VL, so leave disk space."
          }
        ],
        "quantization": [
          [
            "4-bit (VRAM-friendly)",
            "8-bit (Balanced)",
            "None (FP16)"
          ],
          {
            "default": "None (FP16)",
            "tooltip": "Precision vs VRAM. FP16 gives the best quality if memory allows; 8-bit suits 816 GB GPUs; 4-bit fits 6 GB or lower but is slower."
          }
        ],
        "attention_mode": [
          [
            "auto",
            "flash_attention_2",
            "sdpa"
          ],
          {
            "default": "auto",
            "tooltip": "auto tries flash-attn v2 when installed and falls back to SDPA. Only override when debugging attention backends."
          }
        ],
        "use_torch_compile": [
          "BOOLEAN",
          {
            "default": false,
            "tooltip": "Enable torch.compile('reduce-overhead') on supported CUDA/Torch 2.1+ builds for extra throughput after the first compile."
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "mps",
            "cuda:0"
          ],
          {
            "default": "auto",
            "tooltip": "Choose where to run the model: auto, cpu, mps, or cuda:x for multi-GPU systems."
          }
        ],
        "preset_prompt": [
          [
            " Tags",
            " Simple Description",
            " Detailed Description",
            " Ultra Detailed Description",
            " Cinematic Description",
            " Detailed Analysis",
            " Video Summary",
            " Short Story",
            " Prompt Refine & Expand"
          ],
          {
            "default": " Detailed Description",
            "tooltip": "Built-in instruction describing how Qwen-VL should analyze the media input."
          }
        ],
        "custom_prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "tooltip": "Optional overridewhen filled it completely replaces the preset template."
          }
        ],
        "max_tokens": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096,
            "tooltip": "Maximum number of new tokens to decode. Larger values yield longer answers but consume more time and memory."
          }
        ],
        "temperature": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.1,
            "max": 1.0,
            "tooltip": "Sampling randomness when num_beams == 1. 0.20.4 is focused, 0.7+ is creative."
          }
        ],
        "top_p": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 1.0,
            "tooltip": "Nucleus sampling cutoff when num_beams == 1. Lower values keep only top tokens; 0.90.95 allows more variety."
          }
        ],
        "num_beams": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 8,
            "tooltip": "Beam-search width. Values >1 disable temperature/top_p and trade speed for more stable answers."
          }
        ],
        "repetition_penalty": [
          "FLOAT",
          {
            "default": 1.2,
            "min": 0.5,
            "max": 2.0,
            "tooltip": "Values >1 (e.g., 1.11.3) penalize repeated phrases; 1.0 leaves logits untouched."
          }
        ],
        "frame_count": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "max": 64,
            "tooltip": "Number of frames extracted from video inputs before prompting Qwen-VL. More frames provide context but cost time."
          }
        ],
        "keep_model_loaded": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Keeps the model resident in VRAM/RAM after the run so the next prompt skips loading."
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4294967295,
            "tooltip": "Seed controlling sampling and frame picking; reuse it to reproduce results."
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ],
        "video": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "quantization",
        "attention_mode",
        "use_torch_compile",
        "device",
        "preset_prompt",
        "custom_prompt",
        "max_tokens",
        "temperature",
        "top_p",
        "num_beams",
        "repetition_penalty",
        "frame_count",
        "keep_model_loaded",
        "seed"
      ],
      "optional": [
        "image",
        "video"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "RESPONSE"
    ],
    "name": "AILab_QwenVL_Advanced",
    "display_name": "QwenVL (Advanced)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-QwenVL",
    "category": "AILab/QwenVL",
    "output_node": false
  },
  "AILab_QwenVL_GGUF": {
    "input": {
      "required": {
        "model_name": [
          [
            "Qwen3VL-4B-Instruct-F16.gguf",
            "Qwen3VL-4B-Instruct-Q4_K_M.gguf",
            "Qwen3VL-4B-Instruct-Q8_0.gguf",
            "Qwen3VL-4B-Thinking-F16.gguf",
            "Qwen3VL-4B-Thinking-Q4_K_M.gguf",
            "Qwen3VL-4B-Thinking-Q8_0.gguf",
            "Qwen3VL-8B-Instruct-F16.gguf",
            "Qwen3VL-8B-Instruct-Q4_K_M.gguf",
            "Qwen3VL-8B-Instruct-Q8_0.gguf",
            "Qwen3VL-8B-Thinking-F16.gguf",
            "Qwen3VL-8B-Thinking-Q4_K_M.gguf",
            "Qwen3VL-8B-Thinking-Q8_0.gguf"
          ],
          {
            "default": "Qwen3VL-4B-Instruct-F16.gguf"
          }
        ],
        "preset_prompt": [
          [
            " Tags",
            " Simple Description",
            " Detailed Description",
            " Ultra Detailed Description",
            " Cinematic Description",
            " Detailed Analysis",
            " Video Summary",
            " Short Story",
            " Prompt Refine & Expand"
          ],
          {
            "default": " Detailed Description"
          }
        ],
        "custom_prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "max_tokens": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 2048
          }
        ],
        "keep_model_loaded": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4294967295
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ],
        "video": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "preset_prompt",
        "custom_prompt",
        "max_tokens",
        "keep_model_loaded",
        "seed"
      ],
      "optional": [
        "image",
        "video"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "RESPONSE"
    ],
    "name": "AILab_QwenVL_GGUF",
    "display_name": "QwenVL (GGUF)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-QwenVL",
    "category": "AILab/QwenVL",
    "output_node": false
  },
  "AILab_QwenVL_GGUF_Advanced": {
    "input": {
      "required": {
        "model_name": [
          [
            "Qwen3VL-4B-Instruct-F16.gguf",
            "Qwen3VL-4B-Instruct-Q4_K_M.gguf",
            "Qwen3VL-4B-Instruct-Q8_0.gguf",
            "Qwen3VL-4B-Thinking-F16.gguf",
            "Qwen3VL-4B-Thinking-Q4_K_M.gguf",
            "Qwen3VL-4B-Thinking-Q8_0.gguf",
            "Qwen3VL-8B-Instruct-F16.gguf",
            "Qwen3VL-8B-Instruct-Q4_K_M.gguf",
            "Qwen3VL-8B-Instruct-Q8_0.gguf",
            "Qwen3VL-8B-Thinking-F16.gguf",
            "Qwen3VL-8B-Thinking-Q4_K_M.gguf",
            "Qwen3VL-8B-Thinking-Q8_0.gguf"
          ],
          {
            "default": "Qwen3VL-4B-Instruct-F16.gguf"
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "mps",
            "cuda:0"
          ],
          {
            "default": "auto"
          }
        ],
        "preset_prompt": [
          [
            " Tags",
            " Simple Description",
            " Detailed Description",
            " Ultra Detailed Description",
            " Cinematic Description",
            " Detailed Analysis",
            " Video Summary",
            " Short Story",
            " Prompt Refine & Expand"
          ],
          {
            "default": " Detailed Description"
          }
        ],
        "custom_prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "max_tokens": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096
          }
        ],
        "temperature": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.0,
            "max": 2.0
          }
        ],
        "top_p": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "repetition_penalty": [
          "FLOAT",
          {
            "default": 1.2,
            "min": 0.5,
            "max": 2.0
          }
        ],
        "frame_count": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "max": 64
          }
        ],
        "ctx": [
          "INT",
          {
            "default": 8192,
            "min": 1024,
            "max": 262144,
            "step": 512
          }
        ],
        "n_batch": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 32768,
            "step": 64
          }
        ],
        "gpu_layers": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 200
          }
        ],
        "image_max_tokens": [
          "INT",
          {
            "default": 4096,
            "min": 256,
            "max": 1024000,
            "step": 256
          }
        ],
        "top_k": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 32768
          }
        ],
        "pool_size": [
          "INT",
          {
            "default": 4194304,
            "min": 1048576,
            "max": 10485760,
            "step": 524288
          }
        ],
        "keep_model_loaded": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4294967295
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ],
        "video": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "device",
        "preset_prompt",
        "custom_prompt",
        "max_tokens",
        "temperature",
        "top_p",
        "repetition_penalty",
        "frame_count",
        "ctx",
        "n_batch",
        "gpu_layers",
        "image_max_tokens",
        "top_k",
        "pool_size",
        "keep_model_loaded",
        "seed"
      ],
      "optional": [
        "image",
        "video"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "RESPONSE"
    ],
    "name": "AILab_QwenVL_GGUF_Advanced",
    "display_name": "QwenVL Advanced (GGUF)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-QwenVL",
    "category": "AILab/QwenVL",
    "output_node": false
  },
  "AILab_QwenVL_PromptEnhancer": {
    "input": {
      "required": {
        "model_name": [
          [
            "Qwen3-0.6B",
            "qwen3-4b-Z-Image-Engineer",
            "Qwen3-4B-Instruct-2507",
            "Qwen3-VL-2B-Instruct",
            "Qwen3-VL-2B-Thinking",
            "Qwen3-VL-2B-Instruct-FP8",
            "Qwen3-VL-2B-Thinking-FP8",
            "Qwen3-VL-4B-Instruct",
            "Qwen3-VL-4B-Thinking",
            "Qwen3-VL-4B-Instruct-FP8",
            "Qwen3-VL-4B-Thinking-FP8",
            "Qwen3-VL-8B-Instruct",
            "Qwen3-VL-8B-Thinking",
            "Qwen3-VL-8B-Instruct-FP8",
            "Qwen3-VL-8B-Thinking-FP8",
            "Qwen3-VL-32B-Instruct",
            "Qwen3-VL-32B-Thinking",
            "Qwen3-VL-32B-Instruct-FP8",
            "Qwen3-VL-32B-Thinking-FP8",
            "Qwen2.5-VL-3B-Instruct",
            "Qwen2.5-VL-7B-Instruct",
            "Qwen3-VL-8B-Instruct-abliterated",
            "Qwen3-VL-8B-NSFW-Caption-V4.5"
          ],
          {
            "default": "Qwen3-0.6B",
            "tooltip": "Pick the Qwen-VL checkpoint. First run downloads weights into models/LLM/Qwen-VL, so leave disk space."
          }
        ],
        "quantization": [
          [
            "4-bit (VRAM-friendly)",
            "8-bit (Balanced)",
            "None (FP16)"
          ],
          {
            "default": "None (FP16)",
            "tooltip": "Precision vs VRAM. FP16 gives the best quality if memory allows; 8-bit suits 816 GB GPUs; 4-bit fits 6 GB or lower but is slower."
          }
        ],
        "attention_mode": [
          [
            "auto",
            "flash_attention_2",
            "sdpa"
          ],
          {
            "default": "auto",
            "tooltip": "auto tries flash-attn v2 when installed and falls back to SDPA. Only override when debugging attention backends."
          }
        ],
        "use_torch_compile": [
          "BOOLEAN",
          {
            "default": false,
            "tooltip": "Enable torch.compile('reduce-overhead') on supported CUDA/Torch 2.1+ builds for extra throughput after the first compile."
          }
        ],
        "device": [
          [
            "auto",
            "cuda",
            "cpu",
            "mps"
          ],
          {
            "default": "auto",
            "tooltip": "Choose where to run the model: auto, cpu, mps, or cuda:x for multi-GPU systems."
          }
        ],
        "prompt_text": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "tooltip": "Prompt text to enhance. Leave blank to just emit the preset instruction."
          }
        ],
        "enhancement_style": [
          [
            " Enhance",
            " Refine",
            " Creative Rewrite",
            " Detailed Visual",
            " Artistic Style",
            " Technical Specs"
          ],
          {
            "default": " Enhance"
          }
        ],
        "custom_system_prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ],
        "max_tokens": [
          "INT",
          {
            "default": 256,
            "min": 32,
            "max": 1024
          }
        ],
        "temperature": [
          "FLOAT",
          {
            "default": 0.7,
            "min": 0.1,
            "max": 1.0
          }
        ],
        "top_p": [
          "FLOAT",
          {
            "default": 0.9,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "repetition_penalty": [
          "FLOAT",
          {
            "default": 1.1,
            "min": 0.5,
            "max": 2.0
          }
        ],
        "keep_model_loaded": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4294967295
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name",
        "quantization",
        "attention_mode",
        "use_torch_compile",
        "device",
        "prompt_text",
        "enhancement_style",
        "custom_system_prompt",
        "max_tokens",
        "temperature",
        "top_p",
        "repetition_penalty",
        "keep_model_loaded",
        "seed"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "ENHANCED_OUTPUT"
    ],
    "name": "AILab_QwenVL_PromptEnhancer",
    "display_name": "QwenVL Prompt Enhancer",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-QwenVL",
    "category": "AILab/QwenVL",
    "output_node": false
  },
  "AnimeFace_SemSegPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "remove_background_using_abg": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 512,
            "max": 512,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "remove_background_using_abg",
        "resolution"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "ABG_CHARACTER_MASK (MASK)"
    ],
    "name": "AnimeFace_SemSegPreprocessor",
    "display_name": "Anime Face Segmentor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Semantic Segmentation",
    "output_node": false
  },
  "AnyLineArtPreprocessor_aux": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "merge_with_lineart": [
          [
            "lineart_standard",
            "lineart_realisitic",
            "lineart_anime",
            "manga_line"
          ],
          {
            "default": "lineart_standard"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 1280,
            "min": 64,
            "max": 16384,
            "step": 8
          }
        ],
        "lineart_lower_bound": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "lineart_upper_bound": [
          "FLOAT",
          {
            "default": 1,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "object_min_size": [
          "INT",
          {
            "default": 36,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "object_connectivity": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "merge_with_lineart",
        "resolution",
        "lineart_lower_bound",
        "lineart_upper_bound",
        "object_min_size",
        "object_connectivity"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "AnyLineArtPreprocessor_aux",
    "display_name": "AnyLine Lineart",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "BinaryPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "bin_threshold": [
          "INT",
          {
            "default": 100,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "bin_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "BinaryPreprocessor",
    "display_name": "Binary Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "CannyEdgePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "low_threshold": [
          "INT",
          {
            "default": 100,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "high_threshold": [
          "INT",
          {
            "default": 200,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "low_threshold",
        "high_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "CannyEdgePreprocessor",
    "display_name": "Canny Edge",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "ColorPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ColorPreprocessor",
    "display_name": "Color Pallete",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/T2IAdapter-only",
    "output_node": false
  },
  "DensePosePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "model": [
          [
            "densepose_r50_fpn_dl.torchscript",
            "densepose_r101_fpn_dl.torchscript"
          ],
          {
            "default": "densepose_r50_fpn_dl.torchscript"
          }
        ],
        "cmap": [
          [
            "Viridis (MagicAnimate)",
            "Parula (CivitAI)"
          ],
          {
            "default": "Viridis (MagicAnimate)"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "model",
        "cmap",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "DensePosePreprocessor",
    "display_name": "DensePose Estimator",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Faces and Poses Estimators",
    "output_node": false
  },
  "DepthAnythingPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "ckpt_name": [
          [
            "depth_anything_vitl14.pth",
            "depth_anything_vitb14.pth",
            "depth_anything_vits14.pth"
          ],
          {
            "default": "depth_anything_vitl14.pth"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "ckpt_name",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "DepthAnythingPreprocessor",
    "display_name": "Depth Anything",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "Zoe_DepthAnythingPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "environment": [
          [
            "indoor",
            "outdoor"
          ],
          {
            "default": "indoor"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "environment",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Zoe_DepthAnythingPreprocessor",
    "display_name": "Zoe Depth Anything",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "DepthAnythingV2Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "ckpt_name": [
          [
            "depth_anything_v2_vitg.pth",
            "depth_anything_v2_vitl.pth",
            "depth_anything_v2_vitb.pth",
            "depth_anything_v2_vits.pth"
          ],
          {
            "default": "depth_anything_v2_vitl.pth"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "ckpt_name",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "DepthAnythingV2Preprocessor",
    "display_name": "Depth Anything V2 - Relative",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "DiffusionEdge_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "environment": [
          [
            "indoor",
            "urban",
            "natrual"
          ],
          {
            "default": "indoor"
          }
        ],
        "patch_batch_size": [
          "INT",
          {
            "default": 4,
            "min": 1,
            "max": 16,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "environment",
        "patch_batch_size",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "DiffusionEdge_Preprocessor",
    "display_name": "Diffusion Edge (batch size  => speed , VRAM )",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "DSINE-NormalMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "fov": [
          "FLOAT",
          {
            "default": 60.0,
            "min": 0,
            "max": 365.0,
            "step": 0.01
          }
        ],
        "iterations": [
          "INT",
          {
            "default": 5,
            "min": 1,
            "max": 20,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "fov",
        "iterations",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "DSINE-NormalMapPreprocessor",
    "display_name": "DSINE Normal Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "DWPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "detect_hand": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "detect_body": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "detect_face": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ],
        "bbox_detector": [
          [
            "None",
            "yolox_l.torchscript.pt",
            "yolox_l.onnx",
            "yolo_nas_l_fp16.onnx",
            "yolo_nas_m_fp16.onnx",
            "yolo_nas_s_fp16.onnx"
          ],
          {
            "default": "yolox_l.onnx"
          }
        ],
        "pose_estimator": [
          [
            "dw-ll_ucoco_384_bs5.torchscript.pt",
            "dw-ll_ucoco_384.onnx",
            "dw-ll_ucoco.onnx"
          ],
          {
            "default": "dw-ll_ucoco_384_bs5.torchscript.pt"
          }
        ],
        "scale_stick_for_xinsr_cn": [
          [
            "disable",
            "enable"
          ],
          {
            "default": "disable"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "detect_hand",
        "detect_body",
        "detect_face",
        "resolution",
        "bbox_detector",
        "pose_estimator",
        "scale_stick_for_xinsr_cn"
      ]
    },
    "output": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "name": "DWPreprocessor",
    "display_name": "DWPose Estimator",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Faces and Poses Estimators",
    "output_node": false
  },
  "AnimalPosePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "bbox_detector": [
          [
            "None",
            "yolox_l.torchscript.pt",
            "yolox_l.onnx",
            "yolo_nas_l_fp16.onnx",
            "yolo_nas_m_fp16.onnx",
            "yolo_nas_s_fp16.onnx"
          ],
          {
            "default": "yolox_l.torchscript.pt"
          }
        ],
        "pose_estimator": [
          [
            "rtmpose-m_ap10k_256_bs5.torchscript.pt",
            "rtmpose-m_ap10k_256.onnx"
          ],
          {
            "default": "rtmpose-m_ap10k_256_bs5.torchscript.pt"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "bbox_detector",
        "pose_estimator",
        "resolution"
      ]
    },
    "output": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "name": "AnimalPosePreprocessor",
    "display_name": "AnimalPose Estimator (AP10K)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Faces and Poses Estimators",
    "output_node": false
  },
  "HEDPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "safe": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "safe",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "HEDPreprocessor",
    "display_name": "HED Soft-Edge Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "FakeScribblePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "safe": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "safe",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "FakeScribblePreprocessor",
    "display_name": "Fake Scribble Lines (aka scribble_hed)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "InpaintPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ]
      },
      "optional": {
        "black_pixel_for_xinsir_cn": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mask"
      ],
      "optional": [
        "black_pixel_for_xinsir_cn"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "InpaintPreprocessor",
    "display_name": "Inpaint Preprocessor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/others",
    "output_node": false
  },
  "LeReS-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "rm_nearest": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "rm_background": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "boost": [
          [
            "disable",
            "enable"
          ],
          {
            "default": "disable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "rm_nearest",
        "rm_background",
        "boost",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "LeReS-DepthMapPreprocessor",
    "display_name": "LeReS Depth Map (enable boost for leres++)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "LineArtPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "coarse": [
          [
            "disable",
            "enable"
          ],
          {
            "default": "disable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "coarse",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "LineArtPreprocessor",
    "display_name": "Realistic Lineart",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "AnimeLineArtPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "AnimeLineArtPreprocessor",
    "display_name": "Anime Lineart",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "LineartStandardPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "guassian_sigma": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0,
            "max": 100.0,
            "step": 0.01
          }
        ],
        "intensity_threshold": [
          "INT",
          {
            "default": 8,
            "min": 0,
            "max": 16,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "guassian_sigma",
        "intensity_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "LineartStandardPreprocessor",
    "display_name": "Standard Lineart",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "Manga2Anime_LineArt_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Manga2Anime_LineArt_Preprocessor",
    "display_name": "Manga Lineart (aka lineart_anime_denoise)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "MediaPipe-FaceMeshPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "max_faces": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 50,
            "step": 1
          }
        ],
        "min_confidence": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.1,
            "max": 1,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "max_faces",
        "min_confidence",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "MediaPipe-FaceMeshPreprocessor",
    "display_name": "MediaPipe Face Mesh",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Faces and Poses Estimators",
    "output_node": false
  },
  "MeshGraphormer-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "mask_bbox_padding": [
          "INT",
          {
            "default": 30,
            "min": 0,
            "max": 100
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ],
        "mask_type": [
          [
            "based_on_depth",
            "tight_bboxes",
            "original"
          ],
          {
            "default": "based_on_depth"
          }
        ],
        "mask_expand": [
          "INT",
          {
            "default": 5,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "rand_seed": [
          "INT",
          {
            "default": 88,
            "min": 0,
            "max": 18446744073709551615,
            "step": 1
          }
        ],
        "detect_thr": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.1,
            "max": 1,
            "step": 0.01
          }
        ],
        "presence_thr": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0.1,
            "max": 1,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "mask_bbox_padding",
        "resolution",
        "mask_type",
        "mask_expand",
        "rand_seed",
        "detect_thr",
        "presence_thr"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "INPAINTING_MASK"
    ],
    "name": "MeshGraphormer-DepthMapPreprocessor",
    "display_name": "MeshGraphormer Hand Refiner",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "MeshGraphormer+ImpactDetector-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "bbox_detector": [
          "BBOX_DETECTOR"
        ]
      },
      "optional": {
        "bbox_threshold": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.1,
            "max": 1,
            "step": 0.01
          }
        ],
        "bbox_dilation": [
          "INT",
          {
            "default": 10,
            "min": -512,
            "max": 512,
            "step": 1
          }
        ],
        "bbox_crop_factor": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 1.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "drop_size": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "mask_bbox_padding": [
          "INT",
          {
            "default": 30,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "mask_type": [
          [
            "based_on_depth",
            "tight_bboxes",
            "original"
          ],
          {
            "default": "based_on_depth"
          }
        ],
        "mask_expand": [
          "INT",
          {
            "default": 5,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "rand_seed": [
          "INT",
          {
            "default": 88,
            "min": 0,
            "max": 18446744073709551615,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "bbox_detector"
      ],
      "optional": [
        "bbox_threshold",
        "bbox_dilation",
        "bbox_crop_factor",
        "drop_size",
        "mask_bbox_padding",
        "mask_type",
        "mask_expand",
        "rand_seed",
        "resolution"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "INPAINTING_MASK"
    ],
    "name": "MeshGraphormer+ImpactDetector-DepthMapPreprocessor",
    "display_name": "MeshGraphormer Hand Refiner With External Detector",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "Metric3D-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "backbone": [
          [
            "vit-small",
            "vit-large",
            "vit-giant2"
          ],
          {
            "default": "vit-small"
          }
        ],
        "fx": [
          "INT",
          {
            "default": 1000,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "fy": [
          "INT",
          {
            "default": 1000,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "backbone",
        "fx",
        "fy",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Metric3D-DepthMapPreprocessor",
    "display_name": "Metric3D Depth Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "Metric3D-NormalMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "backbone": [
          [
            "vit-small",
            "vit-large",
            "vit-giant2"
          ],
          {
            "default": "vit-small"
          }
        ],
        "fx": [
          "INT",
          {
            "default": 1000,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "fy": [
          "INT",
          {
            "default": 1000,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "backbone",
        "fx",
        "fy",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Metric3D-NormalMapPreprocessor",
    "display_name": "Metric3D Normal Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "MiDaS-NormalMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "a": [
          "FLOAT",
          {
            "default": 6.283185307179586,
            "min": 0.0,
            "max": 15.707963267948966,
            "step": 0.01
          }
        ],
        "bg_threshold": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "a",
        "bg_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "MiDaS-NormalMapPreprocessor",
    "display_name": "MiDaS Normal Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "MiDaS-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "a": [
          "FLOAT",
          {
            "default": 6.283185307179586,
            "min": 0.0,
            "max": 15.707963267948966,
            "step": 0.01
          }
        ],
        "bg_threshold": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "a",
        "bg_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "MiDaS-DepthMapPreprocessor",
    "display_name": "MiDaS Depth Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "M-LSDPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "score_threshold": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.01,
            "max": 2.0,
            "step": 0.01
          }
        ],
        "dist_threshold": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.01,
            "max": 20.0,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "score_threshold",
        "dist_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "M-LSDPreprocessor",
    "display_name": "M-LSD Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "BAE-NormalMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "BAE-NormalMapPreprocessor",
    "display_name": "BAE Normal Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "OneFormer-COCO-SemSegPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "OneFormer-COCO-SemSegPreprocessor",
    "display_name": "OneFormer COCO Segmentor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Semantic Segmentation",
    "output_node": false
  },
  "OneFormer-ADE20K-SemSegPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "OneFormer-ADE20K-SemSegPreprocessor",
    "display_name": "OneFormer ADE20K Segmentor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Semantic Segmentation",
    "output_node": false
  },
  "OpenposePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "detect_hand": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "detect_body": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "detect_face": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ],
        "scale_stick_for_xinsr_cn": [
          [
            "disable",
            "enable"
          ],
          {
            "default": "disable"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "detect_hand",
        "detect_body",
        "detect_face",
        "resolution",
        "scale_stick_for_xinsr_cn"
      ]
    },
    "output": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "POSE_KEYPOINT"
    ],
    "name": "OpenposePreprocessor",
    "display_name": "OpenPose Pose",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Faces and Poses Estimators",
    "output_node": false
  },
  "PiDiNetPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "safe": [
          [
            "enable",
            "disable"
          ],
          {
            "default": "enable"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "safe",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "PiDiNetPreprocessor",
    "display_name": "PiDiNet Soft-Edge Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "SavePoseKpsAsJsonFile": {
    "input": {
      "required": {
        "pose_kps": [
          "POSE_KEYPOINT"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "PoseKeypoint"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pose_kps",
        "filename_prefix"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "SavePoseKpsAsJsonFile",
    "display_name": "Save Pose Keypoints",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Pose Keypoint Postprocess",
    "output_node": true
  },
  "FacialPartColoringFromPoseKps": {
    "input": {
      "required": {
        "pose_kps": [
          "POSE_KEYPOINT"
        ],
        "mode": [
          [
            "point",
            "polygon"
          ],
          {
            "default": "polygon"
          }
        ],
        "skin": [
          "STRING",
          {
            "default": "rgb(0, 153, 255)",
            "multiline": false
          }
        ],
        "left_eye": [
          "STRING",
          {
            "default": "rgb(0, 204, 153)",
            "multiline": false
          }
        ],
        "right_eye": [
          "STRING",
          {
            "default": "rgb(255, 153, 0)",
            "multiline": false
          }
        ],
        "nose": [
          "STRING",
          {
            "default": "rgb(255, 102, 255)",
            "multiline": false
          }
        ],
        "upper_lip": [
          "STRING",
          {
            "default": "rgb(102, 0, 51)",
            "multiline": false
          }
        ],
        "inner_mouth": [
          "STRING",
          {
            "default": "rgb(255, 204, 255)",
            "multiline": false
          }
        ],
        "lower_lip": [
          "STRING",
          {
            "default": "rgb(255, 0, 102)",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pose_kps",
        "mode",
        "skin",
        "left_eye",
        "right_eye",
        "nose",
        "upper_lip",
        "inner_mouth",
        "lower_lip"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "FacialPartColoringFromPoseKps",
    "display_name": "Colorize Facial Parts from PoseKPS",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Pose Keypoint Postprocess",
    "output_node": false
  },
  "UpperBodyTrackingFromPoseKps": {
    "input": {
      "required": {
        "pose_kps": [
          "POSE_KEYPOINT"
        ],
        "id_include": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "Head_width_height": [
          "STRING",
          {
            "default": "256, 256",
            "multiline": false
          }
        ],
        "Neck_width_height": [
          "STRING",
          {
            "default": "100, 100",
            "multiline": false
          }
        ],
        "Shoulder_width_height": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "Torso_width_height": [
          "STRING",
          {
            "default": "350, 450",
            "multiline": false
          }
        ],
        "RArm_width_height": [
          "STRING",
          {
            "default": "128, 256",
            "multiline": false
          }
        ],
        "RForearm_width_height": [
          "STRING",
          {
            "default": "128, 256",
            "multiline": false
          }
        ],
        "LArm_width_height": [
          "STRING",
          {
            "default": "128, 256",
            "multiline": false
          }
        ],
        "LForearm_width_height": [
          "STRING",
          {
            "default": "128, 256",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pose_kps",
        "id_include",
        "Head_width_height",
        "Neck_width_height",
        "Shoulder_width_height",
        "Torso_width_height",
        "RArm_width_height",
        "RForearm_width_height",
        "LArm_width_height",
        "LForearm_width_height"
      ]
    },
    "output": [
      "TRACKING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "tracking",
      "prompt"
    ],
    "name": "UpperBodyTrackingFromPoseKps",
    "display_name": "Upper Body Tracking From PoseKps (InstanceDiffusion)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Pose Keypoint Postprocess",
    "output_node": false
  },
  "RenderPeopleKps": {
    "input": {
      "required": {
        "kps": [
          "POSE_KEYPOINT"
        ],
        "render_body": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "render_hand": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "render_face": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "kps",
        "render_body",
        "render_hand",
        "render_face"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "RenderPeopleKps",
    "display_name": "Render Pose JSON (Human)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Pose Keypoint Postprocess",
    "output_node": false
  },
  "RenderAnimalKps": {
    "input": {
      "required": {
        "kps": [
          "POSE_KEYPOINT"
        ]
      }
    },
    "input_order": {
      "required": [
        "kps"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "RenderAnimalKps",
    "display_name": "Render Pose JSON (Animal)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Pose Keypoint Postprocess",
    "output_node": false
  },
  "PyraCannyPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "low_threshold": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "high_threshold": [
          "INT",
          {
            "default": 128,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "low_threshold",
        "high_threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "PyraCannyPreprocessor",
    "display_name": "PyraCanny",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "ImageLuminanceDetector": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "gamma_correction": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 2.0,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "gamma_correction",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageLuminanceDetector",
    "display_name": "Image Luminance",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Recolor",
    "output_node": false
  },
  "ImageIntensityDetector": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "gamma_correction": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.1,
            "max": 2.0,
            "step": 0.01
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "gamma_correction",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageIntensityDetector",
    "display_name": "Image Intensity",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Recolor",
    "output_node": false
  },
  "ScribblePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ScribblePreprocessor",
    "display_name": "Scribble Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "Scribble_XDoG_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "threshold": [
          "INT",
          {
            "default": 32,
            "min": 1,
            "max": 64,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "threshold",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Scribble_XDoG_Preprocessor",
    "display_name": "Scribble XDoG Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "Scribble_PiDiNet_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "safe": [
          [
            "enable",
            "disable"
          ]
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "safe",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Scribble_PiDiNet_Preprocessor",
    "display_name": "Scribble PiDiNet Lines",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "SAMPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "SAMPreprocessor",
    "display_name": "SAM Segmentor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/others",
    "output_node": false
  },
  "ShufflePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ShufflePreprocessor",
    "display_name": "Content Shuffle",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/T2IAdapter-only",
    "output_node": false
  },
  "TEEDPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "safe_steps": [
          "INT",
          {
            "default": 2,
            "min": 0,
            "max": 10,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "safe_steps",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "TEEDPreprocessor",
    "display_name": "TEEDPreprocessor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Line Extractors",
    "output_node": false
  },
  "TilePreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "pyrUp_iters": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 10,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "pyrUp_iters",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "TilePreprocessor",
    "display_name": "Tile",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/tile",
    "output_node": false
  },
  "TTPlanet_TileGF_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "scale_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 1.0,
            "max": 8.0,
            "step": 0.01
          }
        ],
        "blur_strength": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 1.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "radius": [
          "INT",
          {
            "default": 7,
            "min": 1,
            "max": 20,
            "step": 1
          }
        ],
        "eps": [
          "FLOAT",
          {
            "default": 0.01,
            "min": 0.001,
            "max": 0.1,
            "step": 0.001
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "scale_factor",
        "blur_strength",
        "radius",
        "eps",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "TTPlanet_TileGF_Preprocessor",
    "display_name": "TTPlanet Tile GuidedFilter",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/tile",
    "output_node": false
  },
  "TTPlanet_TileSimple_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "scale_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 1.0,
            "max": 8.0,
            "step": 0.01
          }
        ],
        "blur_strength": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 1.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "scale_factor",
        "blur_strength"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "TTPlanet_TileSimple_Preprocessor",
    "display_name": "TTPlanet Tile Simple",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/tile",
    "output_node": false
  },
  "UniFormer-SemSegPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "UniFormer-SemSegPreprocessor",
    "display_name": "UniFormer Segmentor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Semantic Segmentation",
    "output_node": false
  },
  "SemSegPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "SemSegPreprocessor",
    "display_name": "Semantic Segmentor (legacy, alias for UniFormer)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Semantic Segmentation",
    "output_node": false
  },
  "Unimatch_OptFlowPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "ckpt_name": [
          [
            "gmflow-scale1-mixdata.pth",
            "gmflow-scale2-mixdata.pth",
            "gmflow-scale2-regrefine6-mixdata.pth"
          ],
          {
            "default": "gmflow-scale2-regrefine6-mixdata.pth"
          }
        ],
        "backward_flow": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "bidirectional_flow": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "ckpt_name",
        "backward_flow",
        "bidirectional_flow"
      ]
    },
    "output": [
      "OPTICAL_FLOW",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "OPTICAL_FLOW",
      "PREVIEW_IMAGE"
    ],
    "name": "Unimatch_OptFlowPreprocessor",
    "display_name": "Unimatch Optical Flow",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Optical Flow",
    "output_node": false
  },
  "MaskOptFlow": {
    "input": {
      "required": {
        "optical_flow": [
          "OPTICAL_FLOW"
        ],
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "optical_flow",
        "mask"
      ]
    },
    "output": [
      "OPTICAL_FLOW",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "OPTICAL_FLOW",
      "PREVIEW_IMAGE"
    ],
    "name": "MaskOptFlow",
    "display_name": "Mask Optical Flow (DragNUWA)",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Optical Flow",
    "output_node": false
  },
  "Zoe-DepthMapPreprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Zoe-DepthMapPreprocessor",
    "display_name": "Zoe Depth Map",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors/Normal and Depth Estimators",
    "output_node": false
  },
  "AIO_Preprocessor": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "preprocessor": [
          [
            "none",
            "AnimeFace_SemSegPreprocessor",
            "AnyLineArtPreprocessor_aux",
            "BinaryPreprocessor",
            "CannyEdgePreprocessor",
            "ColorPreprocessor",
            "DensePosePreprocessor",
            "DepthAnythingPreprocessor",
            "Zoe_DepthAnythingPreprocessor",
            "DepthAnythingV2Preprocessor",
            "DSINE-NormalMapPreprocessor",
            "DWPreprocessor",
            "AnimalPosePreprocessor",
            "HEDPreprocessor",
            "FakeScribblePreprocessor",
            "LeReS-DepthMapPreprocessor",
            "LineArtPreprocessor",
            "AnimeLineArtPreprocessor",
            "LineartStandardPreprocessor",
            "Manga2Anime_LineArt_Preprocessor",
            "MediaPipe-FaceMeshPreprocessor",
            "MeshGraphormer-DepthMapPreprocessor",
            "Metric3D-DepthMapPreprocessor",
            "Metric3D-NormalMapPreprocessor",
            "MiDaS-NormalMapPreprocessor",
            "MiDaS-DepthMapPreprocessor",
            "M-LSDPreprocessor",
            "BAE-NormalMapPreprocessor",
            "OneFormer-COCO-SemSegPreprocessor",
            "OneFormer-ADE20K-SemSegPreprocessor",
            "OpenposePreprocessor",
            "PiDiNetPreprocessor",
            "PyraCannyPreprocessor",
            "ImageLuminanceDetector",
            "ImageIntensityDetector",
            "ScribblePreprocessor",
            "Scribble_XDoG_Preprocessor",
            "Scribble_PiDiNet_Preprocessor",
            "SAMPreprocessor",
            "ShufflePreprocessor",
            "TEEDPreprocessor",
            "TilePreprocessor",
            "TTPlanet_TileGF_Preprocessor",
            "TTPlanet_TileSimple_Preprocessor",
            "UniFormer-SemSegPreprocessor",
            "SemSegPreprocessor",
            "Zoe-DepthMapPreprocessor"
          ],
          {
            "default": "none"
          }
        ],
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "preprocessor",
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "AIO_Preprocessor",
    "display_name": "AIO Aux Preprocessor",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "ControlNetPreprocessorSelector": {
    "input": {
      "required": {
        "preprocessor": [
          [
            "none",
            "AnimeFace_SemSegPreprocessor",
            "AnyLineArtPreprocessor_aux",
            "BinaryPreprocessor",
            "CannyEdgePreprocessor",
            "ColorPreprocessor",
            "DensePosePreprocessor",
            "DepthAnythingPreprocessor",
            "Zoe_DepthAnythingPreprocessor",
            "DepthAnythingV2Preprocessor",
            "DSINE-NormalMapPreprocessor",
            "DWPreprocessor",
            "AnimalPosePreprocessor",
            "HEDPreprocessor",
            "FakeScribblePreprocessor",
            "LeReS-DepthMapPreprocessor",
            "LineArtPreprocessor",
            "AnimeLineArtPreprocessor",
            "LineartStandardPreprocessor",
            "Manga2Anime_LineArt_Preprocessor",
            "MediaPipe-FaceMeshPreprocessor",
            "MeshGraphormer-DepthMapPreprocessor",
            "Metric3D-DepthMapPreprocessor",
            "Metric3D-NormalMapPreprocessor",
            "MiDaS-NormalMapPreprocessor",
            "MiDaS-DepthMapPreprocessor",
            "M-LSDPreprocessor",
            "BAE-NormalMapPreprocessor",
            "OneFormer-COCO-SemSegPreprocessor",
            "OneFormer-ADE20K-SemSegPreprocessor",
            "OpenposePreprocessor",
            "PiDiNetPreprocessor",
            "PyraCannyPreprocessor",
            "ImageLuminanceDetector",
            "ImageIntensityDetector",
            "ScribblePreprocessor",
            "Scribble_XDoG_Preprocessor",
            "Scribble_PiDiNet_Preprocessor",
            "SAMPreprocessor",
            "ShufflePreprocessor",
            "TEEDPreprocessor",
            "TilePreprocessor",
            "TTPlanet_TileGF_Preprocessor",
            "TTPlanet_TileSimple_Preprocessor",
            "UniFormer-SemSegPreprocessor",
            "SemSegPreprocessor",
            "Zoe-DepthMapPreprocessor"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "preprocessor"
      ]
    },
    "output": [
      [
        "none",
        "AnimeFace_SemSegPreprocessor",
        "AnyLineArtPreprocessor_aux",
        "BinaryPreprocessor",
        "CannyEdgePreprocessor",
        "ColorPreprocessor",
        "DensePosePreprocessor",
        "DepthAnythingPreprocessor",
        "Zoe_DepthAnythingPreprocessor",
        "DepthAnythingV2Preprocessor",
        "DSINE-NormalMapPreprocessor",
        "DWPreprocessor",
        "AnimalPosePreprocessor",
        "HEDPreprocessor",
        "FakeScribblePreprocessor",
        "LeReS-DepthMapPreprocessor",
        "LineArtPreprocessor",
        "AnimeLineArtPreprocessor",
        "LineartStandardPreprocessor",
        "Manga2Anime_LineArt_Preprocessor",
        "MediaPipe-FaceMeshPreprocessor",
        "MeshGraphormer-DepthMapPreprocessor",
        "Metric3D-DepthMapPreprocessor",
        "Metric3D-NormalMapPreprocessor",
        "MiDaS-NormalMapPreprocessor",
        "MiDaS-DepthMapPreprocessor",
        "M-LSDPreprocessor",
        "BAE-NormalMapPreprocessor",
        "OneFormer-COCO-SemSegPreprocessor",
        "OneFormer-ADE20K-SemSegPreprocessor",
        "OpenposePreprocessor",
        "PiDiNetPreprocessor",
        "PyraCannyPreprocessor",
        "ImageLuminanceDetector",
        "ImageIntensityDetector",
        "ScribblePreprocessor",
        "Scribble_XDoG_Preprocessor",
        "Scribble_PiDiNet_Preprocessor",
        "SAMPreprocessor",
        "ShufflePreprocessor",
        "TEEDPreprocessor",
        "TilePreprocessor",
        "TTPlanet_TileGF_Preprocessor",
        "TTPlanet_TileSimple_Preprocessor",
        "UniFormer-SemSegPreprocessor",
        "SemSegPreprocessor",
        "Zoe-DepthMapPreprocessor"
      ]
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "preprocessor"
    ],
    "name": "ControlNetPreprocessorSelector",
    "display_name": "Preprocessor Selector",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "PixelPerfectResolution": {
    "input": {
      "required": {
        "original_image": [
          "IMAGE"
        ],
        "image_gen_width": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 8192,
            "step": 8
          }
        ],
        "image_gen_height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 8192,
            "step": 8
          }
        ],
        "resize_mode": [
          [
            "Just Resize",
            "Crop and Resize",
            "Resize and Fill"
          ],
          {
            "default": "Just Resize"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "original_image",
        "image_gen_width",
        "image_gen_height",
        "resize_mode"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "RESOLUTION (INT)"
    ],
    "name": "PixelPerfectResolution",
    "display_name": "Pixel Perfect Resolution",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "ImageGenResolutionFromImage": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE_GEN_WIDTH (INT)",
      "IMAGE_GEN_HEIGHT (INT)"
    ],
    "name": "ImageGenResolutionFromImage",
    "display_name": "Generation Resolution From Image",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "ImageGenResolutionFromLatent": {
    "input": {
      "required": {
        "latent": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "latent"
      ]
    },
    "output": [
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE_GEN_WIDTH (INT)",
      "IMAGE_GEN_HEIGHT (INT)"
    ],
    "name": "ImageGenResolutionFromLatent",
    "display_name": "Generation Resolution From Latent",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "HintImageEnchance": {
    "input": {
      "required": {
        "hint_image": [
          "IMAGE"
        ],
        "image_gen_width": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 8192,
            "step": 8
          }
        ],
        "image_gen_height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 8192,
            "step": 8
          }
        ],
        "resize_mode": [
          [
            "Just Resize",
            "Crop and Resize",
            "Resize and Fill"
          ],
          {
            "default": "Just Resize"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "hint_image",
        "image_gen_width",
        "image_gen_height",
        "resize_mode"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "HintImageEnchance",
    "display_name": "Enchance And Resize Hint Images",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "ExecuteAllControlNetPreprocessors": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      },
      "optional": {
        "resolution": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 16384,
            "step": 64
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ],
      "optional": [
        "resolution"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ExecuteAllControlNetPreprocessors",
    "display_name": "Execute All ControlNet Preprocessors",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "ControlNetAuxSimpleAddText": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "text"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ControlNetAuxSimpleAddText",
    "display_name": "ControlNetAuxSimpleAddText",
    "description": "",
    "python_module": "custom_nodes.comfyui_controlnet_aux",
    "category": "ControlNet Preprocessors",
    "output_node": false
  },
  "IPAdapter": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "weight_type": [
          [
            "standard",
            "prompt is more important",
            "style transfer"
          ]
        ]
      },
      "optional": {
        "attn_mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "start_at",
        "end_at",
        "weight_type"
      ],
      "optional": [
        "attn_mask"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapter",
    "display_name": "IPAdapter",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter",
    "output_node": false
  },
  "IPAdapterAdvanced": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_type",
        "combine_embeds",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterAdvanced",
    "display_name": "IPAdapter Advanced",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter",
    "output_node": false
  },
  "IPAdapterBatch": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ],
        "encode_batch_size": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096
          }
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_type",
        "start_at",
        "end_at",
        "embeds_scaling",
        "encode_batch_size"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterBatch",
    "display_name": "IPAdapter Batch (Adv.)",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter",
    "output_node": false
  },
  "IPAdapterFaceID": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_faceidv2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5.0,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ],
        "insightface": [
          "INSIGHTFACE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_faceidv2",
        "weight_type",
        "combine_embeds",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision",
        "insightface"
      ]
    },
    "output": [
      "MODEL",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "face_image"
    ],
    "name": "IPAdapterFaceID",
    "display_name": "IPAdapter FaceID",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/faceid",
    "output_node": false
  },
  "IPAAdapterFaceIDBatch": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_faceidv2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5.0,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ],
        "insightface": [
          "INSIGHTFACE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_faceidv2",
        "weight_type",
        "combine_embeds",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision",
        "insightface"
      ]
    },
    "output": [
      "MODEL",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "face_image"
    ],
    "name": "IPAAdapterFaceIDBatch",
    "display_name": "IPAdapter FaceID Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/faceid",
    "output_node": false
  },
  "IPAdapterTiled": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "sharpening": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_type",
        "combine_embeds",
        "start_at",
        "end_at",
        "sharpening",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL",
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "tiles",
      "masks"
    ],
    "name": "IPAdapterTiled",
    "display_name": "IPAdapter Tiled",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/tiled",
    "output_node": false
  },
  "IPAdapterTiledBatch": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "sharpening": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ],
        "encode_batch_size": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096
          }
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_type",
        "start_at",
        "end_at",
        "sharpening",
        "embeds_scaling",
        "encode_batch_size"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL",
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "tiles",
      "masks"
    ],
    "name": "IPAdapterTiledBatch",
    "display_name": "IPAdapter Tiled Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/tiled",
    "output_node": false
  },
  "IPAdapterEmbeds": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "pos_embed": [
          "EMBEDS"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "neg_embed": [
          "EMBEDS"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "pos_embed",
        "weight",
        "weight_type",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "neg_embed",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterEmbeds",
    "display_name": "IPAdapter Embeds",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": false
  },
  "IPAdapterEmbedsBatch": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "pos_embed": [
          "EMBEDS"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 3,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "neg_embed": [
          "EMBEDS"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "pos_embed",
        "weight",
        "weight_type",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "neg_embed",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterEmbedsBatch",
    "display_name": "IPAdapter Embeds Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": false
  },
  "IPAdapterStyleComposition": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image_style": [
          "IMAGE"
        ],
        "image_composition": [
          "IMAGE"
        ],
        "weight_style": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "weight_composition": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "expand_style": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ],
          {
            "default": "average"
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image_style",
        "image_composition",
        "weight_style",
        "weight_composition",
        "expand_style",
        "combine_embeds",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterStyleComposition",
    "display_name": "IPAdapter Style & Composition SDXL",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/style_composition",
    "output_node": false
  },
  "IPAdapterStyleCompositionBatch": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image_style": [
          "IMAGE"
        ],
        "image_composition": [
          "IMAGE"
        ],
        "weight_style": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "weight_composition": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "expand_style": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image_style",
        "image_composition",
        "weight_style",
        "weight_composition",
        "expand_style",
        "start_at",
        "end_at",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterStyleCompositionBatch",
    "display_name": "IPAdapter Style & Composition Batch SDXL",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/style_composition",
    "output_node": false
  },
  "IPAdapterMS": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5,
            "step": 0.05
          }
        ],
        "weight_faceidv2": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1,
            "max": 5.0,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ],
        "layer_weights": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "attn_mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ],
        "insightface": [
          "INSIGHTFACE"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "image",
        "weight",
        "weight_faceidv2",
        "weight_type",
        "combine_embeds",
        "start_at",
        "end_at",
        "embeds_scaling",
        "layer_weights"
      ],
      "optional": [
        "image_negative",
        "attn_mask",
        "clip_vision",
        "insightface"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterMS",
    "display_name": "IPAdapter Mad Scientist",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/dev",
    "output_node": false
  },
  "IPAdapterFromParams": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "ipadapter": [
          "IPADAPTER"
        ],
        "ipadapter_params": [
          "IPADAPTER_PARAMS"
        ],
        "combine_embeds": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average"
          ]
        ],
        "embeds_scaling": [
          [
            "V only",
            "K+V",
            "K+V w/ C penalty",
            "K+mean(V) w/ C penalty"
          ]
        ]
      },
      "optional": {
        "image_negative": [
          "IMAGE"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "ipadapter",
        "ipadapter_params",
        "combine_embeds",
        "embeds_scaling"
      ],
      "optional": [
        "image_negative",
        "clip_vision"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "IPAdapterFromParams",
    "display_name": "IPAdapter from Params",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/params",
    "output_node": false
  },
  "IPAdapterUnifiedLoader": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "preset": [
          [
            "LIGHT - SD1.5 only (low strength)",
            "STANDARD (medium strength)",
            "VIT-G (medium strength)",
            "PLUS (high strength)",
            "PLUS FACE (portraits)",
            "FULL FACE - SD1.5 only (portraits stronger)"
          ]
        ]
      },
      "optional": {
        "ipadapter": [
          "IPADAPTER"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "preset"
      ],
      "optional": [
        "ipadapter"
      ]
    },
    "output": [
      "MODEL",
      "IPADAPTER"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model",
      "ipadapter"
    ],
    "name": "IPAdapterUnifiedLoader",
    "display_name": "IPAdapter Unified Loader",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter",
    "output_node": false
  },
  "IPAdapterUnifiedLoaderFaceID": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "preset": [
          [
            "FACEID",
            "FACEID PLUS - SD1.5 only",
            "FACEID PLUS V2",
            "FACEID PORTRAIT (style transfer)",
            "FACEID PORTRAIT UNNORM - SDXL only (strong)"
          ]
        ],
        "lora_strength": [
          "FLOAT",
          {
            "default": 0.6,
            "min": 0,
            "max": 1,
            "step": 0.01
          }
        ],
        "provider": [
          [
            "CPU",
            "CUDA",
            "ROCM",
            "DirectML",
            "OpenVINO",
            "CoreML"
          ]
        ]
      },
      "optional": {
        "ipadapter": [
          "IPADAPTER"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "preset",
        "lora_strength",
        "provider"
      ],
      "optional": [
        "ipadapter"
      ]
    },
    "output": [
      "MODEL",
      "IPADAPTER"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "ipadapter"
    ],
    "name": "IPAdapterUnifiedLoaderFaceID",
    "display_name": "IPAdapter Unified Loader FaceID",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/faceid",
    "output_node": false
  },
  "IPAdapterModelLoader": {
    "input": {
      "required": {
        "ipadapter_file": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "ipadapter_file"
      ]
    },
    "output": [
      "IPADAPTER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IPADAPTER"
    ],
    "name": "IPAdapterModelLoader",
    "display_name": "IPAdapter Model Loader",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/loaders",
    "output_node": false
  },
  "IPAdapterInsightFaceLoader": {
    "input": {
      "required": {
        "provider": [
          [
            "CPU",
            "CUDA",
            "ROCM"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "provider"
      ]
    },
    "output": [
      "INSIGHTFACE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INSIGHTFACE"
    ],
    "name": "IPAdapterInsightFaceLoader",
    "display_name": "IPAdapter InsightFace Loader",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/loaders",
    "output_node": false
  },
  "IPAdapterUnifiedLoaderCommunity": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "preset": [
          [
            "Composition"
          ]
        ]
      },
      "optional": {
        "ipadapter": [
          "IPADAPTER"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "preset"
      ],
      "optional": [
        "ipadapter"
      ]
    },
    "output": [
      "MODEL",
      "IPADAPTER"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "model",
      "ipadapter"
    ],
    "name": "IPAdapterUnifiedLoaderCommunity",
    "display_name": "IPAdapter Unified Loader Community",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/loaders",
    "output_node": false
  },
  "IPAdapterEncoder": {
    "input": {
      "required": {
        "ipadapter": [
          "IPADAPTER"
        ],
        "image": [
          "IMAGE"
        ],
        "weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1.0,
            "max": 3.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "clip_vision": [
          "CLIP_VISION"
        ]
      }
    },
    "input_order": {
      "required": [
        "ipadapter",
        "image",
        "weight"
      ],
      "optional": [
        "mask",
        "clip_vision"
      ]
    },
    "output": [
      "EMBEDS",
      "EMBEDS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "pos_embed",
      "neg_embed"
    ],
    "name": "IPAdapterEncoder",
    "display_name": "IPAdapter Encoder",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": false
  },
  "IPAdapterCombineEmbeds": {
    "input": {
      "required": {
        "embed1": [
          "EMBEDS"
        ],
        "method": [
          [
            "concat",
            "add",
            "subtract",
            "average",
            "norm average",
            "max",
            "min"
          ]
        ]
      },
      "optional": {
        "embed2": [
          "EMBEDS"
        ],
        "embed3": [
          "EMBEDS"
        ],
        "embed4": [
          "EMBEDS"
        ],
        "embed5": [
          "EMBEDS"
        ]
      }
    },
    "input_order": {
      "required": [
        "embed1",
        "method"
      ],
      "optional": [
        "embed2",
        "embed3",
        "embed4",
        "embed5"
      ]
    },
    "output": [
      "EMBEDS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "EMBEDS"
    ],
    "name": "IPAdapterCombineEmbeds",
    "display_name": "IPAdapter Combine Embeds",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": false
  },
  "IPAdapterNoise": {
    "input": {
      "required": {
        "type": [
          [
            "fade",
            "dissolve",
            "gaussian",
            "shuffle"
          ]
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0,
            "max": 1,
            "step": 0.05
          }
        ],
        "blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 32,
            "step": 1
          }
        ]
      },
      "optional": {
        "image_optional": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "type",
        "strength",
        "blur"
      ],
      "optional": [
        "image_optional"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "IPAdapterNoise",
    "display_name": "IPAdapter Noise",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/utils",
    "output_node": false
  },
  "PrepImageForClipVision": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "interpolation": [
          [
            "LANCZOS",
            "BICUBIC",
            "HAMMING",
            "BILINEAR",
            "BOX",
            "NEAREST"
          ]
        ],
        "crop_position": [
          [
            "top",
            "bottom",
            "left",
            "right",
            "center",
            "pad"
          ]
        ],
        "sharpening": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0,
            "max": 1,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "interpolation",
        "crop_position",
        "sharpening"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "PrepImageForClipVision",
    "display_name": "Prep Image For ClipVision",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/utils",
    "output_node": false
  },
  "IPAdapterSaveEmbeds": {
    "input": {
      "required": {
        "embeds": [
          "EMBEDS"
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "IP_embeds"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "embeds",
        "filename_prefix"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "IPAdapterSaveEmbeds",
    "display_name": "IPAdapter Save Embeds",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": true
  },
  "IPAdapterLoadEmbeds": {
    "input": {
      "required": {
        "embeds": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "embeds"
      ]
    },
    "output": [
      "EMBEDS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "EMBEDS"
    ],
    "name": "IPAdapterLoadEmbeds",
    "display_name": "IPAdapter Load Embeds",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/embeds",
    "output_node": false
  },
  "IPAdapterWeights": {
    "input": {
      "required": {
        "weights": [
          "STRING",
          {
            "default": "1.0, 0.0",
            "multiline": true
          }
        ],
        "timing": [
          [
            "custom",
            "linear",
            "ease_in_out",
            "ease_in",
            "ease_out",
            "random"
          ],
          {
            "default": "linear"
          }
        ],
        "frames": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9999,
            "step": 1
          }
        ],
        "start_frame": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9999,
            "step": 1
          }
        ],
        "end_frame": [
          "INT",
          {
            "default": 9999,
            "min": 0,
            "max": 9999,
            "step": 1
          }
        ],
        "add_starting_frames": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9999,
            "step": 1
          }
        ],
        "add_ending_frames": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9999,
            "step": 1
          }
        ],
        "method": [
          [
            "full batch",
            "shift batches",
            "alternate batches"
          ],
          {
            "default": "full batch"
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "weights",
        "timing",
        "frames",
        "start_frame",
        "end_frame",
        "add_starting_frames",
        "add_ending_frames",
        "method"
      ],
      "optional": [
        "image"
      ]
    },
    "output": [
      "FLOAT",
      "FLOAT",
      "INT",
      "IMAGE",
      "IMAGE",
      "WEIGHTS_STRATEGY"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "weights",
      "weights_invert",
      "total_frames",
      "image_1",
      "image_2",
      "weights_strategy"
    ],
    "name": "IPAdapterWeights",
    "display_name": "IPAdapter Weights",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/weights",
    "output_node": false
  },
  "IPAdapterCombineWeights": {
    "input": {
      "required": {
        "weights_1": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "weights_2": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "weights_1",
        "weights_2"
      ]
    },
    "output": [
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "weights",
      "count"
    ],
    "name": "IPAdapterCombineWeights",
    "display_name": "IPAdapter Combine Weights",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/utils",
    "output_node": false
  },
  "IPAdapterWeightsFromStrategy": {
    "input": {
      "required": {
        "weights_strategy": [
          "WEIGHTS_STRATEGY"
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "weights_strategy"
      ],
      "optional": [
        "image"
      ]
    },
    "output": [
      "FLOAT",
      "FLOAT",
      "INT",
      "IMAGE",
      "IMAGE",
      "WEIGHTS_STRATEGY"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "weights",
      "weights_invert",
      "total_frames",
      "image_1",
      "image_2",
      "weights_strategy"
    ],
    "name": "IPAdapterWeightsFromStrategy",
    "display_name": "IPAdapter Weights From Strategy",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/weights",
    "output_node": false
  },
  "IPAdapterPromptScheduleFromWeightsStrategy": {
    "input": {
      "required": {
        "weights_strategy": [
          "WEIGHTS_STRATEGY"
        ],
        "prompt": [
          "STRING",
          {
            "default": "",
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "weights_strategy",
        "prompt"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "prompt_schedule"
    ],
    "name": "IPAdapterPromptScheduleFromWeightsStrategy",
    "display_name": "Prompt Schedule From Weights Strategy",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/weights",
    "output_node": false
  },
  "IPAdapterRegionalConditioning": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "image_weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1.0,
            "max": 3.0,
            "step": 0.05
          }
        ],
        "prompt_weight": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.05
          }
        ],
        "weight_type": [
          [
            "linear",
            "ease in",
            "ease out",
            "ease in-out",
            "reverse in-out",
            "weak input",
            "weak output",
            "weak middle",
            "strong middle",
            "style transfer",
            "composition",
            "strong style transfer"
          ]
        ],
        "start_at": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "end_at": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "image_weight",
        "prompt_weight",
        "weight_type",
        "start_at",
        "end_at"
      ],
      "optional": [
        "mask",
        "positive",
        "negative"
      ]
    },
    "output": [
      "IPADAPTER_PARAMS",
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IPADAPTER_PARAMS",
      "POSITIVE",
      "NEGATIVE"
    ],
    "name": "IPAdapterRegionalConditioning",
    "display_name": "IPAdapter Regional Conditioning",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/params",
    "output_node": false
  },
  "IPAdapterCombineParams": {
    "input": {
      "required": {
        "params_1": [
          "IPADAPTER_PARAMS"
        ],
        "params_2": [
          "IPADAPTER_PARAMS"
        ]
      },
      "optional": {
        "params_3": [
          "IPADAPTER_PARAMS"
        ],
        "params_4": [
          "IPADAPTER_PARAMS"
        ],
        "params_5": [
          "IPADAPTER_PARAMS"
        ]
      }
    },
    "input_order": {
      "required": [
        "params_1",
        "params_2"
      ],
      "optional": [
        "params_3",
        "params_4",
        "params_5"
      ]
    },
    "output": [
      "IPADAPTER_PARAMS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IPADAPTER_PARAMS"
    ],
    "name": "IPAdapterCombineParams",
    "display_name": "IPAdapter Combine Params",
    "description": "",
    "python_module": "custom_nodes.comfyui_ipadapter_plus",
    "category": "ipadapter/params",
    "output_node": false
  },
  "ReActorFaceSwap": {
    "input": {
      "required": {
        "enabled": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "OFF",
            "label_on": "ON"
          }
        ],
        "input_image": [
          "IMAGE"
        ],
        "swap_model": [
          []
        ],
        "facedetection": [
          [
            "retinaface_resnet50",
            "retinaface_mobile0.25",
            "YOLOv5l",
            "YOLOv5n"
          ]
        ],
        "face_restore_model": [
          [
            "none",
            "codeformer-v0.1.0.pth",
            "GFPGANv1.3.pth",
            "GFPGANv1.4.pth",
            "GPEN-BFR-512.onnx"
          ]
        ],
        "face_restore_visibility": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.1,
            "max": 1,
            "step": 0.05
          }
        ],
        "codeformer_weight": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ],
        "detect_gender_input": [
          [
            "no",
            "female",
            "male"
          ],
          {
            "default": "no"
          }
        ],
        "detect_gender_source": [
          [
            "no",
            "female",
            "male"
          ],
          {
            "default": "no"
          }
        ],
        "input_faces_index": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "source_faces_index": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "console_log_level": [
          [
            0,
            1,
            2
          ],
          {
            "default": 1
          }
        ]
      },
      "optional": {
        "source_image": [
          "IMAGE"
        ],
        "face_model": [
          "FACE_MODEL"
        ],
        "face_boost": [
          "FACE_BOOST"
        ]
      },
      "hidden": {
        "faces_order": "FACES_ORDER"
      }
    },
    "input_order": {
      "required": [
        "enabled",
        "input_image",
        "swap_model",
        "facedetection",
        "face_restore_model",
        "face_restore_visibility",
        "codeformer_weight",
        "detect_gender_input",
        "detect_gender_source",
        "input_faces_index",
        "source_faces_index",
        "console_log_level"
      ],
      "optional": [
        "source_image",
        "face_model",
        "face_boost"
      ],
      "hidden": [
        "faces_order"
      ]
    },
    "output": [
      "IMAGE",
      "FACE_MODEL",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "SWAPPED_IMAGE",
      "FACE_MODEL",
      "ORIGINAL_IMAGE"
    ],
    "name": "ReActorFaceSwap",
    "display_name": "ReActor  Fast Face Swap",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorFaceSwapOpt": {
    "input": {
      "required": {
        "enabled": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "OFF",
            "label_on": "ON"
          }
        ],
        "input_image": [
          "IMAGE"
        ],
        "swap_model": [
          []
        ],
        "facedetection": [
          [
            "retinaface_resnet50",
            "retinaface_mobile0.25",
            "YOLOv5l",
            "YOLOv5n"
          ]
        ],
        "face_restore_model": [
          [
            "none",
            "codeformer-v0.1.0.pth",
            "GFPGANv1.3.pth",
            "GFPGANv1.4.pth",
            "GPEN-BFR-512.onnx"
          ]
        ],
        "face_restore_visibility": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.1,
            "max": 1,
            "step": 0.05
          }
        ],
        "codeformer_weight": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ]
      },
      "optional": {
        "source_image": [
          "IMAGE"
        ],
        "face_model": [
          "FACE_MODEL"
        ],
        "options": [
          "OPTIONS"
        ],
        "face_boost": [
          "FACE_BOOST"
        ]
      }
    },
    "input_order": {
      "required": [
        "enabled",
        "input_image",
        "swap_model",
        "facedetection",
        "face_restore_model",
        "face_restore_visibility",
        "codeformer_weight"
      ],
      "optional": [
        "source_image",
        "face_model",
        "options",
        "face_boost"
      ]
    },
    "output": [
      "IMAGE",
      "FACE_MODEL",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "SWAPPED_IMAGE",
      "FACE_MODEL",
      "ORIGINAL_IMAGE"
    ],
    "name": "ReActorFaceSwapOpt",
    "display_name": "ReActor  Fast Face Swap [OPTIONS]",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorOptions": {
    "input": {
      "required": {
        "input_faces_order": [
          [
            "left-right",
            "right-left",
            "top-bottom",
            "bottom-top",
            "small-large",
            "large-small"
          ],
          {
            "default": "large-small"
          }
        ],
        "input_faces_index": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "detect_gender_input": [
          [
            "no",
            "female",
            "male"
          ],
          {
            "default": "no"
          }
        ],
        "source_faces_order": [
          [
            "left-right",
            "right-left",
            "top-bottom",
            "bottom-top",
            "small-large",
            "large-small"
          ],
          {
            "default": "large-small"
          }
        ],
        "source_faces_index": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "detect_gender_source": [
          [
            "no",
            "female",
            "male"
          ],
          {
            "default": "no"
          }
        ],
        "console_log_level": [
          [
            0,
            1,
            2
          ],
          {
            "default": 1
          }
        ],
        "restore_swapped_only": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "no",
            "label_on": "yes"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "input_faces_order",
        "input_faces_index",
        "detect_gender_input",
        "source_faces_order",
        "source_faces_index",
        "detect_gender_source",
        "console_log_level",
        "restore_swapped_only"
      ]
    },
    "output": [
      "OPTIONS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "OPTIONS"
    ],
    "name": "ReActorOptions",
    "display_name": "ReActor  Options",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorFaceBoost": {
    "input": {
      "required": {
        "enabled": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "OFF",
            "label_on": "ON"
          }
        ],
        "boost_model": [
          [
            "none",
            "codeformer-v0.1.0.pth",
            "GFPGANv1.3.pth",
            "GFPGANv1.4.pth",
            "GPEN-BFR-512.onnx"
          ]
        ],
        "interpolation": [
          [
            "Nearest",
            "Bilinear",
            "Bicubic",
            "Lanczos"
          ],
          {
            "default": "Bicubic"
          }
        ],
        "visibility": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.1,
            "max": 1,
            "step": 0.05
          }
        ],
        "codeformer_weight": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ],
        "restore_with_main_after": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "enabled",
        "boost_model",
        "interpolation",
        "visibility",
        "codeformer_weight",
        "restore_with_main_after"
      ]
    },
    "output": [
      "FACE_BOOST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FACE_BOOST"
    ],
    "name": "ReActorFaceBoost",
    "display_name": "ReActor  Face Booster",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorMaskHelper": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "swapped_image": [
          "IMAGE"
        ],
        "bbox_model_name": [
          []
        ],
        "bbox_threshold": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "bbox_dilation": [
          "INT",
          {
            "default": 10,
            "min": -512,
            "max": 512,
            "step": 1
          }
        ],
        "bbox_crop_factor": [
          "FLOAT",
          {
            "default": 3.0,
            "min": 1.0,
            "max": 100,
            "step": 0.1
          }
        ],
        "bbox_drop_size": [
          "INT",
          {
            "min": 1,
            "max": 8192,
            "step": 1,
            "default": 10
          }
        ],
        "sam_model_name": [
          []
        ],
        "sam_dilation": [
          "INT",
          {
            "default": 0,
            "min": -512,
            "max": 512,
            "step": 1
          }
        ],
        "sam_threshold": [
          "FLOAT",
          {
            "default": 0.93,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "bbox_expansion": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 1000,
            "step": 1
          }
        ],
        "mask_hint_threshold": [
          "FLOAT",
          {
            "default": 0.7,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "mask_hint_use_negative": [
          [
            "False",
            "Small",
            "Outter"
          ]
        ],
        "morphology_operation": [
          [
            "dilate",
            "erode",
            "open",
            "close"
          ]
        ],
        "morphology_distance": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 128,
            "step": 1
          }
        ],
        "blur_radius": [
          "INT",
          {
            "default": 9,
            "min": 0,
            "max": 48,
            "step": 1
          }
        ],
        "sigma_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 3.0,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "mask_optional": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "swapped_image",
        "bbox_model_name",
        "bbox_threshold",
        "bbox_dilation",
        "bbox_crop_factor",
        "bbox_drop_size",
        "sam_model_name",
        "sam_dilation",
        "sam_threshold",
        "bbox_expansion",
        "mask_hint_threshold",
        "mask_hint_use_negative",
        "morphology_operation",
        "morphology_distance",
        "blur_radius",
        "sigma_factor"
      ],
      "optional": [
        "mask_optional"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK",
      "MASK_PREVIEW",
      "SWAPPED_FACE"
    ],
    "name": "ReActorMaskHelper",
    "display_name": "ReActor  Masking Helper",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorSetWeight": {
    "input": {
      "required": {
        "input_image": [
          "IMAGE"
        ],
        "faceswap_weight": [
          [
            "0%",
            "12.5%",
            "25%",
            "37.5%",
            "50%",
            "62.5%",
            "75%",
            "87.5%",
            "100%"
          ],
          {
            "default": "50%"
          }
        ]
      },
      "optional": {
        "source_image": [
          "IMAGE"
        ],
        "face_model": [
          "FACE_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "input_image",
        "faceswap_weight"
      ],
      "optional": [
        "source_image",
        "face_model"
      ]
    },
    "output": [
      "IMAGE",
      "FACE_MODEL"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "INPUT_IMAGE",
      "FACE_MODEL"
    ],
    "name": "ReActorSetWeight",
    "display_name": "ReActor  Set Face Swap Weight",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": true
  },
  "ReActorSaveFaceModel": {
    "input": {
      "required": {
        "save_mode": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "OFF",
            "label_on": "ON"
          }
        ],
        "face_model_name": [
          "STRING",
          {
            "default": "default"
          }
        ],
        "select_face_index": [
          "INT",
          {
            "default": 0,
            "min": 0
          }
        ]
      },
      "optional": {
        "image": [
          "IMAGE"
        ],
        "face_model": [
          "FACE_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "save_mode",
        "face_model_name",
        "select_face_index"
      ],
      "optional": [
        "image",
        "face_model"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "ReActorSaveFaceModel",
    "display_name": "Save Face Model  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": true
  },
  "ReActorLoadFaceModel": {
    "input": {
      "required": {
        "face_model": [
          [
            "none"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "face_model"
      ]
    },
    "output": [
      "FACE_MODEL",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "FACE_MODEL",
      "FACE_MODEL_NAME"
    ],
    "name": "ReActorLoadFaceModel",
    "display_name": "Load Face Model  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorBuildFaceModel": {
    "input": {
      "required": {
        "save_mode": [
          "BOOLEAN",
          {
            "default": true,
            "label_off": "OFF",
            "label_on": "ON"
          }
        ],
        "send_only": [
          "BOOLEAN",
          {
            "default": false,
            "label_off": "NO",
            "label_on": "YES"
          }
        ],
        "face_model_name": [
          "STRING",
          {
            "default": "default"
          }
        ],
        "compute_method": [
          [
            "Mean",
            "Median",
            "Mode"
          ],
          {
            "default": "Mean"
          }
        ]
      },
      "optional": {
        "images": [
          "IMAGE"
        ],
        "face_models": [
          "FACE_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "save_mode",
        "send_only",
        "face_model_name",
        "compute_method"
      ],
      "optional": [
        "images",
        "face_models"
      ]
    },
    "output": [
      "FACE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FACE_MODEL"
    ],
    "name": "ReActorBuildFaceModel",
    "display_name": "Build Blended Face Model  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": true
  },
  "ReActorMakeFaceModelBatch": {
    "input": {
      "required": {
        "face_model1": [
          "FACE_MODEL"
        ]
      },
      "optional": {
        "face_model2": [
          "FACE_MODEL"
        ],
        "face_model3": [
          "FACE_MODEL"
        ],
        "face_model4": [
          "FACE_MODEL"
        ],
        "face_model5": [
          "FACE_MODEL"
        ],
        "face_model6": [
          "FACE_MODEL"
        ],
        "face_model7": [
          "FACE_MODEL"
        ],
        "face_model8": [
          "FACE_MODEL"
        ],
        "face_model9": [
          "FACE_MODEL"
        ],
        "face_model10": [
          "FACE_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "face_model1"
      ],
      "optional": [
        "face_model2",
        "face_model3",
        "face_model4",
        "face_model5",
        "face_model6",
        "face_model7",
        "face_model8",
        "face_model9",
        "face_model10"
      ]
    },
    "output": [
      "FACE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FACE_MODELS"
    ],
    "name": "ReActorMakeFaceModelBatch",
    "display_name": "Make Face Model Batch  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorRestoreFace": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "facedetection": [
          [
            "retinaface_resnet50",
            "retinaface_mobile0.25",
            "YOLOv5l",
            "YOLOv5n"
          ]
        ],
        "model": [
          [
            "none",
            "codeformer-v0.1.0.pth",
            "GFPGANv1.3.pth",
            "GFPGANv1.4.pth",
            "GPEN-BFR-512.onnx"
          ]
        ],
        "visibility": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ],
        "codeformer_weight": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "facedetection",
        "model",
        "visibility",
        "codeformer_weight"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ReActorRestoreFace",
    "display_name": "Restore Face  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorRestoreFaceAdvanced": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "facedetection": [
          [
            "retinaface_resnet50",
            "retinaface_mobile0.25",
            "YOLOv5l",
            "YOLOv5n"
          ]
        ],
        "model": [
          [
            "none",
            "codeformer-v0.1.0.pth",
            "GFPGANv1.3.pth",
            "GFPGANv1.4.pth",
            "GPEN-BFR-512.onnx"
          ]
        ],
        "visibility": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ],
        "codeformer_weight": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1,
            "step": 0.05
          }
        ],
        "face_selection": [
          [
            "all",
            "filter",
            "largest"
          ],
          {
            "default": "all"
          }
        ]
      },
      "optional": {
        "sort_by": [
          [
            "area",
            "x_position",
            "y_position",
            "detection_confidence"
          ],
          {
            "default": "area"
          }
        ],
        "reverse_order": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "take_start": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "take_count": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 100,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "facedetection",
        "model",
        "visibility",
        "codeformer_weight",
        "face_selection"
      ],
      "optional": [
        "sort_by",
        "reverse_order",
        "take_start",
        "take_count"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ReActorRestoreFaceAdvanced",
    "display_name": "Restore Face Advanced  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorImageDublicator": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "count": [
          "INT",
          {
            "default": 1,
            "min": 0
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "count"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "IMAGES"
    ],
    "name": "ReActorImageDublicator",
    "display_name": "Image Dublicator (List)  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ImageRGBA2RGB": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageRGBA2RGB",
    "display_name": "Convert RGBA to RGB  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "ReActorUnload": {
    "input": {
      "required": {
        "trigger": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "trigger"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ReActorUnload",
    "display_name": "Unload ReActor Models  ReActor",
    "description": "",
    "python_module": "custom_nodes.comfyui-reactor-node",
    "category": " ReActor",
    "output_node": false
  },
  "SeedVR2VideoUpscaler": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Input video frames as image batch.\nAccepts both RGB (3-channel) and RGBA (4-channel) formats.\nOutput format will match input format."
          }
        ],
        "dit": [
          "SEEDVR2_DIT",
          {
            "tooltip": "DiT model configuration from SeedVR2 (Down)Load DiT Model node"
          }
        ],
        "vae": [
          "SEEDVR2_VAE",
          {
            "tooltip": "VAE model configuration from SeedVR2 (Down)Load VAE Model node"
          }
        ],
        "seed": [
          "INT",
          {
            "tooltip": "Random seed for reproducible generation (default: 42).\nSame seed with same inputs produces identical output.",
            "default": 42,
            "min": 0,
            "max": 4294967295,
            "step": 1
          }
        ],
        "resolution": [
          "INT",
          {
            "tooltip": "Target resolution for the shortest edge in pixels (default: 1080).\nAutomatically maintains aspect ratio of input.\nEven values required for optimal processing.",
            "default": 1080,
            "min": 16,
            "max": 16384,
            "step": 2
          }
        ],
        "max_resolution": [
          "INT",
          {
            "tooltip": "Maximum resolution limit for any dimension (default: 0, no limit).\nIf any edge exceeds this after applying resolution,\nboth dimensions are scaled down proportionally.\nUseful to prevent excessive VRAM usage on extreme aspect ratios.",
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 2
          }
        ],
        "batch_size": [
          "INT",
          {
            "tooltip": "Number of frames processed together per batch (default: 5).\nMust follow pattern 4n+1: 1, 5, 9, 13, 17, 21, ...\n\n Higher values: Better temporal consistency and faster processing\n Lower values: Reduced VRAM usage\n\nIdeally match to shot length for best quality.",
            "default": 5,
            "min": 1,
            "max": 16384,
            "step": 4
          }
        ],
        "uniform_batch_size": [
          "BOOLEAN",
          {
            "tooltip": "Pad final batch to match batch_size (default: False).\nPrevents temporal artifacts caused by small final batch.\nAdd extra compute but recommended for optimal quality.",
            "default": false
          }
        ],
        "color_correction": [
          "COMBO",
          {
            "tooltip": "Corrects color shifts in upscaled output to match original input (default: lab).\nThe upscaling process may alter colors; this applies color grading to restore them.\n\n lab: Perceptual color matching with detail preservation (recommended)\n wavelet: Frequency-based natural colors, preserves fine details\n wavelet_adaptive: Wavelet base with targeted saturation correction\n hsv: Hue-conditional saturation matching\n adain: Statistical style transfer approach\n none: No color correction applied",
            "default": "lab",
            "multiselect": false,
            "options": [
              "lab",
              "wavelet",
              "wavelet_adaptive",
              "hsv",
              "adain",
              "none"
            ]
          }
        ]
      },
      "optional": {
        "temporal_overlap": [
          "INT",
          {
            "tooltip": "Overlapping frames between consecutive batches (default: 0, disabled).\nImproves temporal consistency across batch boundaries through blending.\nValues 1-4 work well for most content.",
            "default": 0,
            "min": 0,
            "max": 16,
            "step": 1
          }
        ],
        "prepend_frames": [
          "INT",
          {
            "tooltip": "Number of frames to prepend (reversed from start) before processing (default: 0).\nHelps reduce artifacts at video beginning.\nPrepended frames are automatically removed from final output.",
            "default": 0,
            "min": 0,
            "max": 32,
            "step": 1
          }
        ],
        "input_noise_scale": [
          "FLOAT",
          {
            "tooltip": "Input noise injection scale (default: 0.0, disabled).\nAdds controlled variation to input images before encoding.\nRange: 0.0 (no noise) to 1.0 (maximum noise).\nCan help with certain types of artifacts.",
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "latent_noise_scale": [
          "FLOAT",
          {
            "tooltip": "Latent space noise injection scale (default: 0.0, disabled).\nAdds controlled variation during the diffusion process.\nRange: 0.0 (no noise) to 1.0 (maximum noise).\nCan soften details if input_noise_scale doesn't help.",
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "offload_device": [
          "COMBO",
          {
            "tooltip": "Device for storing intermediate tensors between processing phases (default: cpu).\n 'none': Keep all tensors on inference device (fastest but highest VRAM usage)\n 'cpu': Offload to system RAM (recommended for long videos, slower transfers)\n 'cuda:X': Offload to another GPU (good balance if available, faster than CPU)",
            "default": "cpu",
            "multiselect": false,
            "options": [
              "none",
              "cpu",
              "cuda:0"
            ]
          }
        ],
        "enable_debug": [
          "BOOLEAN",
          {
            "tooltip": "Enable detailed debug logging (default: False).\nShows memory usage, timing information, and processing details.\nUseful for troubleshooting errors and performance issues.",
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "dit",
        "vae",
        "seed",
        "resolution",
        "max_resolution",
        "batch_size",
        "uniform_batch_size",
        "color_correction"
      ],
      "optional": [
        "temporal_overlap",
        "prepend_frames",
        "input_noise_scale",
        "latent_noise_scale",
        "offload_device",
        "enable_debug"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "output_tooltips": [
      "Upscaled video frames with color correction applied. Format (RGB/RGBA) matches input. Range [0, 1] normalized for ComfyUI compatibility."
    ],
    "output_matchtypes": null,
    "name": "SeedVR2VideoUpscaler",
    "display_name": "SeedVR2 Video Upscaler (v2.5.24)",
    "description": "SeedVR2 main upscaling node: processes video frames using DiT and VAE models with diffusion-based enhancement. Handles RGB/RGBA formats, maintains temporal consistency across frames, applies color correction, and manages VRAM through intelligent tensor offloading. \n\nRequires DiT and VAE model configurations.",
    "python_module": "custom_nodes.seedvr2_videoupscaler",
    "category": "SEEDVR2",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SeedVR2LoadDiTModel": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "DiT (Diffusion Transformer) model for video upscaling.\nModels automatically download on first use.\nAdditional models can be added to the ComfyUI models folder.",
            "default": "seedvr2_ema_3b_fp8_e4m3fn.safetensors",
            "multiselect": false,
            "options": [
              "seedvr2_ema_3b-Q4_K_M.gguf",
              "seedvr2_ema_3b-Q8_0.gguf",
              "seedvr2_ema_3b_fp8_e4m3fn.safetensors",
              "seedvr2_ema_3b_fp16.safetensors",
              "seedvr2_ema_7b-Q4_K_M.gguf",
              "seedvr2_ema_7b_fp8_e4m3fn_mixed_block35_fp16.safetensors",
              "seedvr2_ema_7b_fp16.safetensors",
              "seedvr2_ema_7b_sharp-Q4_K_M.gguf",
              "seedvr2_ema_7b_sharp_fp8_e4m3fn_mixed_block35_fp16.safetensors",
              "seedvr2_ema_7b_sharp_fp16.safetensors"
            ]
          }
        ],
        "device": [
          "COMBO",
          {
            "tooltip": "GPU device for DiT model inference (upscaling phase)",
            "default": "cuda:0",
            "multiselect": false,
            "options": [
              "cuda:0"
            ]
          }
        ]
      },
      "optional": {
        "blocks_to_swap": [
          "INT",
          {
            "tooltip": "Number of transformer blocks to swap between devices for VRAM optimization.\n 0: Disabled (default)\n 3B model: 0-32 blocks\n 7B model: 0-36 blocks\n\nRequires offload_device to be set and different from device.\nNot available on macOS (unified memory architecture).",
            "default": 0,
            "min": 0,
            "max": 36,
            "step": 1
          }
        ],
        "swap_io_components": [
          "BOOLEAN",
          {
            "tooltip": "Offload input/output embeddings and normalization layers to reduce VRAM.\nRequires offload_device to be set and different from device.\nNot available on macOS (unified memory architecture).",
            "default": false
          }
        ],
        "offload_device": [
          "COMBO",
          {
            "tooltip": "Device to offload DiT model when not actively processing.\n 'none': Keep model on inference device (default, fastest)\n 'cpu': Offload to system RAM (reduces VRAM usage)\n 'cuda:X': Offload to another GPU (good balance if available)\n\nRequired for BlockSwap (blocks_to_swap or swap_io_components).",
            "default": "none",
            "multiselect": false,
            "options": [
              "none",
              "cpu",
              "cuda:0"
            ]
          }
        ],
        "cache_model": [
          "BOOLEAN",
          {
            "tooltip": "Keep DiT model loaded on offload_device between workflow runs.\nUseful for batch processing to avoid repeated loading.\nRequires offload_device to be set.",
            "default": false
          }
        ],
        "attention_mode": [
          "COMBO",
          {
            "tooltip": "Attention computation backend:\n sdpa: PyTorch scaled_dot_product_attention (default, stable, always available)\n flash_attn_2: Flash Attention 2 (Ampere+, requires flash-attn package)\n flash_attn_3: Flash Attention 3 (Hopper+, requires flash-attn with FA3 support)\n sageattn_2: SageAttention 2 (requires sageattention package)\n sageattn_3: SageAttention 3 (Blackwell/RTX 50xx only, requires sageattn3 package)\n\nSDPA is recommended - stable and works everywhere.\nFlash Attention and SageAttention provide speedup through optimized CUDA kernels on compatible GPUs.",
            "default": "sdpa",
            "multiselect": false,
            "options": [
              "sdpa",
              "flash_attn_2",
              "flash_attn_3",
              "sageattn_2",
              "sageattn_3"
            ]
          }
        ],
        "torch_compile_args": [
          "TORCH_COMPILE_ARGS",
          {
            "tooltip": "Optional torch.compile optimization settings from SeedVR2 Torch Compile Settings node.\nProvides 20-40% speedup with compatible PyTorch 2.0+ and Triton installation."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "device"
      ],
      "optional": [
        "blocks_to_swap",
        "swap_io_components",
        "offload_device",
        "cache_model",
        "attention_mode",
        "torch_compile_args"
      ]
    },
    "output": [
      "SEEDVR2_DIT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SEEDVR2_DIT"
    ],
    "output_tooltips": [
      "DiT model configuration containing model path, device settings, BlockSwap parameters, and compilation options. Connect to Video Upscaler node."
    ],
    "output_matchtypes": null,
    "name": "SeedVR2LoadDiTModel",
    "display_name": "SeedVR2 (Down)Load DiT Model",
    "description": "Load and configure SeedVR2 DiT (Diffusion Transformer) model for video upscaling. Supports BlockSwap memory optimization for low VRAM systems, model caching for batch processing, multi-GPU offloading, and torch.compile acceleration. \n\nConnect to Video Upscaler node.",
    "python_module": "custom_nodes.seedvr2_videoupscaler",
    "category": "SEEDVR2",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SeedVR2LoadVAEModel": {
    "input": {
      "required": {
        "model": [
          "COMBO",
          {
            "tooltip": "VAE (Variational Autoencoder) model for encoding/decoding.\nModels automatically download on first use.\nAdditional models can be added to the ComfyUI models folder.",
            "default": "ema_vae_fp16.safetensors",
            "multiselect": false,
            "options": [
              "ema_vae_fp16.safetensors"
            ]
          }
        ],
        "device": [
          "COMBO",
          {
            "tooltip": "GPU device for VAE model inference (encoding/decoding phases)",
            "default": "cuda:0",
            "multiselect": false,
            "options": [
              "cuda:0"
            ]
          }
        ]
      },
      "optional": {
        "encode_tiled": [
          "BOOLEAN",
          {
            "tooltip": "Enable tiled encoding to reduce VRAM usage during the encoding phase",
            "default": false
          }
        ],
        "encode_tile_size": [
          "INT",
          {
            "tooltip": "Encoding tile size in pixels (default: 1024).\nApplied to both height and width.\nLower values reduce VRAM usage but may increase processing time.\nOnly used when encode_tiled is enabled.",
            "default": 1024,
            "min": 64,
            "step": 32
          }
        ],
        "encode_tile_overlap": [
          "INT",
          {
            "tooltip": "Pixel overlap between encoding tiles (default: 128).\nReduces visible seams between tiles through blending.\nHigher values improve quality but slow processing.\nOnly used when encode_tiled is enabled.",
            "default": 128,
            "min": 0,
            "step": 32
          }
        ],
        "decode_tiled": [
          "BOOLEAN",
          {
            "tooltip": "Enable tiled decoding to reduce VRAM usage during the decoding phase",
            "default": false
          }
        ],
        "decode_tile_size": [
          "INT",
          {
            "tooltip": "Decoding tile size in pixels (default: 1024).\nApplied to both height and width.\nLower values reduce VRAM usage but may increase processing time.\nOnly used when decode_tiled is enabled.",
            "default": 1024,
            "min": 64,
            "step": 32
          }
        ],
        "decode_tile_overlap": [
          "INT",
          {
            "tooltip": "Pixel overlap between decoding tiles (default: 128).\nReduces visible seams between tiles through blending.\nHigher values improve quality but slow processing.\nOnly used when decode_tiled is enabled.",
            "default": 128,
            "min": 0,
            "step": 32
          }
        ],
        "tile_debug": [
          "COMBO",
          {
            "tooltip": "Tile debug visualization mode:\n 'false': No visualization overlay (default)\n 'encode': Show encoding tile boundaries\n 'decode': Show decoding tile boundaries\n\nOnly works when respective tiling is enabled.",
            "default": "false",
            "multiselect": false,
            "options": [
              "false",
              "encode",
              "decode"
            ]
          }
        ],
        "offload_device": [
          "COMBO",
          {
            "tooltip": "Device to offload VAE model when not actively processing.\n 'none': Keep model on inference device (default, fastest)\n 'cpu': Offload to system RAM (reduces VRAM usage)\n 'cuda:X': Offload to another GPU (good balance if available)",
            "default": "none",
            "multiselect": false,
            "options": [
              "none",
              "cpu",
              "cuda:0"
            ]
          }
        ],
        "cache_model": [
          "BOOLEAN",
          {
            "tooltip": "Keep VAE model loaded on offload_device between workflow runs.\nUseful for batch processing to avoid repeated loading.\nRequires offload_device to be set.",
            "default": false
          }
        ],
        "torch_compile_args": [
          "TORCH_COMPILE_ARGS",
          {
            "tooltip": "Optional torch.compile optimization settings from SeedVR2 Torch Compile Settings node.\nProvides 15-25% speedup with compatible PyTorch 2.0+ and Triton installation."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "device"
      ],
      "optional": [
        "encode_tiled",
        "encode_tile_size",
        "encode_tile_overlap",
        "decode_tiled",
        "decode_tile_size",
        "decode_tile_overlap",
        "tile_debug",
        "offload_device",
        "cache_model",
        "torch_compile_args"
      ]
    },
    "output": [
      "SEEDVR2_VAE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SEEDVR2_VAE"
    ],
    "output_tooltips": [
      "VAE model configuration containing model path, device settings, tiling parameters, and compilation options. Connect to Video Upscaler node."
    ],
    "output_matchtypes": null,
    "name": "SeedVR2LoadVAEModel",
    "display_name": "SeedVR2 (Down)Load VAE Model",
    "description": "Load and configure SeedVR2 VAE (Variational Autoencoder) for encoding/decoding video frames to/from latent space. Supports tiled processing to handle high resolutions on limited VRAM, model caching, multi-GPU offloading, and torch.compile acceleration. \n\nConnect to Video Upscaler node.",
    "python_module": "custom_nodes.seedvr2_videoupscaler",
    "category": "SEEDVR2",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "SeedVR2TorchCompileSettings": {
    "input": {
      "required": {
        "backend": [
          "COMBO",
          {
            "tooltip": "Compilation backend:\n inductor: Full optimization with Triton kernel generation and fusion (recommended)\n cudagraphs: Lightweight wrapper using CUDA graphs, no kernel optimization",
            "default": "inductor",
            "multiselect": false,
            "options": [
              "inductor",
              "cudagraphs"
            ]
          }
        ],
        "mode": [
          "COMBO",
          {
            "tooltip": "Optimization level (compilation time vs runtime performance):\n default: Fast compilation with good speedup (recommended for development)\n reduce-overhead: Lower overhead, optimized for smaller models\n max-autotune: Slowest compilation, best runtime performance (recommended for production)\n max-autotune-no-cudagraphs: Like max-autotune but without CUDA graphs",
            "default": "default",
            "multiselect": false,
            "options": [
              "default",
              "reduce-overhead",
              "max-autotune",
              "max-autotune-no-cudagraphs"
            ]
          }
        ],
        "fullgraph": [
          "BOOLEAN",
          {
            "tooltip": "Compile entire model as single graph without breaks.\n False: Allow graph breaks for better compatibility (default)\n True: Enforce no breaks for maximum optimization (may fail with dynamic shapes)",
            "default": false
          }
        ],
        "dynamic": [
          "BOOLEAN",
          {
            "tooltip": "Handle varying input shapes without recompilation.\n False: Specialize for exact input shapes (default)\n True: Create dynamic kernels that adapt to shape variations\n\nEnable when processing different resolutions or batch sizes.",
            "default": false
          }
        ],
        "dynamo_cache_size_limit": [
          "INT",
          {
            "tooltip": "Maximum cached compiled versions per function (default: 64).\nControls how many shape variations to compile before stopping.\n\n Increase: When processing many different input shapes (more memory usage)\n Decrease: When recompilation cost outweighs benefits (faster fallback to eager)",
            "default": 64,
            "min": 0,
            "max": 1024,
            "step": 1
          }
        ],
        "dynamo_recompile_limit": [
          "INT",
          {
            "tooltip": "Maximum recompilation attempts before fallback to eager mode (default: 128).\nSafety limit to prevent infinite compilation loops.\n\nOnly increase if you see 'hit config.recompile_limit' warnings and have bounded shape variations.",
            "default": 128,
            "min": 0,
            "max": 1024,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "backend",
        "mode",
        "fullgraph",
        "dynamic",
        "dynamo_cache_size_limit",
        "dynamo_recompile_limit"
      ]
    },
    "output": [
      "TORCH_COMPILE_ARGS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "TORCH_COMPILE_ARGS"
    ],
    "output_tooltips": [
      "torch.compile optimization settings including backend, mode, and Dynamo configuration. Connect to DiT and/or VAE model loader nodes."
    ],
    "output_matchtypes": null,
    "name": "SeedVR2TorchCompileSettings",
    "display_name": "SeedVR2 Torch Compile Settings",
    "description": "Configure SeedVR2 torch.compile optimization for 20-40% DiT speedup and 15-25% VAE speedup. Trades longer first-run compilation time for faster inference.\n\nConnect to DiT and/or VAE model loaders. Requires PyTorch 2.0+ and Triton for inductor backend.",
    "python_module": "custom_nodes.seedvr2_videoupscaler",
    "category": "SEEDVR2",
    "output_node": false,
    "deprecated": false,
    "experimental": false,
    "api_node": false
  },
  "VHS_VideoCombine": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "frame_rate": [
          "FLOAT",
          {
            "default": 8,
            "min": 1,
            "step": 1
          }
        ],
        "loop_count": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "AnimateDiff"
          }
        ],
        "format": [
          [
            "image/gif",
            "image/webp",
            "video/16bit-png",
            "video/8bit-png",
            "video/ProRes",
            "video/av1-webm",
            "video/ffmpeg-gif",
            "video/ffv1-mkv",
            "video/h264-mp4",
            "video/h265-mp4",
            "video/nvenc_av1-mp4",
            "video/nvenc_h264-mp4",
            "video/nvenc_hevc-mp4",
            "video/webm"
          ],
          {
            "formats": {
              "video/ProRes": [
                [
                  "profile",
                  [
                    "lt",
                    "standard",
                    "hq",
                    "4444",
                    "4444xq"
                  ],
                  {
                    "default": "hq"
                  }
                ]
              ],
              "video/av1-webm": [
                [
                  "pix_fmt",
                  [
                    "yuv420p10le",
                    "yuv420p"
                  ]
                ],
                [
                  "crf",
                  "INT",
                  {
                    "default": 23,
                    "min": 0,
                    "max": 100,
                    "step": 1
                  }
                ],
                [
                  "input_color_depth",
                  [
                    "8bit",
                    "16bit"
                  ]
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ],
              "video/ffmpeg-gif": [
                [
                  "dither",
                  [
                    "bayer",
                    "heckbert",
                    "floyd_steinberg",
                    "sierra2",
                    "sierra2_4a",
                    "sierra3",
                    "burkes",
                    "atkinson",
                    "none"
                  ],
                  {
                    "default": "sierra2_4a"
                  },
                  "[0:v] split [a][b]; [a] palettegen=reserve_transparent=on:transparency_color=ffffff [p]; [b][p] paletteuse=dither=$val"
                ]
              ],
              "video/ffv1-mkv": [
                [
                  "level",
                  [
                    "0",
                    "1",
                    "3"
                  ],
                  {
                    "default": "3"
                  }
                ],
                [
                  "coder",
                  [
                    "0",
                    "1",
                    "2"
                  ],
                  {
                    "default": "1"
                  }
                ],
                [
                  "context",
                  [
                    "0",
                    "1"
                  ],
                  {
                    "default": "1"
                  }
                ],
                [
                  "gop_size",
                  "INT",
                  {
                    "default": 1,
                    "min": 1,
                    "max": 300,
                    "step": 1
                  }
                ],
                [
                  "slices",
                  [
                    "4",
                    "6",
                    "9",
                    "12",
                    "16",
                    "20",
                    "24",
                    "30"
                  ],
                  {
                    "default": "16"
                  }
                ],
                [
                  "slicecrc",
                  [
                    "0",
                    "1"
                  ],
                  {
                    "default": "1"
                  }
                ],
                [
                  "pix_fmt",
                  [
                    "rgba64le",
                    "bgra",
                    "yuv420p",
                    "yuv422p",
                    "yuv444p",
                    "yuva420p",
                    "yuva422p",
                    "yuva444p",
                    "yuv420p10le",
                    "yuv422p10le",
                    "yuv444p10le",
                    "yuv420p12le",
                    "yuv422p12le",
                    "yuv444p12le",
                    "yuv420p14le",
                    "yuv422p14le",
                    "yuv444p14le",
                    "yuv420p16le",
                    "yuv422p16le",
                    "yuv444p16le",
                    "gray",
                    "gray10le",
                    "gray12le",
                    "gray16le"
                  ],
                  {
                    "default": "rgba64le"
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "trim_to_audio",
                  "BOOLEAN",
                  {
                    "default": false
                  }
                ]
              ],
              "video/h264-mp4": [
                [
                  "pix_fmt",
                  [
                    "yuv420p",
                    "yuv420p10le"
                  ]
                ],
                [
                  "crf",
                  "INT",
                  {
                    "default": 19,
                    "min": 0,
                    "max": 100,
                    "step": 1
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "trim_to_audio",
                  "BOOLEAN",
                  {
                    "default": false
                  }
                ]
              ],
              "video/h265-mp4": [
                [
                  "pix_fmt",
                  [
                    "yuv420p10le",
                    "yuv420p"
                  ]
                ],
                [
                  "crf",
                  "INT",
                  {
                    "default": 22,
                    "min": 0,
                    "max": 100,
                    "step": 1
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ],
              "video/nvenc_av1-mp4": [
                [
                  "pix_fmt",
                  [
                    "yuv420p",
                    "p010le"
                  ]
                ],
                [
                  "bitrate",
                  "INT",
                  {
                    "default": 10,
                    "min": 1,
                    "max": 999,
                    "step": 1
                  }
                ],
                [
                  "megabit",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ],
              "video/nvenc_h264-mp4": [
                [
                  "pix_fmt",
                  [
                    "yuv420p",
                    "p010le"
                  ]
                ],
                [
                  "bitrate",
                  "INT",
                  {
                    "default": 10,
                    "min": 1,
                    "max": 999,
                    "step": 1
                  }
                ],
                [
                  "megabit",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ],
              "video/nvenc_hevc-mp4": [
                [
                  "pix_fmt",
                  [
                    "yuv420p",
                    "p010le"
                  ]
                ],
                [
                  "bitrate",
                  "INT",
                  {
                    "default": 10,
                    "min": 1,
                    "max": 999,
                    "step": 1
                  }
                ],
                [
                  "megabit",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ],
              "video/webm": [
                [
                  "pix_fmt",
                  [
                    "yuv420p",
                    "yuva420p"
                  ]
                ],
                [
                  "crf",
                  "INT",
                  {
                    "default": 20,
                    "min": 0,
                    "max": 100,
                    "step": 1
                  }
                ],
                [
                  "save_metadata",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ],
                [
                  "trim_to_audio",
                  "BOOLEAN",
                  {
                    "default": false
                  }
                ]
              ],
              "image/webp": [
                [
                  "lossless",
                  "BOOLEAN",
                  {
                    "default": true
                  }
                ]
              ]
            }
          }
        ],
        "pingpong": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "save_output": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      },
      "optional": {
        "audio": [
          "AUDIO"
        ],
        "meta_batch": [
          "VHS_BatchManager"
        ],
        "vae": [
          "VAE"
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "images",
        "frame_rate",
        "loop_count",
        "filename_prefix",
        "format",
        "pingpong",
        "save_output"
      ],
      "optional": [
        "audio",
        "meta_batch",
        "vae"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo",
        "unique_id"
      ]
    },
    "output": [
      "VHS_FILENAMES"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Filenames"
    ],
    "name": "VHS_VideoCombine",
    "display_name": "Video Combine ",
    "description": "Video Combine <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine an image sequence into a video</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be turned into a video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: (optional) audio to add to the video</div></div><div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long image sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided, the node will take latents as input instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Unlike on Load Video, this isn't always a strict upgrade over using a standalone VAE Decode.</div><div style=\"font-size: 1em\">If you have multiple Video Combine outputs, then the VAE decode will be performed for each output node increasing execution time</div><div style=\"font-size: 1em\">If you make any change to output settings on the Video Combine (such as changing the output format), the VAE decode will be performed again as the decoded result is (by design) not cached</div></div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frame_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_rate: The frame rate which will be used for the output video. Consider converting this to an input and connecting this to a Load Video with Video Info(Loaded)->fps. When including audio, failure to properly set this will result in audio desync</div></div><div vhs_title=\"loop_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loop_count: The number of additional times the video should repeat. Can cause performance issues when used with long (100+ frames) sequences</div></div><div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A prefix to add to the name of the output filename. This can include subfolders or format strings.</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: The output format to use. Formats starting with, 'image' are saved with PIL, but formats starting with 'video' utilize the video_formats system. 'video' options require ffmpeg and selecting one frequently adds additional options to the node.</div></div><div vhs_title=\"pingpong\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pingpong: Play the video normally, then repeat the video in reverse so that it 'pingpongs' back and forth. This is frequently used to minimize the appearance of skips on very short animations.</div></div><div vhs_title=\"save_output\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_output: Specifies if output files should be saved to the output folder, or the temporary output folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the processed result. If advanced previews is enabled, the output is always converted to a format viewable from the browser. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div><div vhs_title=\"Common Format Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Common Format Widgets: <div vhs_title=\"crf\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crf: Determines how much to prioritize quality over filesize. Numbers vary between formats, but on each format that includes it, the default value provides visually loss less output</div></div><div vhs_title=\"pix_fmt\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pix_fmt: The pixel format to use for output. Alternative options will often have higher quality at the cost of increased file size and reduced compatibility with external software.<div style=\"font-size: 1em\"><div vhs_title=\"yuv420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p: The most common and default format</div></div><div vhs_title=\"yuv420p10le\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p10le: Use 10 bit color depth. This can improve color quality when combined with 16bit input color depth</div></div><div vhs_title=\"yuva420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuva420p: Include transparency in the output video</div></div></div></div></div><div vhs_title=\"input_color_depth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">input_color_depth: VHS supports outputting 16bit images. While this produces higher quality output, the difference usually isn't visible without postprocessing and it significantly increases file size and processing time.</div></div><div vhs_title=\"save_metadata\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_metadata: Determines if metadata for the workflow should be included in the output video file</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": true
  },
  "VHS_LoadVideo": {
    "input": {
      "required": {
        "video": [
          []
        ],
        "force_rate": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 60,
            "step": 1,
            "disable": 0
          }
        ],
        "custom_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "custom_height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "frame_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1,
            "disable": 0
          }
        ],
        "skip_first_frames": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      },
      "optional": {
        "meta_batch": [
          "VHS_BatchManager"
        ],
        "vae": [
          "VAE"
        ],
        "format": [
          [
            "None",
            "AnimateDiff",
            "Mochi",
            "LTXV",
            "Hunyuan",
            "Cosmos",
            "Wan"
          ],
          {
            "default": "AnimateDiff",
            "formats": {
              "None": {},
              "AnimateDiff": {
                "target_rate": 8,
                "dim": [
                  8,
                  0,
                  512,
                  512
                ]
              },
              "Mochi": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  6,
                  1
                ]
              },
              "LTXV": {
                "target_rate": 24,
                "dim": [
                  32,
                  0,
                  768,
                  512
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Hunyuan": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              },
              "Cosmos": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  1280,
                  704
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Wan": {
                "target_rate": 16,
                "dim": [
                  8,
                  0,
                  832,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              }
            }
          }
        ]
      },
      "hidden": {
        "force_size": "STRING",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "video",
        "force_rate",
        "custom_width",
        "custom_height",
        "frame_load_cap",
        "skip_first_frames",
        "select_every_nth"
      ],
      "optional": [
        "meta_batch",
        "vae",
        "format"
      ],
      "hidden": [
        "force_size",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "AUDIO",
      "VHS_VIDEOINFO"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "frame_count",
      "audio",
      "video_info"
    ],
    "name": "VHS_LoadVideo",
    "display_name": "Load Video (Upload) ",
    "description": "Load Video <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadVideoPath": {
    "input": {
      "required": {
        "video": [
          "STRING",
          {
            "placeholder": "X://insert/path/here.mp4",
            "vhs_path_extensions": [
              "webm",
              "mp4",
              "mkv",
              "gif",
              "mov"
            ]
          }
        ],
        "force_rate": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 60,
            "step": 1,
            "disable": 0
          }
        ],
        "custom_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "custom_height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "frame_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1,
            "disable": 0
          }
        ],
        "skip_first_frames": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      },
      "optional": {
        "meta_batch": [
          "VHS_BatchManager"
        ],
        "vae": [
          "VAE"
        ],
        "format": [
          [
            "None",
            "AnimateDiff",
            "Mochi",
            "LTXV",
            "Hunyuan",
            "Cosmos",
            "Wan"
          ],
          {
            "default": "AnimateDiff",
            "formats": {
              "None": {},
              "AnimateDiff": {
                "target_rate": 8,
                "dim": [
                  8,
                  0,
                  512,
                  512
                ]
              },
              "Mochi": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  6,
                  1
                ]
              },
              "LTXV": {
                "target_rate": 24,
                "dim": [
                  32,
                  0,
                  768,
                  512
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Hunyuan": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              },
              "Cosmos": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  1280,
                  704
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Wan": {
                "target_rate": 16,
                "dim": [
                  8,
                  0,
                  832,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              }
            }
          }
        ]
      },
      "hidden": {
        "force_size": "STRING",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "video",
        "force_rate",
        "custom_width",
        "custom_height",
        "frame_load_cap",
        "skip_first_frames",
        "select_every_nth"
      ],
      "optional": [
        "meta_batch",
        "vae",
        "format"
      ],
      "hidden": [
        "force_size",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "AUDIO",
      "VHS_VIDEOINFO"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "frame_count",
      "audio",
      "video_info"
    ],
    "name": "VHS_LoadVideoPath",
    "display_name": "Load Video (Path) ",
    "description": "Load Video (Path) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadVideoFFmpeg": {
    "input": {
      "required": {
        "video": [
          []
        ],
        "force_rate": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 60,
            "step": 1,
            "disable": 0
          }
        ],
        "custom_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "custom_height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "frame_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1,
            "disable": 0
          }
        ],
        "start_time": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 0.001,
            "widgetType": "VHSTIMESTAMP"
          }
        ]
      },
      "optional": {
        "meta_batch": [
          "VHS_BatchManager"
        ],
        "vae": [
          "VAE"
        ],
        "format": [
          [
            "None",
            "AnimateDiff",
            "Mochi",
            "LTXV",
            "Hunyuan",
            "Cosmos",
            "Wan"
          ],
          {
            "default": "AnimateDiff",
            "formats": {
              "None": {},
              "AnimateDiff": {
                "target_rate": 8,
                "dim": [
                  8,
                  0,
                  512,
                  512
                ]
              },
              "Mochi": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  6,
                  1
                ]
              },
              "LTXV": {
                "target_rate": 24,
                "dim": [
                  32,
                  0,
                  768,
                  512
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Hunyuan": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              },
              "Cosmos": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  1280,
                  704
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Wan": {
                "target_rate": 16,
                "dim": [
                  8,
                  0,
                  832,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              }
            }
          }
        ]
      },
      "hidden": {
        "force_size": "STRING",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "video",
        "force_rate",
        "custom_width",
        "custom_height",
        "frame_load_cap",
        "start_time"
      ],
      "optional": [
        "meta_batch",
        "vae",
        "format"
      ],
      "hidden": [
        "force_size",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "AUDIO",
      "VHS_VIDEOINFO"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "mask",
      "audio",
      "video_info"
    ],
    "name": "VHS_LoadVideoFFmpeg",
    "display_name": "Load Video FFmpeg (Upload) ",
    "description": "Load Video FFmpeg <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadVideoFFmpegPath": {
    "input": {
      "required": {
        "video": [
          "STRING",
          {
            "placeholder": "X://insert/path/here.mp4",
            "vhs_path_extensions": [
              "webm",
              "mp4",
              "mkv",
              "gif",
              "mov"
            ]
          }
        ],
        "force_rate": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 60,
            "step": 1,
            "disable": 0
          }
        ],
        "custom_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "custom_height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "disable": 0
          }
        ],
        "frame_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1,
            "disable": 0
          }
        ],
        "start_time": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 0.001,
            "widgetType": "VHSTIMESTAMP"
          }
        ]
      },
      "optional": {
        "meta_batch": [
          "VHS_BatchManager"
        ],
        "vae": [
          "VAE"
        ],
        "format": [
          [
            "None",
            "AnimateDiff",
            "Mochi",
            "LTXV",
            "Hunyuan",
            "Cosmos",
            "Wan"
          ],
          {
            "default": "AnimateDiff",
            "formats": {
              "None": {},
              "AnimateDiff": {
                "target_rate": 8,
                "dim": [
                  8,
                  0,
                  512,
                  512
                ]
              },
              "Mochi": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  6,
                  1
                ]
              },
              "LTXV": {
                "target_rate": 24,
                "dim": [
                  32,
                  0,
                  768,
                  512
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Hunyuan": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  848,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              },
              "Cosmos": {
                "target_rate": 24,
                "dim": [
                  16,
                  0,
                  1280,
                  704
                ],
                "frames": [
                  8,
                  1
                ]
              },
              "Wan": {
                "target_rate": 16,
                "dim": [
                  8,
                  0,
                  832,
                  480
                ],
                "frames": [
                  4,
                  1
                ]
              }
            }
          }
        ]
      },
      "hidden": {
        "force_size": "STRING",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "video",
        "force_rate",
        "custom_width",
        "custom_height",
        "frame_load_cap",
        "start_time"
      ],
      "optional": [
        "meta_batch",
        "vae",
        "format"
      ],
      "hidden": [
        "force_size",
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "AUDIO",
      "VHS_VIDEOINFO"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "mask",
      "audio",
      "video_info"
    ],
    "name": "VHS_LoadVideoFFmpegPath",
    "display_name": "Load Video FFmpeg (Path) ",
    "description": "Load Video FFmpeg (Path) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadImagePath": {
    "input": {
      "required": {
        "image": [
          "STRING",
          {
            "placeholder": "X://insert/path/here.png",
            "vhs_path_extensions": [
              ".bmp",
              ".pgm",
              ".webp",
              ".tiff",
              ".jpg",
              ".ppm",
              ".tif",
              ".jpeg",
              ".png"
            ]
          }
        ],
        "custom_width": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 8,
            "disable": 0
          }
        ],
        "custom_height": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 8,
            "disable": 0
          }
        ]
      },
      "optional": {
        "vae": [
          "VAE"
        ]
      },
      "hidden": {
        "force_size": "STRING"
      }
    },
    "input_order": {
      "required": [
        "image",
        "custom_width",
        "custom_height"
      ],
      "optional": [
        "vae"
      ],
      "hidden": [
        "force_size"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "mask"
    ],
    "name": "VHS_LoadImagePath",
    "display_name": "Load Image (Path) ",
    "description": "Load Image (Path) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Load a single image from a given path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"image\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image: The image file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadImages": {
    "input": {
      "required": {
        "directory": [
          [
            "3d"
          ]
        ]
      },
      "optional": {
        "image_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "skip_first_images": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "meta_batch": [
          "VHS_BatchManager"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "directory"
      ],
      "optional": [
        "image_load_cap",
        "skip_first_images",
        "select_every_nth",
        "meta_batch"
      ],
      "hidden": [
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK",
      "frame_count"
    ],
    "name": "VHS_LoadImages",
    "display_name": "Load Images (Upload) ",
    "description": "Load Images <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from a subdirectory of the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files</div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"choose folder to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose folder to upload: An upload button is provided to upload a local folder containing images to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadImagesPath": {
    "input": {
      "required": {
        "directory": [
          "STRING",
          {
            "placeholder": "X://path/to/images",
            "vhs_path_extensions": []
          }
        ]
      },
      "optional": {
        "image_load_cap": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "skip_first_images": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "meta_batch": [
          "VHS_BatchManager"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "directory"
      ],
      "optional": [
        "image_load_cap",
        "skip_first_images",
        "select_every_nth",
        "meta_batch"
      ],
      "hidden": [
        "unique_id"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK",
      "frame_count"
    ],
    "name": "VHS_LoadImagesPath",
    "display_name": "Load Images (Path) ",
    "description": "Load Images (Path) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of images which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Keeps only the first of every n frames and discard the rest.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_LoadAudio": {
    "input": {
      "required": {
        "audio_file": [
          "STRING",
          {
            "default": "input/",
            "vhs_path_extensions": [
              "wav",
              "mp3",
              "ogg",
              "m4a",
              "flac"
            ]
          }
        ]
      },
      "optional": {
        "seek_seconds": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "widgetType": "VHSTIMESTAMP"
          }
        ],
        "duration": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 10000000,
            "step": 0.01,
            "widgetType": "VHSTIMESTAMP"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio_file"
      ],
      "optional": [
        "seek_seconds",
        "duration"
      ]
    },
    "output": [
      "AUDIO",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "audio",
      "duration"
    ],
    "name": "VHS_LoadAudio",
    "display_name": "Load Audio (Path)",
    "description": "Load Audio (Path) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio_file\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio_file: The audio file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"seek_seconds\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">seek_seconds: An offset from the start of the sound file that the audio should start from</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /audio",
    "output_node": false
  },
  "VHS_LoadAudioUpload": {
    "input": {
      "required": {
        "audio": [
          []
        ]
      },
      "optional": {
        "start_time": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 10000000,
            "step": 0.01,
            "widgetType": "VHSTIMESTAMP"
          }
        ],
        "duration": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 10000000,
            "step": 0.01,
            "widgetType": "VHSTIMESTAMP"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ],
      "optional": [
        "start_time",
        "duration"
      ]
    },
    "output": [
      "AUDIO",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "audio",
      "duration"
    ],
    "name": "VHS_LoadAudioUpload",
    "display_name": "Load Audio (Upload)",
    "description": "Load Audio (Upload) <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from the input directory</div></div><div style=\"font-size: 0.8em\">Very similar in functionality to the built-in LoadAudio. It was originally added before VHS swapped to use Comfy's internal AUDIO format, but provides the additional options for start time and duration</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio file to be loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: An offset from the start of the sound file that the audio should start from</div></div><div vhs_title=\"duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">duration: A maximum limit for the audio. Disabled if 0</div></div><div vhs_title=\"choose audio to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose audio to upload: An upload button is provided to upload an audio file to the input folder</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /audio",
    "output_node": false
  },
  "VHS_AudioToVHSAudio": {
    "input": {
      "required": {
        "audio": [
          "AUDIO"
        ]
      }
    },
    "input_order": {
      "required": [
        "audio"
      ]
    },
    "output": [
      "VHS_AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "vhs_audio"
    ],
    "name": "VHS_AudioToVHSAudio",
    "display_name": "Audio to legacy VHS_AUDIO",
    "description": "Audio to legacy VHS_AUDIO <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: An input in the standardized AUDIO format</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the legacy VHS_AUDIO format for use with external nodes</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /audio",
    "output_node": false
  },
  "VHS_VHSAudioToAudio": {
    "input": {
      "required": {
        "vhs_audio": [
          "VHS_AUDIO"
        ]
      }
    },
    "input_order": {
      "required": [
        "vhs_audio"
      ]
    },
    "output": [
      "AUDIO"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "audio"
    ],
    "name": "VHS_VHSAudioToAudio",
    "display_name": "Legacy VHS_AUDIO to Audio",
    "description": "Legacy VHS_AUDIO to Audio <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An input in the legacy VHS_AUDIO format produced by an external node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the standardized AUDIO format</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /audio",
    "output_node": false
  },
  "VHS_PruneOutputs": {
    "input": {
      "required": {
        "filenames": [
          "VHS_FILENAMES"
        ],
        "options": [
          [
            "Intermediate",
            "Intermediate and Utility"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "filenames",
        "options"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "VHS_PruneOutputs",
    "display_name": "Prune Outputs ",
    "description": "Prune Outputs <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Automates deletion of undesired outputs from a Video Combine node.</div></div><div style=\"font-size: 0.8em\">Video Combine produces a number of file outputs in addition to the final output. Some of these, such as a video file without audio included, are implementation limitations and are not feasible to solve. As an alternative, the Prune Outputs node is added to automate the deletion of these file outputs if they are not desired</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A connection from a Video Combine node to indicate which outputs should be pruned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"options\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">options: Which files should be deleted<div style=\"font-size: 1em\"><div vhs_title=\"Intermediate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate: Delete any files that were required for intermediate processing but are not the final output, like the no-audio output file when audio is included</div></div><div vhs_title=\"Intermediate and Utility\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate and Utility: Delete all produced files that aren't the final output, including the first frame png</div></div></div></div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": true
  },
  "VHS_BatchManager": {
    "input": {
      "required": {
        "frames_per_batch": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "frames_per_batch"
      ],
      "hidden": [
        "prompt",
        "unique_id"
      ]
    },
    "output": [
      "VHS_BatchManager"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "meta_batch"
    ],
    "name": "VHS_BatchManager",
    "display_name": "Meta Batch Manager ",
    "description": "Meta Batch Manager <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split the processing of a very long video into sets of smaller Meta Batches</div></div><div style=\"font-size: 0.8em\">The Meta Batch Manager allows for extremely long input videos to be processed when all other methods for fitting the content in RAM fail. It does not effect VRAM usage.</div><div style=\"font-size: 0.8em\">It must be connected to at least one Input (a Load Video or Load Images) AND at least one Video Combine</div><div style=\"font-size: 0.8em\"><img src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/7cb3fb7e-59d8-4cb2-a09f-9c6698de8b1f loading=lazy style=\"width: 0px; min-width: 100%\"></div><div style=\"font-size: 0.8em\">It functions by holding both the inputs and ouputs open between executions, and automatically requeue's the workflow until one of the inputs is unable to provide additional images.</div><div style=\"font-size: 0.8em\">Because each sub execution only contains a subset of the total frames, each sub execution creates a hard window which temporal smoothing can not be applied across. This results in jumps in the output.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: Add all connected nodes to this Meta Batch</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frames_per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frames_per_batch: How many frames to process for each sub execution. If loading as image, each frame will use about 50MB of RAM (not VRAM), and this can safely be set in the 100-1000 range, depending on available memory. When loading and combining from latent space (no blue image noodles exist), this value can be much higher, around the 2,000 to 20,000 range</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_VideoInfo": {
    "input": {
      "required": {
        "video_info": [
          "VHS_VIDEOINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "video_info"
      ]
    },
    "output": [
      "FLOAT",
      "INT",
      "FLOAT",
      "INT",
      "INT",
      "FLOAT",
      "INT",
      "FLOAT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "source_fps",
      "source_frame_count",
      "source_duration",
      "source_width",
      "source_height",
      "loaded_fps",
      "loaded_frame_count",
      "loaded_duration",
      "loaded_width",
      "loaded_height"
    ],
    "name": "VHS_VideoInfo",
    "display_name": "Video Info ",
    "description": "Video Info <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width: The width</div></div><div vhs_title=\"source_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height: The height</div></div><div vhs_title=\"loaded_fps\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width: The width of the video after scaling. These coordinates are in image space even if loading to latent space</div></div><div vhs_title=\"loaded_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height: The height of the video after scaling. These coordinates are in image space even if loading to latent space</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_VideoInfoSource": {
    "input": {
      "required": {
        "video_info": [
          "VHS_VIDEOINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "video_info"
      ]
    },
    "output": [
      "FLOAT",
      "INT",
      "FLOAT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "fps",
      "frame_count",
      "duration",
      "width",
      "height"
    ],
    "name": "VHS_VideoInfoSource",
    "display_name": "Video Info (Source) ",
    "description": "Video Info Source <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself without accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width: The original width</div></div><div vhs_title=\"source_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height: The original height</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_VideoInfoLoaded": {
    "input": {
      "required": {
        "video_info": [
          "VHS_VIDEOINFO"
        ]
      }
    },
    "input_order": {
      "required": [
        "video_info"
      ]
    },
    "output": [
      "FLOAT",
      "INT",
      "FLOAT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "fps",
      "frame_count",
      "duration",
      "width",
      "height"
    ],
    "name": "VHS_VideoInfoLoaded",
    "display_name": "Video Info (Loaded) ",
    "description": "Video Info Loaded <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself after accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"loaded_fps\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width: The width of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div><div vhs_title=\"loaded_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height: The height of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_SelectFilename": {
    "input": {
      "required": {
        "filenames": [
          "VHS_FILENAMES"
        ],
        "index": [
          "INT",
          {
            "default": -1,
            "step": 1,
            "min": -1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "filenames",
        "index"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Filename"
    ],
    "name": "VHS_SelectFilename",
    "display_name": "Select Filename ",
    "description": "VAE Select Filename <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Select a single filename from the VHS_FILENAMES output by a Video Combine and return it as a string</div></div><div style=\"font-size: 0.8em\">Take care when combining this node with Prune Outputs. The VHS_FILENAMES object is immutable and will always contain the full list of output files, but execution order is undefined behavior (currently, Prune Outputs will generally execute first) and SelectFilename may return a path to a file that no longer exists.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A VHS_FILENAMES from a Video Combine node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename: A string representation of the full output path for the chosen file</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">index: The index of which file should be selected. The default, -1, chooses the most complete output</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_VAEEncodeBatched": {
    "input": {
      "required": {
        "pixels": [
          "IMAGE"
        ],
        "vae": [
          "VAE"
        ],
        "per_batch": [
          "INT",
          {
            "default": 16,
            "min": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "pixels",
        "vae",
        "per_batch"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "VHS_VAEEncodeBatched",
    "display_name": "VAE Encode Batched ",
    "description": "VAE Encode Batched <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Encode images as latents with a manually specified batch size.</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when encoding images.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Encode or to encode directly from a Load Video</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"pixels\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pixels: The images to be encoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when encoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The encoded latents.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to encode in each batch.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /batched nodes",
    "output_node": false
  },
  "VHS_VAEDecodeBatched": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "vae": [
          "VAE"
        ],
        "per_batch": [
          "INT",
          {
            "default": 16,
            "min": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "vae",
        "per_batch"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "VHS_VAEDecodeBatched",
    "display_name": "VAE Decode Batched ",
    "description": "VAE Decode Batched <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Decode latents to images with a manually specified batch size</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when decoding latents.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Decode or to decode from a Video Combine directly</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"samples\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">samples: The latents to be decoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when decoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The decoded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to decode in each batch.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /batched nodes",
    "output_node": false
  },
  "VHS_SplitLatents": {
    "input": {
      "required": {
        "latents": [
          "LATENT"
        ],
        "split_index": [
          "INT",
          {
            "default": 0,
            "step": 1,
            "min": -9007199254740991,
            "max": 9007199254740991
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latents",
        "split_index"
      ]
    },
    "output": [
      "LATENT",
      "INT",
      "LATENT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "LATENT_A",
      "A_count",
      "LATENT_B",
      "B_count"
    ],
    "name": "VHS_SplitLatents",
    "display_name": "Split Latents ",
    "description": "Split Latents <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of latents into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_A: The first group of latents</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of latents in group A. This will be equal to split_index unless the latents input has length less than split_index</div></div><div vhs_title=\"LATENT_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_B: The second group of latents</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of latents in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_SplitImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "split_index": [
          "INT",
          {
            "default": 0,
            "step": 1,
            "min": -9007199254740991,
            "max": 9007199254740991
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "split_index"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE_A",
      "A_count",
      "IMAGE_B",
      "B_count"
    ],
    "name": "VHS_SplitImages",
    "display_name": "Split Images ",
    "description": "Split Images <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of images into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_A: The first group of images</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of images in group A. This will be equal to split_index unless the images input has length less than split_index</div></div><div vhs_title=\"IMAGE_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_B: The second group of images</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of images in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_SplitMasks": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "split_index": [
          "INT",
          {
            "default": 0,
            "step": 1,
            "min": -9007199254740991,
            "max": 9007199254740991
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "split_index"
      ]
    },
    "output": [
      "MASK",
      "INT",
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MASK_A",
      "A_count",
      "MASK_B",
      "B_count"
    ],
    "name": "VHS_SplitMasks",
    "display_name": "Split Masks ",
    "description": "Split Masks <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of masks into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The masks to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_A: The first group of masks</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of masks in group A. This will be equal to split_index unless the mask input has length less than split_index</div></div><div vhs_title=\"MASK_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_B: The second group of masks</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of masks in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_MergeLatents": {
    "input": {
      "required": {
        "latents_A": [
          "LATENT"
        ],
        "latents_B": [
          "LATENT"
        ],
        "merge_strategy": [
          [
            "match A",
            "match B",
            "match smaller",
            "match larger"
          ]
        ],
        "scale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "crop": [
          [
            "disabled",
            "center"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "latents_A",
        "latents_B",
        "merge_strategy",
        "scale_method",
        "crop"
      ]
    },
    "output": [
      "LATENT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "count"
    ],
    "name": "VHS_MergeLatents",
    "display_name": "Merge Latents ",
    "description": "Merge Latents <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of latents into a single group of latents</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_A: The first group of latents</div></div><div vhs_title=\"latents_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_B: The first group of latents</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The combined group of latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_MergeImages": {
    "input": {
      "required": {
        "images_A": [
          "IMAGE"
        ],
        "images_B": [
          "IMAGE"
        ],
        "merge_strategy": [
          [
            "match A",
            "match B",
            "match smaller",
            "match larger"
          ]
        ],
        "scale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "crop": [
          [
            "disabled",
            "center"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images_A",
        "images_B",
        "merge_strategy",
        "scale_method",
        "crop"
      ]
    },
    "output": [
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "count"
    ],
    "name": "VHS_MergeImages",
    "display_name": "Merge Images ",
    "description": "Merge Images <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of images into a single group of images</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_A: The first group of images</div></div><div vhs_title=\"images_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_B: The first group of images</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The combined group of images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_MergeMasks": {
    "input": {
      "required": {
        "mask_A": [
          "MASK"
        ],
        "mask_B": [
          "MASK"
        ],
        "merge_strategy": [
          [
            "match A",
            "match B",
            "match smaller",
            "match larger"
          ]
        ],
        "scale_method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "crop": [
          [
            "disabled",
            "center"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mask_A",
        "mask_B",
        "merge_strategy",
        "scale_method",
        "crop"
      ]
    },
    "output": [
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MASK",
      "count"
    ],
    "name": "VHS_MergeMasks",
    "display_name": "Merge Masks ",
    "description": "Merge Masks <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of masks into a single group of masks</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_A: The first group of masks</div></div><div vhs_title=\"mask_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_B: The first group of masks</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The combined group of masks</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_GetLatentCount": {
    "input": {
      "required": {
        "latents": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "latents"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "count"
    ],
    "name": "VHS_GetLatentCount",
    "display_name": "Get Latent Count ",
    "description": "Get Latent Count <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of latents in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_GetImageCount": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "count"
    ],
    "name": "VHS_GetImageCount",
    "display_name": "Get Image Count ",
    "description": "Get Image Count <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of images in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_GetMaskCount": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "mask"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "count"
    ],
    "name": "VHS_GetMaskCount",
    "display_name": "Get Mask Count ",
    "description": "Get Mask Count <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of masks in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of masks in the input</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_DuplicateLatents": {
    "input": {
      "required": {
        "latents": [
          "LATENT"
        ],
        "multiply_by": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latents",
        "multiply_by"
      ]
    },
    "output": [
      "LATENT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "count"
    ],
    "name": "VHS_DuplicateLatents",
    "display_name": "Repeat Latents ",
    "description": "Repeat Latents <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a latent to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The latent with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the output. Equal to the length of the input latent * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the latent should repeat. 1, the default, means no change.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_DuplicateImages": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "multiply_by": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "multiply_by"
      ]
    },
    "output": [
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "count"
    ],
    "name": "VHS_DuplicateImages",
    "display_name": "Repeat Images ",
    "description": "Repeat Images <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a image to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"IMAGES\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGES: The image to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The image with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of image in the output. Equal to the length of the input image * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_DuplicateMasks": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "multiply_by": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "multiply_by"
      ]
    },
    "output": [
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MASK",
      "count"
    ],
    "name": "VHS_DuplicateMasks",
    "display_name": "Repeat Masks ",
    "description": "Repeat Masks <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a mask to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The masks to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The mask with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the output. Equal to the length of the input mask * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_SelectEveryNthLatent": {
    "input": {
      "required": {
        "latents": [
          "LATENT"
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "skip_first_latents": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latents",
        "select_every_nth",
        "skip_first_latents"
      ]
    },
    "output": [
      "LATENT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "count"
    ],
    "name": "VHS_SelectEveryNthLatent",
    "display_name": "Select Every Nth Latent ",
    "description": "Select Every Nth Latent <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 latent for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The output latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_latents: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the latent into groups</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_SelectEveryNthImage": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "skip_first_images": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "select_every_nth",
        "skip_first_images"
      ]
    },
    "output": [
      "IMAGE",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "count"
    ],
    "name": "VHS_SelectEveryNthImage",
    "display_name": "Select Every Nth Image ",
    "description": "Select Every Nth Image <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 image for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The output images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the image into groups</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_SelectEveryNthMask": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "select_every_nth": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 9007199254740991,
            "step": 1
          }
        ],
        "skip_first_masks": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 9007199254740991,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "select_every_nth",
        "skip_first_masks"
      ]
    },
    "output": [
      "MASK",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MASK",
      "count"
    ],
    "name": "VHS_SelectEveryNthMask",
    "display_name": "Select Every Nth Mask ",
    "description": "Select Every Nth Mask <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 mask for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The output mask</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_mask: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the mask into groups</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_SelectLatents": {
    "input": {
      "required": {
        "latent": [
          "LATENT"
        ],
        "indexes": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "err_if_missing": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "err_if_empty": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent",
        "indexes",
        "err_if_missing",
        "err_if_empty"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "VHS_SelectLatents",
    "display_name": "Select Latents ",
    "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /latent",
    "output_node": false
  },
  "VHS_SelectImages": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "indexes": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "err_if_missing": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "err_if_empty": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "indexes",
        "err_if_missing",
        "err_if_empty"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "VHS_SelectImages",
    "display_name": "Select Images ",
    "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /image",
    "output_node": false
  },
  "VHS_SelectMasks": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "indexes": [
          "STRING",
          {
            "default": "0"
          }
        ],
        "err_if_missing": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "err_if_empty": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "indexes",
        "err_if_missing",
        "err_if_empty"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "VHS_SelectMasks",
    "display_name": "Select Masks ",
    "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite /mask",
    "output_node": false
  },
  "VHS_Unbatch": {
    "input": {
      "required": {
        "batched": [
          "*"
        ]
      }
    },
    "input_order": {
      "required": [
        "batched"
      ]
    },
    "output": [
      "*"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "unbatched"
    ],
    "name": "VHS_Unbatch",
    "display_name": "Unbatch ",
    "description": "Unbatch <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Unbatch a list of items into a single concatenated item</div></div><div style=\"font-size: 0.8em\">Useful for when you want a single video output from a complex workflow</div><div style=\"font-size: 0.8em\">Has no relation to the Meta Batch system of VHS</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"batched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">batched: Any input which may or may not be batched</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"unbatched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">unbatched: A single output element. Torch tensors are concatenated across dim 0, all other types are added which functions as concatenation for strings and arrays, but may give undesired results for other types</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false
  },
  "VHS_SelectLatest": {
    "input": {
      "required": {
        "filename_prefix": [
          "STRING",
          {
            "default": "output/AnimateDiff",
            "vhs_path_extensions": []
          }
        ],
        "filename_postfix": [
          "STRING",
          {
            "placeholder": ".webm"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "filename_prefix",
        "filename_postfix"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "Filename"
    ],
    "name": "VHS_SelectLatest",
    "display_name": "Select Latest ",
    "description": "Select Latest <div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Experimental virtual node to select the most recently modified file from a given folder</div></div><div style=\"font-size: 0.8em\">Assists in the creation of workflows where outputs from one execution are used elsewhere in subsequent executions.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A path which can consist of a combination of folders and a prefix which candidate files must match</div></div><div vhs_title=\"filename_postfix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_postfix: A string which chich the selected file must end with. Useful for limiting to a target extension.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"Filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Filename: A string representing a file path to the most recently modified file.</div></div></div></div></div>",
    "python_module": "custom_nodes.comfyui-videohelpersuite",
    "category": "Video Helper Suite ",
    "output_node": false,
    "experimental": true
  },
  "CLIPTextEncodeSDXL+": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "height": [
          "INT",
          {
            "default": 1024.0,
            "min": 0,
            "max": 16384
          }
        ],
        "size_cond_factor": [
          "INT",
          {
            "default": 4,
            "min": 1,
            "max": 16
          }
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true,
            "default": ""
          }
        ],
        "clip": [
          "CLIP"
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "size_cond_factor",
        "text",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "CLIPTextEncodeSDXL+",
    "display_name": " SDXL CLIPTextEncode",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/conditioning",
    "output_node": false
  },
  "ConditioningCombineMultiple+": {
    "input": {
      "required": {
        "conditioning_1": [
          "CONDITIONING"
        ],
        "conditioning_2": [
          "CONDITIONING"
        ]
      },
      "optional": {
        "conditioning_3": [
          "CONDITIONING"
        ],
        "conditioning_4": [
          "CONDITIONING"
        ],
        "conditioning_5": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_1",
        "conditioning_2"
      ],
      "optional": [
        "conditioning_3",
        "conditioning_4",
        "conditioning_5"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "ConditioningCombineMultiple+",
    "display_name": " Cond Combine Multiple",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/conditioning",
    "output_node": false
  },
  "SD3NegativeConditioning+": {
    "input": {
      "required": {
        "conditioning": [
          "CONDITIONING"
        ],
        "end": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning",
        "end"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "SD3NegativeConditioning+",
    "display_name": " SD3 Negative Conditioning",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/conditioning",
    "output_node": false
  },
  "ImageEnhanceDifference+": {
    "input": {
      "required": {
        "image1": [
          "IMAGE"
        ],
        "image2": [
          "IMAGE"
        ],
        "exponent": [
          "FLOAT",
          {
            "default": 0.75,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image1",
        "image2",
        "exponent"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageEnhanceDifference+",
    "display_name": " Image Enhance Difference",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image analysis",
    "output_node": false
  },
  "ImageBatchMultiple+": {
    "input": {
      "required": {
        "image_1": [
          "IMAGE"
        ],
        "method": [
          [
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "lanczos"
          ],
          {
            "default": "lanczos"
          }
        ]
      },
      "optional": {
        "image_2": [
          "IMAGE"
        ],
        "image_3": [
          "IMAGE"
        ],
        "image_4": [
          "IMAGE"
        ],
        "image_5": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image_1",
        "method"
      ],
      "optional": [
        "image_2",
        "image_3",
        "image_4",
        "image_5"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageBatchMultiple+",
    "display_name": " Images Batch Multiple",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image batch",
    "output_node": false
  },
  "ImageExpandBatch+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "size": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "step": 1
          }
        ],
        "method": [
          [
            "expand",
            "repeat all",
            "repeat first",
            "repeat last"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "size",
        "method"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageExpandBatch+",
    "display_name": " Image Expand Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image batch",
    "output_node": false
  },
  "ImageFromBatch+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "start": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "step": 1
          }
        ],
        "length": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "start",
        "length"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageFromBatch+",
    "display_name": " Image From Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image batch",
    "output_node": false
  },
  "ImageListToBatch+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageListToBatch+",
    "display_name": " Image List To Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image batch",
    "output_node": false
  },
  "ImageCompositeFromMaskBatch+": {
    "input": {
      "required": {
        "image_from": [
          "IMAGE"
        ],
        "image_to": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "image_from",
        "image_to",
        "mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageCompositeFromMaskBatch+",
    "display_name": " Image Composite From Mask Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageComposite+": {
    "input": {
      "required": {
        "destination": [
          "IMAGE"
        ],
        "source": [
          "IMAGE"
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "offset_x": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "offset_y": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ]
      },
      "optional": {
        "mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "destination",
        "source",
        "x",
        "y",
        "offset_x",
        "offset_y"
      ],
      "optional": [
        "mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageComposite+",
    "display_name": " Image Composite",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageCrop+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "width": [
          "INT",
          {
            "default": 256,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 256,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "position": [
          [
            "top-left",
            "top-center",
            "top-right",
            "right-center",
            "bottom-right",
            "bottom-center",
            "bottom-left",
            "left-center",
            "center"
          ]
        ],
        "x_offset": [
          "INT",
          {
            "default": 0,
            "min": -99999,
            "step": 1
          }
        ],
        "y_offset": [
          "INT",
          {
            "default": 0,
            "min": -99999,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "width",
        "height",
        "position",
        "x_offset",
        "y_offset"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "x",
      "y"
    ],
    "name": "ImageCrop+",
    "display_name": " Image Crop",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageFlip+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "axis": [
          [
            "x",
            "y",
            "xy"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "axis"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageFlip+",
    "display_name": " Image Flip",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageRandomTransform+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "repeat": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "variation": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "seed",
        "repeat",
        "variation"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageRandomTransform+",
    "display_name": " Image Random Transform",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageRemoveAlpha+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageRemoveAlpha+",
    "display_name": " Image Remove Alpha",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image utils",
    "output_node": false
  },
  "ImageRemoveBackground+": {
    "input": {
      "required": {
        "rembg_session": [
          "REMBG_SESSION"
        ],
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "rembg_session",
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "ImageRemoveBackground+",
    "display_name": " Image Remove Background",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageResize+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 0,
            "max": 16384,
            "step": 1
          }
        ],
        "interpolation": [
          [
            "nearest",
            "bilinear",
            "bicubic",
            "area",
            "nearest-exact",
            "lanczos"
          ]
        ],
        "method": [
          [
            "stretch",
            "keep proportion",
            "fill / crop",
            "pad"
          ]
        ],
        "condition": [
          [
            "always",
            "downscale if bigger",
            "upscale if smaller",
            "if bigger area",
            "if smaller area"
          ]
        ],
        "multiple_of": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 512,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "width",
        "height",
        "interpolation",
        "method",
        "condition",
        "multiple_of"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "width",
      "height"
    ],
    "name": "ImageResize+",
    "display_name": " Image Resize",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageSeamCarving+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "energy": [
          [
            "backward",
            "forward"
          ]
        ],
        "order": [
          [
            "width-first",
            "height-first"
          ]
        ]
      },
      "optional": {
        "keep_mask": [
          "MASK"
        ],
        "drop_mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "width",
        "height",
        "energy",
        "order"
      ],
      "optional": [
        "keep_mask",
        "drop_mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageSeamCarving+",
    "display_name": " Image Seam Carving",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageTile+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "rows": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "cols": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "overlap": [
          "FLOAT",
          {
            "default": 0,
            "min": 0,
            "max": 0.5,
            "step": 0.01
          }
        ],
        "overlap_x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 1
          }
        ],
        "overlap_y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "rows",
        "cols",
        "overlap",
        "overlap_x",
        "overlap_y"
      ]
    },
    "output": [
      "IMAGE",
      "INT",
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "tile_width",
      "tile_height",
      "overlap_x",
      "overlap_y"
    ],
    "name": "ImageTile+",
    "display_name": " Image Tile",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageUntile+": {
    "input": {
      "required": {
        "tiles": [
          "IMAGE"
        ],
        "overlap_x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 1
          }
        ],
        "overlap_y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 8192,
            "step": 1
          }
        ],
        "rows": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "cols": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "tiles",
        "overlap_x",
        "overlap_y",
        "rows",
        "cols"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageUntile+",
    "display_name": " Image Untile",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "RemBGSession+": {
    "input": {
      "required": {
        "model": [
          [
            "u2net: general purpose",
            "u2netp: lightweight general purpose",
            "u2net_human_seg: human segmentation",
            "u2net_cloth_seg: cloths Parsing",
            "silueta: very small u2net",
            "isnet-general-use: general purpose",
            "isnet-anime: anime illustrations",
            "sam: general purpose"
          ]
        ],
        "providers": [
          [
            "CPU",
            "CUDA",
            "ROCM",
            "DirectML",
            "OpenVINO",
            "CoreML",
            "Tensorrt",
            "Azure"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "providers"
      ]
    },
    "output": [
      "REMBG_SESSION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "REMBG_SESSION"
    ],
    "name": "RemBGSession+",
    "display_name": " RemBG Session",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "TransparentBGSession+": {
    "input": {
      "required": {
        "mode": [
          [
            "base",
            "fast",
            "base-nightly"
          ]
        ],
        "use_jit": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mode",
        "use_jit"
      ]
    },
    "output": [
      "REMBG_SESSION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "REMBG_SESSION"
    ],
    "name": "TransparentBGSession+",
    "display_name": " InSPyReNet TransparentBG",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image manipulation",
    "output_node": false
  },
  "ImageApplyLUT+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "lut_file": [
          []
        ],
        "gamma_correction": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "clip_values": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "lut_file",
        "gamma_correction",
        "clip_values",
        "strength"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageApplyLUT+",
    "display_name": " Image Apply LUT",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImageCASharpening+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "amount": [
          "FLOAT",
          {
            "default": 0.8,
            "min": 0,
            "max": 1,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "amount"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageCASharpening+",
    "display_name": " Image Contrast Adaptive Sharpening",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImageDesaturate+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "method": [
          [
            "luminance (Rec.709)",
            "luminance (Rec.601)",
            "average",
            "lightness"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "factor",
        "method"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageDesaturate+",
    "display_name": " Image Desaturate",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "PixelOEPixelize+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "downscale_mode": [
          [
            "contrast",
            "bicubic",
            "nearest",
            "center",
            "k-centroid"
          ]
        ],
        "target_size": [
          "INT",
          {
            "default": 128,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "patch_size": [
          "INT",
          {
            "default": 16,
            "min": 4,
            "max": 32,
            "step": 2
          }
        ],
        "thickness": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 16,
            "step": 1
          }
        ],
        "color_matching": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "upscale": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "downscale_mode",
        "target_size",
        "patch_size",
        "thickness",
        "color_matching",
        "upscale"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "PixelOEPixelize+",
    "display_name": " Pixelize",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImagePosterize+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "threshold": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "threshold"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImagePosterize+",
    "display_name": " Image Posterize",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImageColorMatch+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "reference": [
          "IMAGE"
        ],
        "color_space": [
          [
            "LAB",
            "YCbCr",
            "RGB",
            "LUV",
            "YUV",
            "XYZ"
          ]
        ],
        "factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "gpu"
          ]
        ],
        "batch_size": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 1024,
            "step": 1
          }
        ]
      },
      "optional": {
        "reference_mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "reference",
        "color_space",
        "factor",
        "device",
        "batch_size"
      ],
      "optional": [
        "reference_mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageColorMatch+",
    "display_name": " Image Color Match",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImageColorMatchAdobe+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "reference": [
          "IMAGE"
        ],
        "color_space": [
          [
            "RGB",
            "LAB"
          ]
        ],
        "luminance_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 2.0,
            "step": 0.05
          }
        ],
        "color_intensity_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 2.0,
            "step": 0.05
          }
        ],
        "fade_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "neutralization_factor": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "gpu"
          ]
        ]
      },
      "optional": {
        "reference_mask": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "reference",
        "color_space",
        "luminance_factor",
        "color_intensity_factor",
        "fade_factor",
        "neutralization_factor",
        "device"
      ],
      "optional": [
        "reference_mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageColorMatchAdobe+",
    "display_name": " Image Color Match Adobe",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "ImageHistogramMatch+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "reference": [
          "IMAGE"
        ],
        "method": [
          [
            "pytorch",
            "skimage"
          ]
        ],
        "factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "gpu"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "reference",
        "method",
        "factor",
        "device"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageHistogramMatch+",
    "display_name": " Image Histogram Match",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image processing",
    "output_node": false
  },
  "GetImageSize+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "width",
      "height",
      "count"
    ],
    "name": "GetImageSize+",
    "display_name": " Get Image Size",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image utils",
    "output_node": false
  },
  "ImageToDevice+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "device": [
          [
            "auto",
            "cpu",
            "gpu"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "device"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "ImageToDevice+",
    "display_name": " Image To Device",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image utils",
    "output_node": false
  },
  "ImagePreviewFromLatent+": {
    "input": {
      "required": {
        "latent": [
          "LATENT"
        ],
        "vae": [
          "VAE"
        ],
        "tile_size": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096,
            "step": 64
          }
        ]
      },
      "optional": {
        "image": [
          [
            "none"
          ],
          {
            "image_upload": false
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "latent",
        "vae",
        "tile_size"
      ],
      "optional": [
        "image"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK",
      "width",
      "height"
    ],
    "name": "ImagePreviewFromLatent+",
    "display_name": " Image Preview From Latent",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image utils",
    "output_node": true
  },
  "NoiseFromImage+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "noise_strenght": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "noise_size": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "color_noise": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "mask_strength": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "mask_scale_diff": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "mask_contrast": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "saturation": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "contrast": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1
          }
        ],
        "blur": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.1
          }
        ]
      },
      "optional": {
        "noise_mask": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "noise_strenght",
        "noise_size",
        "color_noise",
        "mask_strength",
        "mask_scale_diff",
        "mask_contrast",
        "saturation",
        "contrast",
        "blur"
      ],
      "optional": [
        "noise_mask"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "NoiseFromImage+",
    "display_name": " Noise From Image",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/image utils",
    "output_node": false
  },
  "MaskBlur+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "amount": [
          "INT",
          {
            "default": 6,
            "min": 0,
            "max": 256,
            "step": 1
          }
        ],
        "device": [
          [
            "auto",
            "cpu",
            "gpu"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "amount",
        "device"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskBlur+",
    "display_name": " Mask Blur",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskBoundingBox+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "padding": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096,
            "step": 1
          }
        ],
        "blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 256,
            "step": 1
          }
        ]
      },
      "optional": {
        "image_optional": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "padding",
        "blur"
      ],
      "optional": [
        "image_optional"
      ]
    },
    "output": [
      "MASK",
      "IMAGE",
      "INT",
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MASK",
      "IMAGE",
      "x",
      "y",
      "width",
      "height"
    ],
    "name": "MaskBoundingBox+",
    "display_name": " Mask Bounding Box",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFix+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "erode_dilate": [
          "INT",
          {
            "default": 0,
            "min": -256,
            "max": 256,
            "step": 1
          }
        ],
        "fill_holes": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 128,
            "step": 1
          }
        ],
        "remove_isolated_pixels": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 32,
            "step": 1
          }
        ],
        "smooth": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 256,
            "step": 1
          }
        ],
        "blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 256,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "erode_dilate",
        "fill_holes",
        "remove_isolated_pixels",
        "smooth",
        "blur"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFix+",
    "display_name": " Mask Fix",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFlip+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "axis": [
          [
            "x",
            "y",
            "xy"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "axis"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFlip+",
    "display_name": " Mask Flip",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFromColor+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "red": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "green": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "blue": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "threshold": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 127,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "red",
        "green",
        "blue",
        "threshold"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFromColor+",
    "display_name": " Mask From Color",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFromList+": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 32,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "height": [
          "INT",
          {
            "default": 32,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      },
      "optional": {
        "values": [
          "INT,FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "str_values": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "placeholder": "0.0, 0.5, 1.0"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height"
      ],
      "optional": [
        "values",
        "str_values"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFromList+",
    "display_name": " Mask From List",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFromRGBCMYBW+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "threshold_r": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1,
            "step": 0.01
          }
        ],
        "threshold_g": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1,
            "step": 0.01
          }
        ],
        "threshold_b": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "threshold_r",
        "threshold_g",
        "threshold_b"
      ]
    },
    "output": [
      "MASK",
      "MASK",
      "MASK",
      "MASK",
      "MASK",
      "MASK",
      "MASK",
      "MASK"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "red",
      "green",
      "blue",
      "cyan",
      "magenta",
      "yellow",
      "black",
      "white"
    ],
    "name": "MaskFromRGBCMYBW+",
    "display_name": " Mask From RGB/CMY/BW",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskFromSegmentation+": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "segments": [
          "INT",
          {
            "default": 6,
            "min": 1,
            "max": 16,
            "step": 1
          }
        ],
        "remove_isolated_pixels": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 32,
            "step": 1
          }
        ],
        "remove_small_masks": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "fill_holes": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "segments",
        "remove_isolated_pixels",
        "remove_small_masks",
        "fill_holes"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFromSegmentation+",
    "display_name": " Mask From Segmentation",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskPreview+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "mask"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "MaskPreview+",
    "display_name": " Mask Preview",
    "description": "Saves the input images to your ComfyUI output directory.",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": true
  },
  "MaskSmooth+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "amount": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 127,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "amount"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskSmooth+",
    "display_name": " Mask Smooth",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "TransitionMask+": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 1,
            "max": 16384,
            "step": 1
          }
        ],
        "frames": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "max": 9999,
            "step": 1
          }
        ],
        "start_frame": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "step": 1
          }
        ],
        "end_frame": [
          "INT",
          {
            "default": 9999,
            "min": 0,
            "step": 1
          }
        ],
        "transition_type": [
          [
            "horizontal slide",
            "vertical slide",
            "horizontal bar",
            "vertical bar",
            "center box",
            "horizontal door",
            "vertical door",
            "circle",
            "fade"
          ]
        ],
        "timing_function": [
          [
            "linear",
            "in",
            "out",
            "in-out"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "frames",
        "start_frame",
        "end_frame",
        "transition_type",
        "timing_function"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "TransitionMask+",
    "display_name": " Transition Mask",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask",
    "output_node": false
  },
  "MaskBatch+": {
    "input": {
      "required": {
        "mask1": [
          "MASK"
        ],
        "mask2": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "mask1",
        "mask2"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskBatch+",
    "display_name": " Mask Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask batch",
    "output_node": false
  },
  "MaskExpandBatch+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "size": [
          "INT",
          {
            "default": 16,
            "min": 1,
            "step": 1
          }
        ],
        "method": [
          [
            "expand",
            "repeat all",
            "repeat first",
            "repeat last"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "size",
        "method"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskExpandBatch+",
    "display_name": " Mask Expand Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask batch",
    "output_node": false
  },
  "MaskFromBatch+": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "start": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "step": 1
          }
        ],
        "length": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "start",
        "length"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "MaskFromBatch+",
    "display_name": " Mask From Batch",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/mask batch",
    "output_node": false
  },
  "KSamplerVariationsStochastic+": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "latent_image": [
          "LATENT"
        ],
        "noise_seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "steps": [
          "INT",
          {
            "default": 25,
            "min": 1,
            "max": 10000
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 7.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "sampler": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "variation_seed": [
          "INT:seed",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "variation_strength": [
          "FLOAT",
          {
            "default": 0.2,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05,
            "round": 0.01
          }
        ],
        "cfg_scale": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "latent_image",
        "noise_seed",
        "steps",
        "cfg",
        "sampler",
        "scheduler",
        "positive",
        "negative",
        "variation_seed",
        "variation_strength",
        "cfg_scale"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "KSamplerVariationsStochastic+",
    "display_name": " KSampler Stochastic Variations",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/sampling",
    "output_node": false
  },
  "KSamplerVariationsWithNoise+": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "latent_image": [
          "LATENT"
        ],
        "main_seed": [
          "INT:seed",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0,
            "step": 0.1,
            "round": 0.01
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "variation_strength": [
          "FLOAT",
          {
            "default": 0.17,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "round": 0.01
          }
        ],
        "variation_seed": [
          "INT:seed",
          {
            "default": 12345,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "latent_image",
        "main_seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "variation_strength",
        "variation_seed",
        "denoise"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "KSamplerVariationsWithNoise+",
    "display_name": " KSampler Variations with Noise Injection",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/sampling",
    "output_node": false
  },
  "InjectLatentNoise+": {
    "input": {
      "required": {
        "latent": [
          "LATENT"
        ],
        "noise_seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "noise_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -20.0,
            "max": 20.0,
            "step": 0.01,
            "round": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent",
        "noise_seed",
        "noise_strength"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "InjectLatentNoise+",
    "display_name": " Inject Latent Noise",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/sampling",
    "output_node": false
  },
  "FluxSamplerParams+": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "conditioning": [
          "CONDITIONING"
        ],
        "latent_image": [
          "LATENT"
        ],
        "noise": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "?"
          }
        ],
        "sampler": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "ipndm"
          }
        ],
        "scheduler": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "simple"
          }
        ],
        "steps": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "20"
          }
        ],
        "guidance": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "3.5"
          }
        ],
        "max_shift": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "1.15"
          }
        ],
        "base_shift": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "0.5"
          }
        ],
        "split_sigmas": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "1.0"
          }
        ],
        "denoise": [
          "STRING",
          {
            "multiline": false,
            "dynamicPrompts": false,
            "default": "1.0"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "conditioning",
        "latent_image",
        "noise",
        "sampler",
        "scheduler",
        "steps",
        "guidance",
        "max_shift",
        "base_shift",
        "split_sigmas",
        "denoise"
      ]
    },
    "output": [
      "LATENT",
      "SAMPLER_PARAMS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "latent",
      "params"
    ],
    "name": "FluxSamplerParams+",
    "display_name": " Flux Sampler Parameters",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/sampling",
    "output_node": false
  },
  "PlotParameters+": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "params": [
          "SAMPLER_PARAMS"
        ],
        "order_by": [
          [
            "none",
            "time",
            "seed",
            "steps",
            "denoise",
            "sampler",
            "scheduler"
          ]
        ],
        "cols_value": [
          [
            "none",
            "time",
            "seed",
            "steps",
            "denoise",
            "sampler",
            "scheduler"
          ]
        ],
        "cols_num": [
          "INT",
          {
            "default": -1,
            "min": -1,
            "max": 1024
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "params",
        "order_by",
        "cols_value",
        "cols_num"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "PlotParameters+",
    "display_name": " Plot Sampler Parameters",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/sampling",
    "output_node": false
  },
  "ApplyCLIPSeg+": {
    "input": {
      "required": {
        "clip_seg": [
          "CLIP_SEG"
        ],
        "image": [
          "IMAGE"
        ],
        "prompt": [
          "STRING",
          {
            "multiline": false,
            "default": ""
          }
        ],
        "threshold": [
          "FLOAT",
          {
            "default": 0.4,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          }
        ],
        "smooth": [
          "INT",
          {
            "default": 9,
            "min": 0,
            "max": 32,
            "step": 1
          }
        ],
        "dilate": [
          "INT",
          {
            "default": 0,
            "min": -32,
            "max": 32,
            "step": 1
          }
        ],
        "blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_seg",
        "image",
        "prompt",
        "threshold",
        "smooth",
        "dilate",
        "blur"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "ApplyCLIPSeg+",
    "display_name": " Apply CLIPSeg",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/segmentation",
    "output_node": false
  },
  "LoadCLIPSegModels+": {
    "input": {
      "required": {}
    },
    "input_order": {
      "required": []
    },
    "output": [
      "CLIP_SEG"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP_SEG"
    ],
    "name": "LoadCLIPSegModels+",
    "display_name": " Load CLIPSeg Models",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/segmentation",
    "output_node": false
  },
  "DrawText+": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true,
            "default": "Hello, World!"
          }
        ],
        "font": [
          [
            "ShareTechMono-Regular.ttf"
          ]
        ],
        "size": [
          "INT",
          {
            "default": 56,
            "min": 1,
            "max": 9999,
            "step": 1
          }
        ],
        "color": [
          "STRING",
          {
            "multiline": false,
            "default": "#FFFFFF"
          }
        ],
        "background_color": [
          "STRING",
          {
            "multiline": false,
            "default": "#00000000"
          }
        ],
        "shadow_distance": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "shadow_blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "shadow_color": [
          "STRING",
          {
            "multiline": false,
            "default": "#000000"
          }
        ],
        "horizontal_align": [
          [
            "left",
            "center",
            "right"
          ]
        ],
        "vertical_align": [
          [
            "top",
            "center",
            "bottom"
          ]
        ],
        "offset_x": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ],
        "offset_y": [
          "INT",
          {
            "default": 0,
            "min": -16384,
            "max": 16384,
            "step": 1
          }
        ]
      },
      "optional": {
        "img_composite": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "font",
        "size",
        "color",
        "background_color",
        "shadow_distance",
        "shadow_blur",
        "shadow_color",
        "horizontal_align",
        "vertical_align",
        "offset_x",
        "offset_y"
      ],
      "optional": [
        "img_composite"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "DrawText+",
    "display_name": " Draw Text",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/text",
    "output_node": false
  },
  "BatchCount+": {
    "input": {
      "required": {
        "batch": [
          "*",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "batch"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INT"
    ],
    "name": "BatchCount+",
    "display_name": " Batch Count",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": false
  },
  "ConsoleDebug+": {
    "input": {
      "required": {
        "value": [
          "*",
          {}
        ]
      },
      "optional": {
        "prefix": [
          "STRING",
          {
            "multiline": false,
            "default": "Value:"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "value"
      ],
      "optional": [
        "prefix"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "ConsoleDebug+",
    "display_name": " Console Debug",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": true
  },
  "DebugTensorShape+": {
    "input": {
      "required": {
        "tensor": [
          "*",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "tensor"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "DebugTensorShape+",
    "display_name": " Debug Tensor Shape",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": true
  },
  "ModelCompile+": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "fullgraph": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "dynamic": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "mode": [
          [
            "default",
            "reduce-overhead",
            "max-autotune",
            "max-autotune-no-cudagraphs"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "fullgraph",
        "dynamic",
        "mode"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "ModelCompile+",
    "display_name": " Model Compile",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": false
  },
  "RemoveLatentMask+": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "samples"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "RemoveLatentMask+",
    "display_name": " Remove Latent Mask",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": false
  },
  "SDXLEmptyLatentSizePicker+": {
    "input": {
      "required": {
        "resolution": [
          [
            "704x1408 (0.5)",
            "704x1344 (0.52)",
            "768x1344 (0.57)",
            "768x1280 (0.6)",
            "832x1216 (0.68)",
            "832x1152 (0.72)",
            "896x1152 (0.78)",
            "896x1088 (0.82)",
            "960x1088 (0.88)",
            "960x1024 (0.94)",
            "1024x1024 (1.0)",
            "1024x960 (1.07)",
            "1088x960 (1.13)",
            "1088x896 (1.21)",
            "1152x896 (1.29)",
            "1152x832 (1.38)",
            "1216x832 (1.46)",
            "1280x768 (1.67)",
            "1344x768 (1.75)",
            "1344x704 (1.91)",
            "1408x704 (2.0)",
            "1472x704 (2.09)",
            "1536x640 (2.4)",
            "1600x640 (2.5)",
            "1664x576 (2.89)",
            "1728x576 (3.0)"
          ],
          {
            "default": "1024x1024 (1.0)"
          }
        ],
        "batch_size": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 4096
          }
        ],
        "width_override": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ],
        "height_override": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16384,
            "step": 8
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "resolution",
        "batch_size",
        "width_override",
        "height_override"
      ]
    },
    "output": [
      "LATENT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "width",
      "height"
    ],
    "name": "SDXLEmptyLatentSizePicker+",
    "display_name": " SDXL Empty Latent Size Picker",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": false
  },
  "SimpleMath+": {
    "input": {
      "optional": {
        "a": [
          "INT,FLOAT",
          {
            "default": 0.0,
            "step": 0.1
          }
        ],
        "b": [
          "INT,FLOAT",
          {
            "default": 0.0,
            "step": 0.1
          }
        ]
      },
      "required": {
        "value": [
          "STRING",
          {
            "multiline": false,
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "optional": [
        "a",
        "b"
      ],
      "required": [
        "value"
      ]
    },
    "output": [
      "INT",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "INT",
      "FLOAT"
    ],
    "name": "SimpleMath+",
    "display_name": " Simple Math",
    "description": "",
    "python_module": "custom_nodes.comfyui_essentials",
    "category": "essentials/utilities",
    "output_node": false
  },
  "DownloadAndLoadFramePackModel": {
    "input": {
      "required": {
        "model": [
          [
            "lllyasviel/FramePackI2V_HY"
          ]
        ],
        "base_precision": [
          [
            "fp32",
            "bf16",
            "fp16"
          ],
          {
            "default": "bf16"
          }
        ],
        "quantization": [
          [
            "disabled",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2"
          ],
          {
            "default": "disabled",
            "tooltip": "optional quantization method"
          }
        ]
      },
      "optional": {
        "attention_mode": [
          [
            "sdpa",
            "flash_attn",
            "sageattn"
          ],
          {
            "default": "sdpa"
          }
        ],
        "compile_args": [
          "FRAMEPACKCOMPILEARGS"
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "base_precision",
        "quantization"
      ],
      "optional": [
        "attention_mode",
        "compile_args"
      ]
    },
    "output": [
      "FramePackMODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "model"
    ],
    "name": "DownloadAndLoadFramePackModel",
    "display_name": "(Down)Load FramePackModel",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "FramePackSampler": {
    "input": {
      "required": {
        "model": [
          "FramePackMODEL"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "start_latent": [
          "LATENT",
          {
            "tooltip": "init Latents to use for image2video"
          }
        ],
        "steps": [
          "INT",
          {
            "default": 30,
            "min": 1
          }
        ],
        "use_teacache": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Use teacache for faster sampling."
          }
        ],
        "teacache_rel_l1_thresh": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "The threshold for the relative L1 loss."
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 30.0,
            "step": 0.01
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "default": 10.0,
            "min": 0.0,
            "max": 32.0,
            "step": 0.01
          }
        ],
        "shift": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "latent_window_size": [
          "INT",
          {
            "default": 9,
            "min": 1,
            "max": 33,
            "step": 1,
            "tooltip": "The size of the latent window to use for sampling."
          }
        ],
        "total_second_length": [
          "FLOAT",
          {
            "default": 5,
            "min": 1,
            "max": 120,
            "step": 0.1,
            "tooltip": "The total length of the video in seconds."
          }
        ],
        "gpu_memory_preservation": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 128.0,
            "step": 0.1,
            "tooltip": "The amount of GPU memory to preserve."
          }
        ],
        "sampler": [
          [
            "unipc_bh1",
            "unipc_bh2"
          ],
          {
            "default": "unipc_bh1"
          }
        ]
      },
      "optional": {
        "image_embeds": [
          "CLIP_VISION_OUTPUT"
        ],
        "end_latent": [
          "LATENT",
          {
            "tooltip": "end Latents to use for image2video"
          }
        ],
        "end_image_embeds": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "end Image's clip embeds"
          }
        ],
        "embed_interpolation": [
          [
            "disabled",
            "weighted_average",
            "linear"
          ],
          {
            "default": "disabled",
            "tooltip": "Image embedding interpolation type. If linear, will smoothly interpolate with time, else it'll be weighted average with the specified weight."
          }
        ],
        "start_embed_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "Weighted average constant for image embed interpolation. If end image is not set, the embed's strength won't be affected"
          }
        ],
        "initial_samples": [
          "LATENT",
          {
            "tooltip": "init Latents to use for video2video"
          }
        ],
        "denoise_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "positive",
        "negative",
        "start_latent",
        "steps",
        "use_teacache",
        "teacache_rel_l1_thresh",
        "cfg",
        "guidance_scale",
        "shift",
        "seed",
        "latent_window_size",
        "total_second_length",
        "gpu_memory_preservation",
        "sampler"
      ],
      "optional": [
        "image_embeds",
        "end_latent",
        "end_image_embeds",
        "embed_interpolation",
        "start_embed_strength",
        "initial_samples",
        "denoise_strength"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "samples"
    ],
    "name": "FramePackSampler",
    "display_name": "FramePackSampler",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "FramePackTorchCompileSettings": {
    "input": {
      "required": {
        "backend": [
          [
            "inductor",
            "cudagraphs"
          ],
          {
            "default": "inductor"
          }
        ],
        "fullgraph": [
          "BOOLEAN",
          {
            "default": false,
            "tooltip": "Enable full graph mode"
          }
        ],
        "mode": [
          [
            "default",
            "max-autotune",
            "max-autotune-no-cudagraphs",
            "reduce-overhead"
          ],
          {
            "default": "default"
          }
        ],
        "dynamic": [
          "BOOLEAN",
          {
            "default": false,
            "tooltip": "Enable dynamic mode"
          }
        ],
        "dynamo_cache_size_limit": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 1024,
            "step": 1,
            "tooltip": "torch._dynamo.config.cache_size_limit"
          }
        ],
        "compile_single_blocks": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Enable single block compilation"
          }
        ],
        "compile_double_blocks": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Enable double block compilation"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "backend",
        "fullgraph",
        "mode",
        "dynamic",
        "dynamo_cache_size_limit",
        "compile_single_blocks",
        "compile_double_blocks"
      ]
    },
    "output": [
      "FRAMEPACKCOMPILEARGS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "torch_compile_args"
    ],
    "name": "FramePackTorchCompileSettings",
    "display_name": "Torch Compile Settings",
    "description": "torch.compile settings, when connected to the model loader, torch.compile of the selected layers is attempted. Requires Triton and torch 2.5.0 is recommended",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "HunyuanVideoWrapper",
    "output_node": false
  },
  "FramePackFindNearestBucket": {
    "input": {
      "required": {
        "image": [
          "IMAGE",
          {
            "tooltip": "Image to resize"
          }
        ],
        "base_resolution": [
          "INT",
          {
            "default": 640,
            "min": 64,
            "max": 2048,
            "step": 16,
            "tooltip": "Width of the image to encode"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "base_resolution"
      ]
    },
    "output": [
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "width",
      "height"
    ],
    "name": "FramePackFindNearestBucket",
    "display_name": "Find Nearest Bucket",
    "description": "Finds the closes resolution bucket as defined in the orignal code",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "LoadFramePackModel": {
    "input": {
      "required": {
        "model": [
          [],
          {
            "tooltip": "These models are loaded from the 'ComfyUI/models/diffusion_models' -folder"
          }
        ],
        "base_precision": [
          [
            "fp32",
            "bf16",
            "fp16"
          ],
          {
            "default": "bf16"
          }
        ],
        "quantization": [
          [
            "disabled",
            "fp8_e4m3fn",
            "fp8_e4m3fn_fast",
            "fp8_e5m2"
          ],
          {
            "default": "disabled",
            "tooltip": "optional quantization method"
          }
        ],
        "load_device": [
          [
            "main_device",
            "offload_device"
          ],
          {
            "default": "cuda",
            "tooltip": "Initialize the model on the main device or offload device"
          }
        ]
      },
      "optional": {
        "attention_mode": [
          [
            "sdpa",
            "flash_attn",
            "sageattn"
          ],
          {
            "default": "sdpa"
          }
        ],
        "compile_args": [
          "FRAMEPACKCOMPILEARGS"
        ],
        "lora": [
          "FPLORA",
          {
            "default": null,
            "tooltip": "LORA model to load"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "base_precision",
        "quantization",
        "load_device"
      ],
      "optional": [
        "attention_mode",
        "compile_args",
        "lora"
      ]
    },
    "output": [
      "FramePackMODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "model"
    ],
    "name": "LoadFramePackModel",
    "display_name": "Load FramePackModel",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "FramePackLoraSelect": {
    "input": {
      "required": {
        "lora": [
          [],
          {
            "tooltip": "LORA models are expected to be in ComfyUI/models/loras with .safetensors extension"
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.0001,
            "tooltip": "LORA strength, set to 0.0 to unmerge the LORA"
          }
        ],
        "fuse_lora": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Fuse the LORA model with the base model. This is recommended for better performance."
          }
        ]
      },
      "optional": {
        "prev_lora": [
          "FPLORA",
          {
            "default": null,
            "tooltip": "For loading multiple LoRAs"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "lora",
        "strength",
        "fuse_lora"
      ],
      "optional": [
        "prev_lora"
      ]
    },
    "output": [
      "FPLORA"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "lora"
    ],
    "name": "FramePackLoraSelect",
    "display_name": "Select Lora",
    "description": "Select a LoRA model from ComfyUI/models/loras",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "FramePackSampler_F1": {
    "input": {
      "required": {
        "model": [
          "FramePackMODEL"
        ],
        "positive_timed_data": [
          "TIMED_CONDITIONING_WITH_METADATA",
          {
            "tooltip": "Output from FramePackTimestampedTextEncode. Dictionary containing sections, duration, and window size."
          }
        ],
        "negative": [
          "CONDITIONING"
        ],
        "steps": [
          "INT",
          {
            "default": 30,
            "min": 1
          }
        ],
        "use_teacache": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Use teacache for faster sampling."
          }
        ],
        "teacache_rel_l1_thresh": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "The threshold for the relative L1 loss."
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 30.0,
            "step": 0.01
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "default": 10.0,
            "min": 0.0,
            "max": 32.0,
            "step": 0.01
          }
        ],
        "shift": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "gpu_memory_preservation": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 128.0,
            "step": 0.1,
            "tooltip": "The amount of GPU memory to preserve."
          }
        ],
        "sampler": [
          [
            "unipc_bh1",
            "unipc_bh2"
          ],
          {
            "default": "unipc_bh1"
          }
        ]
      },
      "optional": {
        "start_latent": [
          "LATENT",
          {
            "tooltip": "init Latents to use for image2video"
          }
        ],
        "start_image_embeds": [
          "CLIP_VISION_OUTPUT"
        ],
        "end_latent": [
          "LATENT",
          {
            "tooltip": "end Latents to use for image2video"
          }
        ],
        "end_image_embeds": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "end Image's clip embeds"
          }
        ],
        "embed_interpolation": [
          [
            "disabled",
            "weighted_average",
            "linear"
          ],
          {
            "default": "disabled",
            "tooltip": "Image embedding interpolation type. If linear, will smoothly interpolate with time, else it'll be weighted average with the specified weight."
          }
        ],
        "start_embed_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "Weighted average constant for image embed interpolation. If end image is not set, the embed's strength won't be affected"
          }
        ],
        "initial_samples": [
          "LATENT",
          {
            "tooltip": "init Latents to use for video2video"
          }
        ],
        "denoise_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "positive_timed_data",
        "negative",
        "steps",
        "use_teacache",
        "teacache_rel_l1_thresh",
        "cfg",
        "guidance_scale",
        "shift",
        "seed",
        "gpu_memory_preservation",
        "sampler"
      ],
      "optional": [
        "start_latent",
        "start_image_embeds",
        "end_latent",
        "end_image_embeds",
        "embed_interpolation",
        "start_embed_strength",
        "initial_samples",
        "denoise_strength"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "samples"
    ],
    "name": "FramePackSampler_F1",
    "display_name": "FramePackSampler (F1)",
    "description": "",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "FramePackTimestampedTextEncode": {
    "input": {
      "required": {
        "clip": [
          "CLIP"
        ],
        "text": [
          "STRING",
          {
            "multiline": true,
            "dynamicPrompts": true,
            "tooltip": "Text prompt, use [Xs: prompt] or [Xs-Ys: prompt] for timed sections."
          }
        ],
        "negative_text": [
          "STRING",
          {
            "multiline": false,
            "default": "",
            "dynamicPrompts": false,
            "tooltip": "Single negative text prompt"
          }
        ],
        "total_second_length": [
          "FLOAT",
          {
            "default": 5.0,
            "min": 0.1,
            "max": 1200.0,
            "step": 0.1,
            "tooltip": "Expected total video duration in seconds for timestamp calculation."
          }
        ],
        "latent_window_size": [
          "INT",
          {
            "default": 9,
            "min": 1,
            "max": 33,
            "step": 1,
            "tooltip": "The latent window size used by the sampler for timestamp boundary snapping."
          }
        ],
        "prompt_blend_sections": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10,
            "step": 1,
            "tooltip": "Number of latent sections (windows) over which to blend prompts when they change. 0 disables blending."
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "text",
        "negative_text",
        "total_second_length",
        "latent_window_size",
        "prompt_blend_sections"
      ]
    },
    "output": [
      "TIMED_CONDITIONING_WITH_METADATA",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive_timed_data",
      "negative"
    ],
    "name": "FramePackTimestampedTextEncode",
    "display_name": "FramePack Text Encode (Enhanced)",
    "description": "Encodes text prompts with optional timestamps for timed conditioning.\n\nUse format: [Xs: prompt] or [Xs-Ys: prompt] where X and Y are times in seconds (e.g., 0s, 1.5s, 10s).\n- [Xs: prompt]: Prompt applies from time X until the next timestamp starts (or end of video).\n- [Xs-Ys: prompt]: Prompt applies specifically between time X and time Y.\n\nText before the first timestamp defaults to starting at 0s.\nGaps between specified timestamps are automatically filled, typically using the preceding prompt.\nTimestamps are aligned to internal section boundaries based on latent_window_size.\n\nOutputs a dictionary containing:\n- timed conditioning sections: List of (start_sec, end_sec, conditioning) tuples defining the prompt for each time segment.\n- total duration: The overall video length in seconds, used for time calculations.\n- latent window size: The sampler's processing window size, used for aligning timestamps.\n- prompt blend sections: Number of sections over which to smoothly blend between changing prompts(if you want smoother visual transitions when your timed prompts change. A higher value gives a longer, more gradual blend).\n",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_Plus",
    "category": "FramePackWrapper/experimental",
    "output_node": false
  },
  "FramePackSingleFrameSampler": {
    "input": {
      "required": {
        "model": [
          "FramePackMODEL"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "start_latent": [
          "LATENT",
          {
            "tooltip": "init Latents to use for image2image"
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "tooltip": "Sampling steps (10=fast preview, 20=balanced, 30=high quality)"
          }
        ],
        "use_teacache": [
          "BOOLEAN",
          {
            "default": false,
            "tooltip": "Use TeaCache for faster sampling (recommended for 15+ steps)."
          }
        ],
        "teacache_rel_l1_thresh": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "The threshold for the relative L1 loss."
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 30.0,
            "step": 0.01
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "default": 10.0,
            "min": 0.0,
            "max": 32.0,
            "step": 0.01
          }
        ],
        "shift": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "latent_window_size": [
          "INT",
          {
            "default": 9,
            "min": 1,
            "max": 33,
            "step": 1,
            "tooltip": "The size of the latent window to use for sampling."
          }
        ],
        "gpu_memory_preservation": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 128.0,
            "step": 0.1,
            "tooltip": "The amount of GPU memory to preserve."
          }
        ],
        "sampler": [
          [
            "unipc_bh1",
            "unipc_bh2"
          ],
          {
            "default": "unipc_bh1"
          }
        ]
      },
      "optional": {
        "image_embeds": [
          "CLIP_VISION_OUTPUT"
        ],
        "initial_samples": [
          "LATENT",
          {
            "tooltip": "init Latents to use for image2image variation"
          }
        ],
        "denoise_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "reference_latents": [
          "REFERENCE_LATENT_LIST",
          {
            "tooltip": "List of reference image latents for kisekaeichi mode (up to 8)"
          }
        ],
        "reference_image_embeds": [
          "REFERENCE_EMBEDS_LIST",
          {
            "tooltip": "List of reference image CLIP embeds for kisekaeichi mode (up to 8)"
          }
        ],
        "reference_masks": [
          "REFERENCE_MASK_LIST",
          {
            "tooltip": "List of reference masks for selective features (up to 8, optional)"
          }
        ],
        "target_index": [
          "INT",
          {
            "default": 5,
            "min": 0,
            "max": 16,
            "step": 1,
            "tooltip": "Target index for kisekaeichi mode (recommended: 1)"
          }
        ],
        "control_index": [
          "STRING",
          {
            "default": "0;10",
            "tooltip": "Control indices separated by semicolon (preferred) or comma: 0;7;8;9;10 or 0,7,8,9,10 (default: 0;10)"
          }
        ],
        "input_mask": [
          "MASK",
          {
            "tooltip": "Input mask for selective application"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "positive",
        "negative",
        "start_latent",
        "steps",
        "use_teacache",
        "teacache_rel_l1_thresh",
        "cfg",
        "guidance_scale",
        "shift",
        "seed",
        "latent_window_size",
        "gpu_memory_preservation",
        "sampler"
      ],
      "optional": [
        "image_embeds",
        "initial_samples",
        "denoise_strength",
        "reference_latents",
        "reference_image_embeds",
        "reference_masks",
        "target_index",
        "control_index",
        "input_mask"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "samples"
    ],
    "name": "FramePackSingleFrameSampler",
    "display_name": "FramePack Single Frame Sampler",
    "description": "Single frame sampler with auto-enabled Kisekaeichi (style transfer) support for multiple references",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_PlusOne",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "ReferenceLatentList": {
    "input": {
      "required": {},
      "optional": {
        "reference_1": [
          "LATENT",
          {
            "tooltip": "Reference latent 1"
          }
        ],
        "reference_2": [
          "LATENT",
          {
            "tooltip": "Reference latent 2"
          }
        ],
        "reference_3": [
          "LATENT",
          {
            "tooltip": "Reference latent 3"
          }
        ],
        "reference_4": [
          "LATENT",
          {
            "tooltip": "Reference latent 4"
          }
        ],
        "reference_5": [
          "LATENT",
          {
            "tooltip": "Reference latent 5"
          }
        ],
        "reference_6": [
          "LATENT",
          {
            "tooltip": "Reference latent 6"
          }
        ],
        "reference_7": [
          "LATENT",
          {
            "tooltip": "Reference latent 7"
          }
        ],
        "reference_8": [
          "LATENT",
          {
            "tooltip": "Reference latent 8"
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "reference_1",
        "reference_2",
        "reference_3",
        "reference_4",
        "reference_5",
        "reference_6",
        "reference_7",
        "reference_8"
      ]
    },
    "output": [
      "REFERENCE_LATENT_LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "reference_latents"
    ],
    "name": "ReferenceLatentList",
    "display_name": "Reference Latent List",
    "description": "Combine up to 8 reference latents into a list for multi-reference Kisekaeichi mode",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_PlusOne",
    "category": "FramePackWrapper/References",
    "output_node": false
  },
  "ReferenceEmbedsList": {
    "input": {
      "required": {},
      "optional": {
        "embeds_1": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 1"
          }
        ],
        "embeds_2": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 2"
          }
        ],
        "embeds_3": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 3"
          }
        ],
        "embeds_4": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 4"
          }
        ],
        "embeds_5": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 5"
          }
        ],
        "embeds_6": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 6"
          }
        ],
        "embeds_7": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 7"
          }
        ],
        "embeds_8": [
          "CLIP_VISION_OUTPUT",
          {
            "tooltip": "Reference embeds 8"
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "embeds_1",
        "embeds_2",
        "embeds_3",
        "embeds_4",
        "embeds_5",
        "embeds_6",
        "embeds_7",
        "embeds_8"
      ]
    },
    "output": [
      "REFERENCE_EMBEDS_LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "reference_embeds"
    ],
    "name": "ReferenceEmbedsList",
    "display_name": "Reference Embeds List",
    "description": "Combine up to 8 reference CLIP vision embeddings into a list for multi-reference Kisekaeichi mode",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_PlusOne",
    "category": "FramePackWrapper/References",
    "output_node": false
  },
  "ReferenceMaskList": {
    "input": {
      "required": {},
      "optional": {
        "mask_1": [
          "MASK",
          {
            "tooltip": "Reference mask 1"
          }
        ],
        "mask_2": [
          "MASK",
          {
            "tooltip": "Reference mask 2"
          }
        ],
        "mask_3": [
          "MASK",
          {
            "tooltip": "Reference mask 3"
          }
        ],
        "mask_4": [
          "MASK",
          {
            "tooltip": "Reference mask 4"
          }
        ],
        "mask_5": [
          "MASK",
          {
            "tooltip": "Reference mask 5"
          }
        ],
        "mask_6": [
          "MASK",
          {
            "tooltip": "Reference mask 6"
          }
        ],
        "mask_7": [
          "MASK",
          {
            "tooltip": "Reference mask 7"
          }
        ],
        "mask_8": [
          "MASK",
          {
            "tooltip": "Reference mask 8"
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "mask_1",
        "mask_2",
        "mask_3",
        "mask_4",
        "mask_5",
        "mask_6",
        "mask_7",
        "mask_8"
      ]
    },
    "output": [
      "REFERENCE_MASK_LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "reference_masks"
    ],
    "name": "ReferenceMaskList",
    "display_name": "Reference Mask List",
    "description": "Combine up to 8 reference masks into a list for multi-reference Kisekaeichi mode (optional)",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_PlusOne",
    "category": "FramePackWrapper/References",
    "output_node": false
  },
  "FramePackSingleFrameResizeSampler": {
    "input": {
      "required": {
        "model": [
          "FramePackMODEL"
        ],
        "vae": [
          "VAE"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "input_image": [
          "IMAGE",
          {
            "tooltip": "Input image to be upscaled"
          }
        ],
        "steps": [
          "INT",
          {
            "default": 30,
            "min": 1
          }
        ],
        "use_teacache": [
          "BOOLEAN",
          {
            "default": true,
            "tooltip": "Use teacache for faster sampling."
          }
        ],
        "teacache_rel_l1_thresh": [
          "FLOAT",
          {
            "default": 0.15,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01,
            "tooltip": "The threshold for the relative L1 loss."
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 30.0,
            "step": 0.01
          }
        ],
        "guidance_scale": [
          "FLOAT",
          {
            "default": 10.0,
            "min": 0.0,
            "max": 32.0,
            "step": 0.01
          }
        ],
        "shift": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1000.0,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "latent_window_size": [
          "INT",
          {
            "default": 9,
            "min": 1,
            "max": 33,
            "step": 1,
            "tooltip": "The size of the latent window to use for sampling."
          }
        ],
        "gpu_memory_preservation": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 128.0,
            "step": 0.1,
            "tooltip": "The amount of GPU memory to preserve."
          }
        ],
        "sampler": [
          [
            "unipc_bh1",
            "unipc_bh2"
          ],
          {
            "default": "unipc_bh1"
          }
        ],
        "tile_size": [
          "INT",
          {
            "default": 256,
            "min": 256,
            "max": 1024,
            "step": 64,
            "tooltip": "Size of each tile for initial split"
          }
        ],
        "tile_resized": [
          "INT",
          {
            "default": 1024,
            "min": 512,
            "max": 2048,
            "step": 64,
            "tooltip": "Size to resize each tile to before processing"
          }
        ],
        "vae_tile_size": [
          "INT",
          {
            "default": 256,
            "min": 64,
            "max": 512,
            "step": 64,
            "tooltip": "Size of each VAE tile for decode"
          }
        ],
        "vae_overlap": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 256,
            "step": 8,
            "tooltip": "Overlap between VAE tiles"
          }
        ],
        "vae_temporal_size": [
          "INT",
          {
            "default": 64,
            "min": 1,
            "max": 128,
            "step": 1,
            "tooltip": "Temporal size for VAE tiled decode"
          }
        ],
        "vae_temporal_overlap": [
          "INT",
          {
            "default": 8,
            "min": 0,
            "max": 32,
            "step": 1,
            "tooltip": "Temporal overlap for VAE tiled decode"
          }
        ]
      },
      "optional": {
        "image_embeds": [
          "CLIP_VISION_OUTPUT"
        ],
        "denoise_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "vae",
        "positive",
        "negative",
        "input_image",
        "steps",
        "use_teacache",
        "teacache_rel_l1_thresh",
        "cfg",
        "guidance_scale",
        "shift",
        "seed",
        "latent_window_size",
        "gpu_memory_preservation",
        "sampler",
        "tile_size",
        "tile_resized",
        "vae_tile_size",
        "vae_overlap",
        "vae_temporal_size",
        "vae_temporal_overlap"
      ],
      "optional": [
        "image_embeds",
        "denoise_strength"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "upscaled_image"
    ],
    "name": "FramePackSingleFrameResizeSampler",
    "display_name": "FramePack Single Frame Resize Sampler (50% Overlap)",
    "description": "Variable ratio image upscaling using 50% overlapping tile-based FramePack single frame sampling",
    "python_module": "custom_nodes.ComfyUI-FramePackWrapper_PlusOne",
    "category": "FramePackWrapper",
    "output_node": false
  },
  "BLIP Model Loader": {
    "input": {
      "required": {
        "blip_model": [
          "STRING",
          {
            "default": "Salesforce/blip-image-captioning-base"
          }
        ],
        "vqa_model_id": [
          "STRING",
          {
            "default": "Salesforce/blip-vqa-base"
          }
        ],
        "device": [
          [
            "cuda",
            "cpu"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "blip_model",
        "vqa_model_id",
        "device"
      ]
    },
    "output": [
      "BLIP_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BLIP_MODEL"
    ],
    "name": "BLIP Model Loader",
    "display_name": "BLIP Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "Blend Latents": {
    "input": {
      "required": {
        "latent_a": [
          "LATENT"
        ],
        "latent_b": [
          "LATENT"
        ],
        "operation": [
          [
            "add",
            "multiply",
            "divide",
            "subtract",
            "overlay",
            "hard_light",
            "soft_light",
            "screen",
            "linear_dodge",
            "difference",
            "exclusion",
            "random"
          ]
        ],
        "blend": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent_a",
        "latent_b",
        "operation",
        "blend"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "Blend Latents",
    "display_name": "Blend Latents",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Latent",
    "output_node": false
  },
  "Bus Node": {
    "input": {
      "required": {},
      "optional": {
        "bus": [
          "BUS"
        ],
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "vae": [
          "VAE"
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "bus",
        "model",
        "clip",
        "vae",
        "positive",
        "negative"
      ]
    },
    "output": [
      "BUS",
      "MODEL",
      "CLIP",
      "VAE",
      "CONDITIONING",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "bus",
      "model",
      "clip",
      "vae",
      "positive",
      "negative"
    ],
    "name": "Bus Node",
    "display_name": "Bus Node",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Utilities",
    "output_node": false
  },
  "Cache Node": {
    "input": {
      "required": {
        "latent_suffix": [
          "STRING",
          {
            "default": "11712784_cache",
            "multiline": false
          }
        ],
        "image_suffix": [
          "STRING",
          {
            "default": "72829618_cache",
            "multiline": false
          }
        ],
        "conditioning_suffix": [
          "STRING",
          {
            "default": "66706038_cache",
            "multiline": false
          }
        ]
      },
      "optional": {
        "output_path": [
          "STRING",
          {
            "default": "/workspace/ComfyUI/custom_nodes/was-ns/cache",
            "multiline": false
          }
        ],
        "latent": [
          "LATENT"
        ],
        "image": [
          "IMAGE"
        ],
        "conditioning": [
          "CONDITIONING"
        ]
      }
    },
    "input_order": {
      "required": [
        "latent_suffix",
        "image_suffix",
        "conditioning_suffix"
      ],
      "optional": [
        "output_path",
        "latent",
        "image",
        "conditioning"
      ]
    },
    "output": [
      "STRING",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "latent_filename",
      "image_filename",
      "conditioning_filename"
    ],
    "name": "Cache Node",
    "display_name": "Cache Node",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": true
  },
  "Checkpoint Loader": {
    "input": {
      "required": {
        "config_name": [
          [
            "anything_v3.yaml",
            "v1-inference.yaml",
            "v1-inference_clip_skip_2.yaml",
            "v1-inference_clip_skip_2_fp16.yaml",
            "v1-inference_fp16.yaml",
            "v1-inpainting-inference.yaml",
            "v2-inference-v.yaml",
            "v2-inference-v_fp32.yaml",
            "v2-inference.yaml",
            "v2-inference_fp32.yaml",
            "v2-inpainting-inference.yaml"
          ]
        ],
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "config_name",
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "NAME_STRING"
    ],
    "name": "Checkpoint Loader",
    "display_name": "Checkpoint Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders/Advanced",
    "output_node": false
  },
  "Checkpoint Loader (Simple)": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "NAME_STRING"
    ],
    "name": "Checkpoint Loader (Simple)",
    "display_name": "Checkpoint Loader (Simple)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "CLIPTextEncode (NSP)": {
    "input": {
      "required": {
        "mode": [
          [
            "Noodle Soup Prompts",
            "Wildcards"
          ]
        ],
        "noodle_key": [
          "STRING",
          {
            "default": "__",
            "multiline": false
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "text": [
          "STRING",
          {
            "multiline": true
          }
        ],
        "clip": [
          "CLIP"
        ]
      }
    },
    "input_order": {
      "required": [
        "mode",
        "noodle_key",
        "seed",
        "text",
        "clip"
      ]
    },
    "output": [
      "CONDITIONING",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "conditioning",
      "parsed_text",
      "raw_text"
    ],
    "name": "CLIPTextEncode (NSP)",
    "display_name": "CLIPTextEncode (NSP)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Conditioning",
    "output_node": true
  },
  "CLIP Input Switch": {
    "input": {
      "required": {
        "clip_a": [
          "CLIP"
        ],
        "clip_b": [
          "CLIP"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_a",
        "clip_b",
        "boolean"
      ]
    },
    "output": [
      "CLIP"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP"
    ],
    "name": "CLIP Input Switch",
    "display_name": "CLIP Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "CLIP Vision Input Switch": {
    "input": {
      "required": {
        "clip_vision_a": [
          "CLIP_VISION"
        ],
        "clip_vision_b": [
          "CLIP_VISION"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip_vision_a",
        "clip_vision_b",
        "boolean"
      ]
    },
    "output": [
      "CLIP_VISION"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CLIP_VISION"
    ],
    "name": "CLIP Vision Input Switch",
    "display_name": "CLIP Vision Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Conditioning Input Switch": {
    "input": {
      "required": {
        "conditioning_a": [
          "CONDITIONING"
        ],
        "conditioning_b": [
          "CONDITIONING"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "conditioning_a",
        "conditioning_b",
        "boolean"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "Conditioning Input Switch",
    "display_name": "Conditioning Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Constant Number": {
    "input": {
      "required": {
        "number_type": [
          [
            "integer",
            "float",
            "bool"
          ]
        ],
        "number": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "number_as_text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "number_type",
        "number"
      ],
      "optional": [
        "number_as_text"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Constant Number",
    "display_name": "Constant Number",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "Create Grid Image": {
    "input": {
      "required": {
        "images_path": [
          "STRING",
          {
            "default": "./ComfyUI/input/",
            "multiline": false
          }
        ],
        "pattern_glob": [
          "STRING",
          {
            "default": "*",
            "multiline": false
          }
        ],
        "include_subfolders": [
          [
            "false",
            "true"
          ]
        ],
        "border_width": [
          "INT",
          {
            "default": 3,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "number_of_columns": [
          "INT",
          {
            "default": 6,
            "min": 1,
            "max": 24,
            "step": 1
          }
        ],
        "max_cell_size": [
          "INT",
          {
            "default": 256,
            "min": 32,
            "max": 1280,
            "step": 1
          }
        ],
        "border_red": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "border_green": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "border_blue": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images_path",
        "pattern_glob",
        "include_subfolders",
        "border_width",
        "number_of_columns",
        "max_cell_size",
        "border_red",
        "border_green",
        "border_blue"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Create Grid Image",
    "display_name": "Create Grid Image",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Create Grid Image from Batch": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "border_width": [
          "INT",
          {
            "default": 3,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "number_of_columns": [
          "INT",
          {
            "default": 6,
            "min": 1,
            "max": 24,
            "step": 1
          }
        ],
        "max_cell_size": [
          "INT",
          {
            "default": 256,
            "min": 32,
            "max": 2048,
            "step": 1
          }
        ],
        "border_red": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "border_green": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "border_blue": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "border_width",
        "number_of_columns",
        "max_cell_size",
        "border_red",
        "border_green",
        "border_blue"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Create Grid Image from Batch",
    "display_name": "Create Grid Image from Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Create Morph Image": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "transition_frames": [
          "INT",
          {
            "default": 30,
            "min": 2,
            "max": 60,
            "step": 1
          }
        ],
        "still_image_delay_ms": [
          "FLOAT",
          {
            "default": 2500.0,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "duration_ms": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "loops": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "max_size": [
          "INT",
          {
            "default": 512,
            "min": 128,
            "max": 1280,
            "step": 1
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/output",
            "multiline": false
          }
        ],
        "filename": [
          "STRING",
          {
            "default": "morph",
            "multiline": false
          }
        ],
        "filetype": [
          [
            "GIF",
            "APNG"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "transition_frames",
        "still_image_delay_ms",
        "duration_ms",
        "loops",
        "max_size",
        "output_path",
        "filename",
        "filetype"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "image_a_pass",
      "image_b_pass",
      "filepath_text",
      "filename_text"
    ],
    "name": "Create Morph Image",
    "display_name": "Create Morph Image",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation",
    "output_node": false
  },
  "Create Morph Image from Path": {
    "input": {
      "required": {
        "transition_frames": [
          "INT",
          {
            "default": 30,
            "min": 2,
            "max": 60,
            "step": 1
          }
        ],
        "still_image_delay_ms": [
          "FLOAT",
          {
            "default": 2500.0,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "duration_ms": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "loops": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "max_size": [
          "INT",
          {
            "default": 512,
            "min": 128,
            "max": 1280,
            "step": 1
          }
        ],
        "input_path": [
          "STRING",
          {
            "default": "./ComfyUI",
            "multiline": false
          }
        ],
        "input_pattern": [
          "STRING",
          {
            "default": "*",
            "multiline": false
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/output",
            "multiline": false
          }
        ],
        "filename": [
          "STRING",
          {
            "default": "morph",
            "multiline": false
          }
        ],
        "filetype": [
          [
            "GIF",
            "APNG"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "transition_frames",
        "still_image_delay_ms",
        "duration_ms",
        "loops",
        "max_size",
        "input_path",
        "input_pattern",
        "output_path",
        "filename",
        "filetype"
      ]
    },
    "output": [
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "filepath_text",
      "filename_text"
    ],
    "name": "Create Morph Image from Path",
    "display_name": "Create Morph Image from Path",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation",
    "output_node": false
  },
  "Create Video from Path": {
    "input": {
      "required": {
        "transition_frames": [
          "INT",
          {
            "default": 30,
            "min": 0,
            "max": 120,
            "step": 1
          }
        ],
        "image_delay_sec": [
          "FLOAT",
          {
            "default": 2.5,
            "min": 0.01,
            "max": 60000.0,
            "step": 0.01
          }
        ],
        "fps": [
          "INT",
          {
            "default": 30,
            "min": 1,
            "max": 60.0,
            "step": 1
          }
        ],
        "max_size": [
          "INT",
          {
            "default": 512,
            "min": 128,
            "max": 1920,
            "step": 1
          }
        ],
        "input_path": [
          "STRING",
          {
            "default": "./ComfyUI/input",
            "multiline": false
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/output",
            "multiline": false
          }
        ],
        "filename": [
          "STRING",
          {
            "default": "comfy_video",
            "multiline": false
          }
        ],
        "codec": [
          [
            "AVC1",
            "FFV1",
            "H264",
            "MP4V"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "transition_frames",
        "image_delay_sec",
        "fps",
        "max_size",
        "input_path",
        "output_path",
        "filename",
        "codec"
      ]
    },
    "output": [
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "filepath_text",
      "filename_text"
    ],
    "name": "Create Video from Path",
    "display_name": "Create Video from Path",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation",
    "output_node": false
  },
  "CLIPSeg Masking": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "clipseg_model": [
          "CLIPSEG_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "text"
      ],
      "optional": [
        "clipseg_model"
      ]
    },
    "output": [
      "MASK",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MASK",
      "MASK_IMAGE"
    ],
    "name": "CLIPSeg Masking",
    "display_name": "CLIPSeg Masking",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "CLIPSeg Model Loader": {
    "input": {
      "required": {
        "model": [
          "STRING",
          {
            "default": "CIDAS/clipseg-rd64-refined",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model"
      ]
    },
    "output": [
      "CLIPSEG_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "clipseg_model"
    ],
    "name": "CLIPSeg Model Loader",
    "display_name": "CLIPSeg Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "CLIPSeg Batch Masking": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "text_a": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_b": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "image_c": [
          "IMAGE"
        ],
        "image_d": [
          "IMAGE"
        ],
        "image_e": [
          "IMAGE"
        ],
        "image_f": [
          "IMAGE"
        ],
        "text_c": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_d": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_e": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_f": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "text_a",
        "text_b"
      ],
      "optional": [
        "image_c",
        "image_d",
        "image_e",
        "image_f",
        "text_c",
        "text_d",
        "text_e",
        "text_f"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGES_BATCH",
      "MASKS_BATCH",
      "MASK_IMAGES_BATCH"
    ],
    "name": "CLIPSeg Batch Masking",
    "display_name": "CLIPSeg Batch Masking",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Convert Masks to Images": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGES"
    ],
    "name": "Convert Masks to Images",
    "display_name": "Convert Masks to Images",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Control Net Model Input Switch": {
    "input": {
      "required": {
        "control_net_a": [
          "CONTROL_NET"
        ],
        "control_net_b": [
          "CONTROL_NET"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "control_net_a",
        "control_net_b",
        "boolean"
      ]
    },
    "output": [
      "CONTROL_NET"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONTROL_NET"
    ],
    "name": "Control Net Model Input Switch",
    "display_name": "Control Net Model Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Debug Number to Console": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ],
        "label": [
          "STRING",
          {
            "default": "Debug to Console",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "number",
        "label"
      ]
    },
    "output": [
      "NUMBER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "NUMBER"
    ],
    "name": "Debug Number to Console",
    "display_name": "Debug Number to Console",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": true
  },
  "Dictionary to Console": {
    "input": {
      "required": {
        "dictionary": [
          "DICT"
        ],
        "label": [
          "STRING",
          {
            "default": "Dictionary Output",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "dictionary",
        "label"
      ]
    },
    "output": [
      "DICT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "DICT"
    ],
    "name": "Dictionary to Console",
    "display_name": "Dictionary to Console",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": true
  },
  "Diffusers Model Loader": {
    "input": {
      "required": {
        "model_path": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "model_path"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "NAME_STRING"
    ],
    "name": "Diffusers Model Loader",
    "display_name": "Diffusers Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders/Advanced",
    "output_node": false
  },
  "Diffusers Hub Model Down-Loader": {
    "input": {
      "required": {
        "repo_id": [
          "STRING",
          {
            "multiline": false
          }
        ],
        "revision": [
          "STRING",
          {
            "default": "None",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "repo_id",
        "revision"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "NAME_STRING"
    ],
    "name": "Diffusers Hub Model Down-Loader",
    "display_name": "Diffusers Hub Model Down-Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders/Advanced",
    "output_node": false
  },
  "Export API": {
    "input": {
      "required": {
        "save_prompt_api": [
          [
            "true",
            "false"
          ]
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/output/",
            "multiline": false
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI_Prompt"
          }
        ],
        "filename_delimiter": [
          "STRING",
          {
            "default": "_"
          }
        ],
        "filename_number_padding": [
          "INT",
          {
            "default": 4,
            "min": 2,
            "max": 9,
            "step": 1
          }
        ],
        "parse_text_tokens": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "hidden": {
        "prompt": "PROMPT"
      }
    },
    "input_order": {
      "required": [
        "save_prompt_api",
        "output_path",
        "filename_prefix",
        "filename_delimiter",
        "filename_number_padding",
        "parse_text_tokens"
      ],
      "hidden": [
        "prompt"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Export API",
    "display_name": "Export API",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": true
  },
  "Latent Input Switch": {
    "input": {
      "required": {
        "latent_a": [
          "LATENT"
        ],
        "latent_b": [
          "LATENT"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent_a",
        "latent_b",
        "boolean"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "Latent Input Switch",
    "display_name": "Latent Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Load Cache": {
    "input": {
      "required": {
        "latent_path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "image_path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "conditioning_path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "latent_path",
        "image_path",
        "conditioning_path"
      ]
    },
    "output": [
      "LATENT",
      "IMAGE",
      "CONDITIONING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "LATENT",
      "IMAGE",
      "CONDITIONING"
    ],
    "name": "Load Cache",
    "display_name": "Load Cache",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": false
  },
  "Logic Boolean": {
    "input": {
      "required": {
        "boolean": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean"
      ]
    },
    "output": [
      "BOOLEAN",
      "NUMBER",
      "INT",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "BOOLEAN",
      "NUMBER",
      "INT",
      "FLOAT"
    ],
    "name": "Logic Boolean",
    "display_name": "Logic Boolean",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Logic Boolean Primitive": {
    "input": {
      "required": {
        "boolean": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Logic Boolean Primitive",
    "display_name": "Logic Boolean Primitive",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Logic Comparison OR": {
    "input": {
      "required": {
        "boolean_a": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "boolean_b": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean_a",
        "boolean_b"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Logic Comparison OR",
    "display_name": "Logic Comparison OR",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Logic Comparison AND": {
    "input": {
      "required": {
        "boolean_a": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "boolean_b": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean_a",
        "boolean_b"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Logic Comparison AND",
    "display_name": "Logic Comparison AND",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Logic Comparison XOR": {
    "input": {
      "required": {
        "boolean_a": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "boolean_b": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean_a",
        "boolean_b"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Logic Comparison XOR",
    "display_name": "Logic Comparison XOR",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Logic NOT": {
    "input": {
      "required": {
        "boolean": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Logic NOT",
    "display_name": "Logic NOT",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Lora Loader": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "lora_name": [
          [
            "None"
          ]
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "strength_clip": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip",
        "lora_name",
        "strength_model",
        "strength_clip"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "NAME_STRING"
    ],
    "name": "Lora Loader",
    "display_name": "Lora Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "Hex to HSL": {
    "input": {
      "required": {
        "hex_color": [
          "STRING",
          {
            "default": "#FF0000"
          }
        ]
      },
      "optional": {
        "include_alpha": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "hex_color"
      ],
      "optional": [
        "include_alpha"
      ]
    },
    "output": [
      "INT",
      "INT",
      "INT",
      "FLOAT",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "hue",
      "saturation",
      "lightness",
      "alpha",
      "hsl"
    ],
    "name": "Hex to HSL",
    "display_name": "Hex to HSL",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Utilities",
    "output_node": false
  },
  "HSL to Hex": {
    "input": {
      "required": {
        "hsl_color": [
          "STRING",
          {
            "default": "hsl(0, 100%, 50%)"
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "hsl_color"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "hex_color"
    ],
    "name": "HSL to Hex",
    "display_name": "HSL to Hex",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Utilities",
    "output_node": false
  },
  "Image SSAO (Ambient Occlusion)": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "depth_images": [
          "IMAGE"
        ],
        "strength": [
          "FLOAT",
          {
            "min": 0.0,
            "max": 5.0,
            "default": 1.0,
            "step": 0.01
          }
        ],
        "radius": [
          "FLOAT",
          {
            "min": 0.01,
            "max": 1024,
            "default": 30,
            "step": 0.01
          }
        ],
        "ao_blur": [
          "FLOAT",
          {
            "min": 0.01,
            "max": 1024,
            "default": 2.5,
            "step": 0.01
          }
        ],
        "specular_threshold": [
          "INT",
          {
            "min": 0,
            "max": 255,
            "default": 25,
            "step": 1
          }
        ],
        "enable_specular_masking": [
          [
            "True",
            "False"
          ]
        ],
        "tile_size": [
          "INT",
          {
            "min": 1,
            "max": 512,
            "default": 1,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "depth_images",
        "strength",
        "radius",
        "ao_blur",
        "specular_threshold",
        "enable_specular_masking",
        "tile_size"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "composited_images",
      "ssao_images",
      "specular_mask_images"
    ],
    "name": "Image SSAO (Ambient Occlusion)",
    "display_name": "Image SSAO (Ambient Occlusion)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image SSDO (Direct Occlusion)": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "depth_images": [
          "IMAGE"
        ],
        "strength": [
          "FLOAT",
          {
            "min": 0.0,
            "max": 5.0,
            "default": 1.0,
            "step": 0.01
          }
        ],
        "radius": [
          "FLOAT",
          {
            "min": 0.01,
            "max": 1024,
            "default": 30,
            "step": 0.01
          }
        ],
        "specular_threshold": [
          "INT",
          {
            "min": 0,
            "max": 255,
            "default": 128,
            "step": 1
          }
        ],
        "colored_occlusion": [
          [
            "True",
            "False"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "depth_images",
        "strength",
        "radius",
        "specular_threshold",
        "colored_occlusion"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE",
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "composited_images",
      "ssdo_images",
      "ssdo_image_masks",
      "light_source_image_masks"
    ],
    "name": "Image SSDO (Direct Occlusion)",
    "display_name": "Image SSDO (Direct Occlusion)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Analyze": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mode": [
          [
            "Black White Levels",
            "RGB Levels"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mode"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Analyze",
    "display_name": "Image Analyze",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Analyze",
    "output_node": false
  },
  "Image Aspect Ratio": {
    "input": {
      "required": {},
      "optional": {
        "image": [
          "IMAGE"
        ],
        "width": [
          "NUMBER"
        ],
        "height": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "image",
        "width",
        "height"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "NUMBER",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "aspect_number",
      "aspect_float",
      "is_landscape_bool",
      "aspect_ratio_common",
      "aspect_type"
    ],
    "name": "Image Aspect Ratio",
    "display_name": "Image Aspect Ratio",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Image Batch": {
    "input": {
      "required": {},
      "optional": {
        "images_a": [
          "IMAGE"
        ],
        "images_b": [
          "IMAGE"
        ],
        "images_c": [
          "IMAGE"
        ],
        "images_d": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "images_a",
        "images_b",
        "images_c",
        "images_d"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Batch",
    "display_name": "Image Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Image Blank": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 4096,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 4096,
            "step": 1
          }
        ],
        "red": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "green": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "blue": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "red",
        "green",
        "blue"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Blank",
    "display_name": "Image Blank",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Image Blend by Mask": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "mask": [
          "IMAGE"
        ],
        "blend_percentage": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "mask",
        "blend_percentage"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Blend by Mask",
    "display_name": "Image Blend by Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Image Blend": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "blend_percentage": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "blend_percentage"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Blend",
    "display_name": "Image Blend",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Image Blending Mode": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "mode": [
          [
            "add",
            "color",
            "color_burn",
            "color_dodge",
            "darken",
            "difference",
            "exclusion",
            "hard_light",
            "hue",
            "lighten",
            "multiply",
            "overlay",
            "screen",
            "soft_light"
          ]
        ],
        "blend_percentage": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "mode",
        "blend_percentage"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Blending Mode",
    "display_name": "Image Blending Mode",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Image Bloom Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "radius": [
          "FLOAT",
          {
            "default": 10,
            "min": 0.0,
            "max": 1024,
            "step": 0.1
          }
        ],
        "intensity": [
          "FLOAT",
          {
            "default": 1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "radius",
        "intensity"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Bloom Filter",
    "display_name": "Image Bloom Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Canny Filter": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "enable_threshold": [
          [
            "false",
            "true"
          ]
        ],
        "threshold_low": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "threshold_high": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "enable_threshold",
        "threshold_low",
        "threshold_high"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Canny Filter",
    "display_name": "Image Canny Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Chromatic Aberration": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "red_offset": [
          "INT",
          {
            "default": 2,
            "min": -255,
            "max": 255,
            "step": 1
          }
        ],
        "green_offset": [
          "INT",
          {
            "default": -1,
            "min": -255,
            "max": 255,
            "step": 1
          }
        ],
        "blue_offset": [
          "INT",
          {
            "default": 1,
            "min": -255,
            "max": 255,
            "step": 1
          }
        ],
        "intensity": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "fade_radius": [
          "INT",
          {
            "default": 12,
            "min": 0,
            "max": 1024,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "red_offset",
        "green_offset",
        "blue_offset",
        "intensity",
        "fade_radius"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Chromatic Aberration",
    "display_name": "Image Chromatic Aberration",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Color Palette": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "colors": [
          "INT",
          {
            "default": 16,
            "min": 8,
            "max": 256,
            "step": 1
          }
        ],
        "mode": [
          [
            "Chart",
            "back_to_back"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "colors",
        "mode"
      ]
    },
    "output": [
      "IMAGE",
      "LIST"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "image",
      "color_palettes"
    ],
    "name": "Image Color Palette",
    "display_name": "Image Color Palette",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Analyze",
    "output_node": false
  },
  "Image Crop Face": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "crop_padding_factor": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 2.0,
            "step": 0.01
          }
        ],
        "cascade_xml": [
          [
            "lbpcascade_animeface.xml",
            "haarcascade_frontalface_default.xml",
            "haarcascade_frontalface_alt.xml",
            "haarcascade_frontalface_alt2.xml",
            "haarcascade_frontalface_alt_tree.xml",
            "haarcascade_profileface.xml",
            "haarcascade_upperbody.xml",
            "haarcascade_eye.xml"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "crop_padding_factor",
        "cascade_xml"
      ]
    },
    "output": [
      "IMAGE",
      "CROP_DATA"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "CROP_DATA"
    ],
    "name": "Image Crop Face",
    "display_name": "Image Crop Face",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Crop Location": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "top": [
          "INT",
          {
            "default": 0,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "left": [
          "INT",
          {
            "default": 0,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "right": [
          "INT",
          {
            "default": 256,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "bottom": [
          "INT",
          {
            "default": 256,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "top",
        "left",
        "right",
        "bottom"
      ]
    },
    "output": [
      "IMAGE",
      "CROP_DATA"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "CROP_DATA"
    ],
    "name": "Image Crop Location",
    "display_name": "Image Crop Location",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Crop Square Location": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "x": [
          "INT",
          {
            "default": 0,
            "max": 24576,
            "min": 0,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "max": 24576,
            "min": 0,
            "step": 1
          }
        ],
        "size": [
          "INT",
          {
            "default": 256,
            "max": 4096,
            "min": 5,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "x",
        "y",
        "size"
      ]
    },
    "output": [
      "IMAGE",
      "CROP_DATA"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "CROP_DATA"
    ],
    "name": "Image Crop Square Location",
    "display_name": "Image Crop Square Location",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Displacement Warp": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "displacement_maps": [
          "IMAGE"
        ],
        "amplitude": [
          "FLOAT",
          {
            "default": 25.0,
            "min": -4096,
            "max": 4096,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "displacement_maps",
        "amplitude"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Displacement Warp",
    "display_name": "Image Displacement Warp",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Lucy Sharpen": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "iterations": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 12,
            "step": 1
          }
        ],
        "kernel_size": [
          "INT",
          {
            "default": 3,
            "min": 1,
            "max": 16,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "iterations",
        "kernel_size"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Lucy Sharpen",
    "display_name": "Image Lucy Sharpen",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Paste Face": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "crop_image": [
          "IMAGE"
        ],
        "crop_data": [
          "CROP_DATA"
        ],
        "crop_blending": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "crop_sharpening": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 3,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "crop_image",
        "crop_data",
        "crop_blending",
        "crop_sharpening"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK_IMAGE"
    ],
    "name": "Image Paste Face",
    "display_name": "Image Paste Face",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Paste Crop": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "crop_image": [
          "IMAGE"
        ],
        "crop_data": [
          "CROP_DATA"
        ],
        "crop_blending": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "crop_sharpening": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 3,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "crop_image",
        "crop_data",
        "crop_blending",
        "crop_sharpening"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "Image Paste Crop",
    "display_name": "Image Paste Crop",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Paste Crop by Location": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "crop_image": [
          "IMAGE"
        ],
        "top": [
          "INT",
          {
            "default": 0,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "left": [
          "INT",
          {
            "default": 0,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "right": [
          "INT",
          {
            "default": 256,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "bottom": [
          "INT",
          {
            "default": 256,
            "max": 10000000,
            "min": 0,
            "step": 1
          }
        ],
        "crop_blending": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "crop_sharpening": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 3,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "crop_image",
        "top",
        "left",
        "right",
        "bottom",
        "crop_blending",
        "crop_sharpening"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "Image Paste Crop by Location",
    "display_name": "Image Paste Crop by Location",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Pixelate": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "pixelation_size": [
          "FLOAT",
          {
            "default": 164,
            "min": 16,
            "max": 480,
            "step": 1
          }
        ],
        "num_colors": [
          "FLOAT",
          {
            "default": 16,
            "min": 2,
            "max": 256,
            "step": 1
          }
        ],
        "init_mode": [
          [
            "k-means++",
            "random",
            "none"
          ]
        ],
        "max_iterations": [
          "FLOAT",
          {
            "default": 100,
            "min": 1,
            "max": 256,
            "step": 1
          }
        ],
        "dither": [
          [
            "False",
            "True"
          ]
        ],
        "dither_mode": [
          [
            "FloydSteinberg",
            "Ordered"
          ]
        ]
      },
      "optional": {
        "color_palettes": [
          "LIST",
          {
            "forceInput": true
          }
        ],
        "color_palette_mode": [
          [
            "Brightness",
            "BrightnessAndTonal",
            "Linear",
            "Tonal"
          ]
        ],
        "reverse_palette": [
          [
            "False",
            "True"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "pixelation_size",
        "num_colors",
        "init_mode",
        "max_iterations",
        "dither",
        "dither_mode"
      ],
      "optional": [
        "color_palettes",
        "color_palette_mode",
        "reverse_palette"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Pixelate",
    "display_name": "Image Pixelate",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Power Noise": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "frequency": [
          "FLOAT",
          {
            "default": 0.5,
            "max": 10.0,
            "min": 0.0,
            "step": 0.01
          }
        ],
        "attenuation": [
          "FLOAT",
          {
            "default": 0.5,
            "max": 10.0,
            "min": 0.0,
            "step": 0.01
          }
        ],
        "noise_type": [
          [
            "grey",
            "white",
            "pink",
            "blue",
            "green",
            "mix"
          ]
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "frequency",
        "attenuation",
        "noise_type",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Power Noise",
    "display_name": "Image Power Noise",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate/Noise",
    "output_node": false
  },
  "Image Dragan Photography Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "saturation": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 16.0,
            "step": 0.01
          }
        ],
        "contrast": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 16.0,
            "step": 0.01
          }
        ],
        "brightness": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 16.0,
            "step": 0.01
          }
        ],
        "sharpness": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 6.0,
            "step": 0.01
          }
        ],
        "highpass_radius": [
          "FLOAT",
          {
            "default": 6.0,
            "min": 0.0,
            "max": 255.0,
            "step": 0.01
          }
        ],
        "highpass_samples": [
          "INT",
          {
            "default": 1,
            "min": 0,
            "max": 6.0,
            "step": 1
          }
        ],
        "highpass_strength": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 3.0,
            "step": 0.01
          }
        ],
        "colorize": [
          [
            "true",
            "false"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "saturation",
        "contrast",
        "brightness",
        "sharpness",
        "highpass_radius",
        "highpass_samples",
        "highpass_strength",
        "colorize"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Dragan Photography Filter",
    "display_name": "Image Dragan Photography Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Edge Detection Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mode": [
          [
            "normal",
            "laplacian"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mode"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Edge Detection Filter",
    "display_name": "Image Edge Detection Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Film Grain": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "density": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "intensity": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "highlights": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.01,
            "max": 255.0,
            "step": 0.01
          }
        ],
        "supersample_factor": [
          "INT",
          {
            "default": 4,
            "min": 1,
            "max": 8,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "density",
        "intensity",
        "highlights",
        "supersample_factor"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Film Grain",
    "display_name": "Image Film Grain",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Filter Adjustments": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "brightness": [
          "FLOAT",
          {
            "default": 0.0,
            "min": -1.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "contrast": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -1.0,
            "max": 2.0,
            "step": 0.01
          }
        ],
        "saturation": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "sharpness": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -5.0,
            "max": 5.0,
            "step": 0.01
          }
        ],
        "blur": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 16,
            "step": 1
          }
        ],
        "gaussian_blur": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1024.0,
            "step": 0.1
          }
        ],
        "edge_enhance": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "detail_enhance": [
          [
            "false",
            "true"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "brightness",
        "contrast",
        "saturation",
        "sharpness",
        "blur",
        "gaussian_blur",
        "edge_enhance",
        "detail_enhance"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Filter Adjustments",
    "display_name": "Image Filter Adjustments",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Flip": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "mode": [
          [
            "horizontal",
            "vertical"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "mode"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Flip",
    "display_name": "Image Flip",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Gradient Map": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "gradient_image": [
          "IMAGE"
        ],
        "flip_left_right": [
          [
            "false",
            "true"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "gradient_image",
        "flip_left_right"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Gradient Map",
    "display_name": "Image Gradient Map",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Generate Gradient": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "direction": [
          [
            "horizontal",
            "vertical"
          ]
        ],
        "tolerance": [
          "INT",
          {
            "default": 0,
            "max": 255,
            "min": 0,
            "step": 1
          }
        ],
        "gradient_stops": [
          "STRING",
          {
            "default": "0:255,0,0\n25:255,255,255\n50:0,255,0\n75:0,0,255",
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "direction",
        "tolerance",
        "gradient_stops"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Generate Gradient",
    "display_name": "Image Generate Gradient",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate",
    "output_node": false
  },
  "Image High Pass Filter": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "radius": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 500,
            "step": 1
          }
        ],
        "strength": [
          "FLOAT",
          {
            "default": 1.5,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "color_output": [
          [
            "true",
            "false"
          ]
        ],
        "neutral_background": [
          [
            "true",
            "false"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "radius",
        "strength",
        "color_output",
        "neutral_background"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image High Pass Filter",
    "display_name": "Image High Pass Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image History Loader": {
    "input": {
      "required": {
        "image": [
          [
            "No History"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "image",
      "filename_text"
    ],
    "name": "Image History Loader",
    "display_name": "Image History Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/History",
    "output_node": false
  },
  "Image Input Switch": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "boolean"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Input Switch",
    "display_name": "Image Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Image Levels Adjustment": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "black_level": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "mid_level": [
          "FLOAT",
          {
            "default": 127.5,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "white_level": [
          "FLOAT",
          {
            "default": 255,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "black_level",
        "mid_level",
        "white_level"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Levels Adjustment",
    "display_name": "Image Levels Adjustment",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Adjustment",
    "output_node": false
  },
  "Image Load": {
    "input": {
      "required": {
        "image_path": [
          "STRING",
          {
            "default": "./ComfyUI/input/example.png",
            "multiline": false
          }
        ],
        "RGBA": [
          [
            "false",
            "true"
          ]
        ]
      },
      "optional": {
        "filename_text_extension": [
          [
            "true",
            "false"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image_path",
        "RGBA"
      ],
      "optional": [
        "filename_text_extension"
      ]
    },
    "output": [
      "IMAGE",
      "MASK",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "image",
      "mask",
      "filename_text"
    ],
    "name": "Image Load",
    "display_name": "Image Load",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": false
  },
  "Image Median Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "diameter": [
          "INT",
          {
            "default": 2.0,
            "min": 0.1,
            "max": 255,
            "step": 1
          }
        ],
        "sigma_color": [
          "FLOAT",
          {
            "default": 10.0,
            "min": -255.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "sigma_space": [
          "FLOAT",
          {
            "default": 10.0,
            "min": -255.0,
            "max": 255.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "diameter",
        "sigma_color",
        "sigma_space"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Median Filter",
    "display_name": "Image Median Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Mix RGB Channels": {
    "input": {
      "required": {
        "red_channel": [
          "IMAGE"
        ],
        "green_channel": [
          "IMAGE"
        ],
        "blue_channel": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "red_channel",
        "green_channel",
        "blue_channel"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Mix RGB Channels",
    "display_name": "Image Mix RGB Channels",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Monitor Effects Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mode": [
          [
            "Digital Distortion",
            "Signal Distortion",
            "TV Distortion"
          ]
        ],
        "amplitude": [
          "INT",
          {
            "default": 5,
            "min": 1,
            "max": 255,
            "step": 1
          }
        ],
        "offset": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mode",
        "amplitude",
        "offset"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Monitor Effects Filter",
    "display_name": "Image Monitor Effects Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Nova Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "amplitude": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ],
        "frequency": [
          "FLOAT",
          {
            "default": 3.14,
            "min": 0.0,
            "max": 100.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "amplitude",
        "frequency"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Nova Filter",
    "display_name": "Image Nova Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Padding": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "feathering": [
          "INT",
          {
            "default": 120,
            "min": 0,
            "max": 2048,
            "step": 1
          }
        ],
        "feather_second_pass": [
          [
            "true",
            "false"
          ]
        ],
        "left_padding": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 48000,
            "step": 1
          }
        ],
        "right_padding": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 48000,
            "step": 1
          }
        ],
        "top_padding": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 48000,
            "step": 1
          }
        ],
        "bottom_padding": [
          "INT",
          {
            "default": 512,
            "min": 8,
            "max": 48000,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "feathering",
        "feather_second_pass",
        "left_padding",
        "right_padding",
        "top_padding",
        "bottom_padding"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "Image Padding",
    "display_name": "Image Padding",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Perlin Noise": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "max": 2048,
            "min": 64,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "max": 2048,
            "min": 64,
            "step": 1
          }
        ],
        "scale": [
          "INT",
          {
            "default": 100,
            "max": 2048,
            "min": 2,
            "step": 1
          }
        ],
        "octaves": [
          "INT",
          {
            "default": 4,
            "max": 8,
            "min": 0,
            "step": 1
          }
        ],
        "persistence": [
          "FLOAT",
          {
            "default": 0.5,
            "max": 100.0,
            "min": 0.01,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "scale",
        "octaves",
        "persistence",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Perlin Noise",
    "display_name": "Image Perlin Noise",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate/Noise",
    "output_node": false
  },
  "Image Rembg (Remove Background)": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "transparency": [
          "BOOLEAN",
          {
            "default": true
          }
        ],
        "model": [
          [
            "u2net",
            "u2netp",
            "u2net_human_seg",
            "silueta",
            "isnet-general-use",
            "isnet-anime"
          ]
        ],
        "post_processing": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "only_mask": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "alpha_matting": [
          "BOOLEAN",
          {
            "default": false
          }
        ],
        "alpha_matting_foreground_threshold": [
          "INT",
          {
            "default": 240,
            "min": 0,
            "max": 255
          }
        ],
        "alpha_matting_background_threshold": [
          "INT",
          {
            "default": 10,
            "min": 0,
            "max": 255
          }
        ],
        "alpha_matting_erode_size": [
          "INT",
          {
            "default": 10,
            "min": 0,
            "max": 255
          }
        ],
        "background_color": [
          [
            "none",
            "black",
            "white",
            "magenta",
            "chroma green",
            "chroma blue"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "transparency",
        "model",
        "post_processing",
        "only_mask",
        "alpha_matting",
        "alpha_matting_foreground_threshold",
        "alpha_matting_background_threshold",
        "alpha_matting_erode_size",
        "background_color"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Rembg (Remove Background)",
    "display_name": "Image Rembg (Remove Background)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/AI",
    "output_node": false
  },
  "Image Perlin Power Fractal": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "max": 8192,
            "min": 64,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "max": 8192,
            "min": 64,
            "step": 1
          }
        ],
        "scale": [
          "INT",
          {
            "default": 100,
            "max": 2048,
            "min": 2,
            "step": 1
          }
        ],
        "octaves": [
          "INT",
          {
            "default": 4,
            "max": 8,
            "min": 0,
            "step": 1
          }
        ],
        "persistence": [
          "FLOAT",
          {
            "default": 0.5,
            "max": 100.0,
            "min": 0.01,
            "step": 0.01
          }
        ],
        "lacunarity": [
          "FLOAT",
          {
            "default": 2.0,
            "max": 100.0,
            "min": 0.01,
            "step": 0.01
          }
        ],
        "exponent": [
          "FLOAT",
          {
            "default": 2.0,
            "max": 100.0,
            "min": 0.01,
            "step": 0.01
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "scale",
        "octaves",
        "persistence",
        "lacunarity",
        "exponent",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Perlin Power Fractal",
    "display_name": "Image Perlin Power Fractal",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate/Noise",
    "output_node": false
  },
  "Image Remove Background (Alpha)": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "mode": [
          [
            "background",
            "foreground"
          ]
        ],
        "threshold": [
          "INT",
          {
            "default": 127,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "threshold_tolerance": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 24,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "mode",
        "threshold",
        "threshold_tolerance"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Remove Background (Alpha)",
    "display_name": "Image Remove Background (Alpha)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Remove Color": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "target_red": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "target_green": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "target_blue": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "replace_red": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "replace_green": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "replace_blue": [
          "INT",
          {
            "default": 255,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "clip_threshold": [
          "INT",
          {
            "default": 10,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "target_red",
        "target_green",
        "target_blue",
        "replace_red",
        "replace_green",
        "replace_blue",
        "clip_threshold"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Remove Color",
    "display_name": "Image Remove Color",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Resize": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mode": [
          [
            "rescale",
            "resize"
          ]
        ],
        "supersample": [
          [
            "true",
            "false"
          ]
        ],
        "resampling": [
          [
            "lanczos",
            "nearest",
            "bilinear",
            "bicubic"
          ]
        ],
        "rescale_factor": [
          "FLOAT",
          {
            "default": 2,
            "min": 0.01,
            "max": 16.0,
            "step": 0.01
          }
        ],
        "resize_width": [
          "INT",
          {
            "default": 1024,
            "min": 1,
            "max": 48000,
            "step": 1
          }
        ],
        "resize_height": [
          "INT",
          {
            "default": 1536,
            "min": 1,
            "max": 48000,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mode",
        "supersample",
        "resampling",
        "rescale_factor",
        "resize_width",
        "resize_height"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Resize",
    "display_name": "Image Resize",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Rotate": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "mode": [
          [
            "transpose",
            "internal"
          ]
        ],
        "rotation": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 360,
            "step": 90
          }
        ],
        "sampler": [
          [
            "nearest",
            "bilinear",
            "bicubic"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "mode",
        "rotation",
        "sampler"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Rotate",
    "display_name": "Image Rotate",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Rotate Hue": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "hue_shift": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.001
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "hue_shift"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Rotate Hue",
    "display_name": "Image Rotate Hue",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Adjustment",
    "output_node": false
  },
  "Image Send HTTP": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "url": [
          "STRING",
          {
            "default": "example.com"
          }
        ],
        "method_type": [
          [
            "post",
            "put",
            "patch"
          ],
          {
            "default": "post"
          }
        ],
        "request_field_name": [
          "STRING",
          {
            "default": "image"
          }
        ]
      },
      "optional": {
        "additional_request_headers": [
          "DICT"
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "url",
        "method_type",
        "request_field_name"
      ],
      "optional": [
        "additional_request_headers"
      ]
    },
    "output": [
      "INT",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "status_code",
      "result_text"
    ],
    "name": "Image Send HTTP",
    "display_name": "Image Send HTTP",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": true
  },
  "Image Save": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "output_path": [
          "STRING",
          {
            "default": "[time(%Y-%m-%d)]",
            "multiline": false
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI"
          }
        ],
        "filename_delimiter": [
          "STRING",
          {
            "default": "_"
          }
        ],
        "filename_number_padding": [
          "INT",
          {
            "default": 4,
            "min": 1,
            "max": 9,
            "step": 1
          }
        ],
        "filename_number_start": [
          [
            "false",
            "true"
          ]
        ],
        "extension": [
          [
            "png",
            "jpg",
            "jpeg",
            "gif",
            "tiff",
            "webp",
            "bmp"
          ]
        ],
        "dpi": [
          "INT",
          {
            "default": 300,
            "min": 1,
            "max": 2400,
            "step": 1
          }
        ],
        "quality": [
          "INT",
          {
            "default": 100,
            "min": 1,
            "max": 100,
            "step": 1
          }
        ],
        "optimize_image": [
          [
            "true",
            "false"
          ]
        ],
        "lossless_webp": [
          [
            "false",
            "true"
          ]
        ],
        "overwrite_mode": [
          [
            "false",
            "prefix_as_filename"
          ]
        ],
        "show_history": [
          [
            "false",
            "true"
          ]
        ],
        "show_history_by_prefix": [
          [
            "true",
            "false"
          ]
        ],
        "embed_workflow": [
          [
            "true",
            "false"
          ]
        ],
        "show_previews": [
          [
            "true",
            "false"
          ]
        ]
      },
      "hidden": {
        "prompt": "PROMPT",
        "extra_pnginfo": "EXTRA_PNGINFO"
      }
    },
    "input_order": {
      "required": [
        "images",
        "output_path",
        "filename_prefix",
        "filename_delimiter",
        "filename_number_padding",
        "filename_number_start",
        "extension",
        "dpi",
        "quality",
        "optimize_image",
        "lossless_webp",
        "overwrite_mode",
        "show_history",
        "show_history_by_prefix",
        "embed_workflow",
        "show_previews"
      ],
      "hidden": [
        "prompt",
        "extra_pnginfo"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "images",
      "files"
    ],
    "name": "Image Save",
    "display_name": "Image Save",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": true
  },
  "Image Seamless Texture": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "blending": [
          "FLOAT",
          {
            "default": 0.4,
            "max": 1.0,
            "min": 0.0,
            "step": 0.01
          }
        ],
        "tiled": [
          [
            "true",
            "false"
          ]
        ],
        "tiles": [
          "INT",
          {
            "default": 2,
            "max": 6,
            "min": 2,
            "step": 2
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "blending",
        "tiled",
        "tiles"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "Image Seamless Texture",
    "display_name": "Image Seamless Texture",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Select Channel": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "channel": [
          [
            "red",
            "green",
            "blue"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "channel"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Select Channel",
    "display_name": "Image Select Channel",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Select Color": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "red": [
          "INT",
          {
            "default": 255.0,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "green": [
          "INT",
          {
            "default": 255.0,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "blue": [
          "INT",
          {
            "default": 255.0,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "variance": [
          "INT",
          {
            "default": 10,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "red",
        "green",
        "blue",
        "variance"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Select Color",
    "display_name": "Image Select Color",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Shadows and Highlights": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "shadow_threshold": [
          "FLOAT",
          {
            "default": 75,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "shadow_factor": [
          "FLOAT",
          {
            "default": 1.5,
            "min": -12.0,
            "max": 12.0,
            "step": 0.1
          }
        ],
        "shadow_smoothing": [
          "FLOAT",
          {
            "default": 0.25,
            "min": -255.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "highlight_threshold": [
          "FLOAT",
          {
            "default": 175,
            "min": 0.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "highlight_factor": [
          "FLOAT",
          {
            "default": 0.5,
            "min": -12.0,
            "max": 12.0,
            "step": 0.1
          }
        ],
        "highlight_smoothing": [
          "FLOAT",
          {
            "default": 0.25,
            "min": -255.0,
            "max": 255.0,
            "step": 0.1
          }
        ],
        "simplify_isolation": [
          "FLOAT",
          {
            "default": 0,
            "min": -255.0,
            "max": 255.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "shadow_threshold",
        "shadow_factor",
        "shadow_smoothing",
        "highlight_threshold",
        "highlight_factor",
        "highlight_smoothing",
        "simplify_isolation"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "image",
      "shadow_map",
      "highlight_map"
    ],
    "name": "Image Shadows and Highlights",
    "display_name": "Image Shadows and Highlights",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Adjustment",
    "output_node": false
  },
  "Image Size to Number": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "NUMBER",
      "NUMBER",
      "FLOAT",
      "FLOAT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "width_num",
      "height_num",
      "width_float",
      "height_float",
      "width_int",
      "height_int"
    ],
    "name": "Image Size to Number",
    "display_name": "Image Size to Number",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Image Stitch": {
    "input": {
      "required": {
        "image_a": [
          "IMAGE"
        ],
        "image_b": [
          "IMAGE"
        ],
        "stitch": [
          [
            "top",
            "left",
            "bottom",
            "right"
          ]
        ],
        "feathering": [
          "INT",
          {
            "default": 50,
            "min": 0,
            "max": 2048,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_a",
        "image_b",
        "stitch",
        "feathering"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Stitch",
    "display_name": "Image Stitch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image Style Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "style": [
          [
            "1977",
            "aden",
            "brannan",
            "brooklyn",
            "clarendon",
            "earlybird",
            "fairy tale",
            "gingham",
            "hudson",
            "inkwell",
            "kelvin",
            "lark",
            "lofi",
            "maven",
            "mayfair",
            "moon",
            "nashville",
            "perpetua",
            "reyes",
            "rise",
            "slumber",
            "stinson",
            "toaster",
            "valencia",
            "walden",
            "willow",
            "xpro2"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "style"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Style Filter",
    "display_name": "Image Style Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image Threshold": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "threshold": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "threshold"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Threshold",
    "display_name": "Image Threshold",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Tiled": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "num_tiles": [
          "INT",
          {
            "default": 4,
            "max": 64,
            "min": 2,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "num_tiles"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGES"
    ],
    "name": "Image Tiled",
    "display_name": "Image Tiled",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Process",
    "output_node": false
  },
  "Image Transpose": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "image_overlay": [
          "IMAGE"
        ],
        "width": [
          "INT",
          {
            "default": 512,
            "min": -48000,
            "max": 48000,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "min": -48000,
            "max": 48000,
            "step": 1
          }
        ],
        "X": [
          "INT",
          {
            "default": 0,
            "min": -48000,
            "max": 48000,
            "step": 1
          }
        ],
        "Y": [
          "INT",
          {
            "default": 0,
            "min": -48000,
            "max": 48000,
            "step": 1
          }
        ],
        "rotation": [
          "INT",
          {
            "default": 0,
            "min": -360,
            "max": 360,
            "step": 1
          }
        ],
        "feathering": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "image_overlay",
        "width",
        "height",
        "X",
        "Y",
        "rotation",
        "feathering"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image Transpose",
    "display_name": "Image Transpose",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Transform",
    "output_node": false
  },
  "Image fDOF Filter": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "depth": [
          "IMAGE"
        ],
        "mode": [
          [
            "mock",
            "gaussian",
            "box"
          ]
        ],
        "radius": [
          "INT",
          {
            "default": 8,
            "min": 1,
            "max": 128,
            "step": 1
          }
        ],
        "samples": [
          "INT",
          {
            "default": 1,
            "min": 1,
            "max": 3,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "depth",
        "mode",
        "radius",
        "samples"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Image fDOF Filter",
    "display_name": "Image fDOF Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Filter",
    "output_node": false
  },
  "Image to Latent Mask": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "channel": [
          [
            "alpha",
            "red",
            "green",
            "blue"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "channel"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Image to Latent Mask",
    "display_name": "Image to Latent Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Image to Noise": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "num_colors": [
          "INT",
          {
            "default": 16,
            "max": 256,
            "min": 2,
            "step": 2
          }
        ],
        "black_mix": [
          "INT",
          {
            "default": 0,
            "max": 20,
            "min": 0,
            "step": 1
          }
        ],
        "gaussian_mix": [
          "FLOAT",
          {
            "default": 0.0,
            "max": 1024,
            "min": 0,
            "step": 0.1
          }
        ],
        "brightness": [
          "FLOAT",
          {
            "default": 1.0,
            "max": 2.0,
            "min": 0.0,
            "step": 0.01
          }
        ],
        "output_mode": [
          [
            "batch",
            "list"
          ]
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "num_colors",
        "black_mix",
        "gaussian_mix",
        "brightness",
        "output_mode",
        "seed"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image to Noise",
    "display_name": "Image to Noise",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate/Noise",
    "output_node": false
  },
  "Image to Seed": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      true
    ],
    "output_name": [
      "INT"
    ],
    "name": "Image to Seed",
    "display_name": "Image to Seed",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Analyze",
    "output_node": false
  },
  "Images to RGB": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Images to RGB",
    "display_name": "Images to RGB",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Images to Linear": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "images"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Images to Linear",
    "display_name": "Images to Linear",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image",
    "output_node": false
  },
  "Integer place counter": {
    "input": {
      "required": {
        "int_input": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 10000000,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "int_input"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INT_PLACES"
    ],
    "name": "Integer place counter",
    "display_name": "Integer place counter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Integer",
    "output_node": false
  },
  "Image Voronoi Noise Filter": {
    "input": {
      "required": {
        "width": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 512,
            "max": 4096,
            "min": 64,
            "step": 1
          }
        ],
        "density": [
          "INT",
          {
            "default": 50,
            "max": 256,
            "min": 10,
            "step": 2
          }
        ],
        "modulator": [
          "INT",
          {
            "default": 0,
            "max": 8,
            "min": 0,
            "step": 1
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      },
      "optional": {
        "flat": [
          [
            "False",
            "True"
          ]
        ],
        "RGB_output": [
          [
            "True",
            "False"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "width",
        "height",
        "density",
        "modulator",
        "seed"
      ],
      "optional": [
        "flat",
        "RGB_output"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "image"
    ],
    "name": "Image Voronoi Noise Filter",
    "display_name": "Image Voronoi Noise Filter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Generate/Noise",
    "output_node": false
  },
  "KSampler (WAS)": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "seed": [
          "SEED"
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "latent_image": [
          "LATENT"
        ],
        "denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "denoise"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "KSampler (WAS)",
    "display_name": "KSampler (WAS)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Sampling",
    "output_node": false
  },
  "KSampler Cycle": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "steps": [
          "INT",
          {
            "default": 20,
            "min": 1,
            "max": 10000
          }
        ],
        "cfg": [
          "FLOAT",
          {
            "default": 8.0,
            "min": 0.0,
            "max": 100.0
          }
        ],
        "sampler_name": [
          [
            "euler",
            "euler_cfg_pp",
            "euler_ancestral",
            "euler_ancestral_cfg_pp",
            "heun",
            "heunpp2",
            "dpm_2",
            "dpm_2_ancestral",
            "lms",
            "dpm_fast",
            "dpm_adaptive",
            "dpmpp_2s_ancestral",
            "dpmpp_2s_ancestral_cfg_pp",
            "dpmpp_sde",
            "dpmpp_sde_gpu",
            "dpmpp_2m",
            "dpmpp_2m_cfg_pp",
            "dpmpp_2m_sde",
            "dpmpp_2m_sde_gpu",
            "dpmpp_2m_sde_heun",
            "dpmpp_2m_sde_heun_gpu",
            "dpmpp_3m_sde",
            "dpmpp_3m_sde_gpu",
            "ddpm",
            "lcm",
            "ipndm",
            "ipndm_v",
            "deis",
            "res_multistep",
            "res_multistep_cfg_pp",
            "res_multistep_ancestral",
            "res_multistep_ancestral_cfg_pp",
            "gradient_estimation",
            "gradient_estimation_cfg_pp",
            "er_sde",
            "seeds_2",
            "seeds_3",
            "sa_solver",
            "sa_solver_pece",
            "ddim",
            "uni_pc",
            "uni_pc_bh2"
          ]
        ],
        "scheduler": [
          [
            "simple",
            "sgm_uniform",
            "karras",
            "exponential",
            "ddim_uniform",
            "beta",
            "normal",
            "linear_quadratic",
            "kl_optimal"
          ]
        ],
        "positive": [
          "CONDITIONING"
        ],
        "negative": [
          "CONDITIONING"
        ],
        "latent_image": [
          "LATENT"
        ],
        "tiled_vae": [
          [
            "disable",
            "enable"
          ]
        ],
        "latent_upscale": [
          [
            "disable",
            "nearest-exact",
            "bilinear",
            "area",
            "bicubic",
            "bislerp"
          ]
        ],
        "upscale_factor": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.1,
            "max": 8.0,
            "step": 0.1
          }
        ],
        "upscale_cycles": [
          "INT",
          {
            "default": 2,
            "min": 2,
            "max": 12,
            "step": 1
          }
        ],
        "starting_denoise": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "cycle_denoise": [
          "FLOAT",
          {
            "default": 0.5,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "scale_denoise": [
          [
            "enable",
            "disable"
          ]
        ],
        "scale_sampling": [
          [
            "bilinear",
            "bicubic",
            "nearest",
            "lanczos"
          ]
        ],
        "vae": [
          "VAE"
        ]
      },
      "optional": {
        "secondary_model": [
          "MODEL"
        ],
        "secondary_start_cycle": [
          "INT",
          {
            "default": 2,
            "min": 2,
            "max": 16,
            "step": 1
          }
        ],
        "upscale_model": [
          "UPSCALE_MODEL"
        ],
        "processor_model": [
          "UPSCALE_MODEL"
        ],
        "pos_additive": [
          "CONDITIONING"
        ],
        "neg_additive": [
          "CONDITIONING"
        ],
        "pos_add_mode": [
          [
            "increment",
            "decrement"
          ]
        ],
        "pos_add_strength": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "pos_add_strength_scaling": [
          [
            "enable",
            "disable"
          ]
        ],
        "pos_add_strength_cutoff": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.01,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "neg_add_mode": [
          [
            "increment",
            "decrement"
          ]
        ],
        "neg_add_strength": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "neg_add_strength_scaling": [
          [
            "enable",
            "disable"
          ]
        ],
        "neg_add_strength_cutoff": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.01,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "sharpen_strength": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "sharpen_radius": [
          "INT",
          {
            "default": 2,
            "min": 1,
            "max": 12,
            "step": 1
          }
        ],
        "steps_scaling": [
          [
            "enable",
            "disable"
          ]
        ],
        "steps_control": [
          [
            "decrement",
            "increment"
          ]
        ],
        "steps_scaling_value": [
          "INT",
          {
            "default": 10,
            "min": 1,
            "max": 20,
            "step": 1
          }
        ],
        "steps_cutoff": [
          "INT",
          {
            "default": 20,
            "min": 4,
            "max": 1000,
            "step": 1
          }
        ],
        "denoise_cutoff": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.01,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "seed",
        "steps",
        "cfg",
        "sampler_name",
        "scheduler",
        "positive",
        "negative",
        "latent_image",
        "tiled_vae",
        "latent_upscale",
        "upscale_factor",
        "upscale_cycles",
        "starting_denoise",
        "cycle_denoise",
        "scale_denoise",
        "scale_sampling",
        "vae"
      ],
      "optional": [
        "secondary_model",
        "secondary_start_cycle",
        "upscale_model",
        "processor_model",
        "pos_additive",
        "neg_additive",
        "pos_add_mode",
        "pos_add_strength",
        "pos_add_strength_scaling",
        "pos_add_strength_cutoff",
        "neg_add_mode",
        "neg_add_strength",
        "neg_add_strength_scaling",
        "neg_add_strength_cutoff",
        "sharpen_strength",
        "sharpen_radius",
        "steps_scaling",
        "steps_control",
        "steps_scaling_value",
        "steps_cutoff",
        "denoise_cutoff"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "latent(s)"
    ],
    "name": "KSampler Cycle",
    "display_name": "KSampler Cycle",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Sampling",
    "output_node": false
  },
  "Latent Batch": {
    "input": {
      "required": {},
      "optional": {
        "latent_a": [
          "LATENT"
        ],
        "latent_b": [
          "LATENT"
        ],
        "latent_c": [
          "LATENT"
        ],
        "latent_d": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "latent_a",
        "latent_b",
        "latent_c",
        "latent_d"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "latent"
    ],
    "name": "Latent Batch",
    "display_name": "Latent Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Latent",
    "output_node": false
  },
  "Latent Noise Injection": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "noise_std": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "noise_std"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "Latent Noise Injection",
    "display_name": "Latent Noise Injection",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Latent/Generate",
    "output_node": false
  },
  "Latent Size to Number": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "samples"
      ]
    },
    "output": [
      "NUMBER",
      "NUMBER",
      "FLOAT",
      "FLOAT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "tensor_w_num",
      "tensor_h_num",
      "tensor_w_float",
      "tensor_h_float",
      "tensor_w_int",
      "tensor_h_int"
    ],
    "name": "Latent Size to Number",
    "display_name": "Latent Size to Number",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Latent Upscale by Factor (WAS)": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ],
        "mode": [
          [
            "area",
            "bicubic",
            "bilinear",
            "nearest"
          ]
        ],
        "factor": [
          "FLOAT",
          {
            "default": 2.0,
            "min": 0.1,
            "max": 8.0,
            "step": 0.01
          }
        ],
        "align": [
          [
            "true",
            "false"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "samples",
        "mode",
        "factor",
        "align"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LATENT"
    ],
    "name": "Latent Upscale by Factor (WAS)",
    "display_name": "Latent Upscale by Factor (WAS)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Latent/Transform",
    "output_node": false
  },
  "Load Image Batch": {
    "input": {
      "required": {
        "mode": [
          [
            "single_image",
            "incremental_image",
            "random"
          ]
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "index": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 150000,
            "step": 1
          }
        ],
        "label": [
          "STRING",
          {
            "default": "Batch 001",
            "multiline": false
          }
        ],
        "path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "pattern": [
          "STRING",
          {
            "default": "*",
            "multiline": false
          }
        ],
        "allow_RGBA_output": [
          [
            "false",
            "true"
          ]
        ]
      },
      "optional": {
        "filename_text_extension": [
          [
            "true",
            "false"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mode",
        "seed",
        "index",
        "label",
        "path",
        "pattern",
        "allow_RGBA_output"
      ],
      "optional": [
        "filename_text_extension"
      ]
    },
    "output": [
      "IMAGE",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "image",
      "filename_text"
    ],
    "name": "Load Image Batch",
    "display_name": "Load Image Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": false
  },
  "Load Text File": {
    "input": {
      "required": {
        "file_path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "dictionary_name": [
          "STRING",
          {
            "default": "[filename]",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file_path",
        "dictionary_name"
      ]
    },
    "output": [
      "STRING",
      "DICT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "STRING",
      "DICT"
    ],
    "name": "Load Text File",
    "display_name": "Load Text File",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": false
  },
  "Load Lora": {
    "input": {
      "required": {
        "model": [
          "MODEL"
        ],
        "clip": [
          "CLIP"
        ],
        "lora_name": [
          [
            "None"
          ]
        ],
        "strength_model": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ],
        "strength_clip": [
          "FLOAT",
          {
            "default": 1.0,
            "min": -10.0,
            "max": 10.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model",
        "clip",
        "lora_name",
        "strength_model",
        "strength_clip"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "NAME_STRING"
    ],
    "name": "Load Lora",
    "display_name": "Load Lora",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "Lora Input Switch": {
    "input": {
      "required": {
        "model_a": [
          "MODEL"
        ],
        "clip_a": [
          "CLIP"
        ],
        "model_b": [
          "MODEL"
        ],
        "clip_b": [
          "CLIP"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_a",
        "clip_a",
        "model_b",
        "clip_b",
        "boolean"
      ]
    },
    "output": [
      "MODEL",
      "CLIP"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP"
    ],
    "name": "Lora Input Switch",
    "display_name": "Lora Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Masks Add": {
    "input": {
      "required": {
        "masks_a": [
          "MASK"
        ],
        "masks_b": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks_a",
        "masks_b"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Masks Add",
    "display_name": "Masks Add",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Masks Subtract": {
    "input": {
      "required": {
        "masks_a": [
          "MASK"
        ],
        "masks_b": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks_a",
        "masks_b"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Masks Subtract",
    "display_name": "Masks Subtract",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Arbitrary Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "size": [
          "INT",
          {
            "default": 256,
            "min": 1,
            "max": 4096,
            "step": 1
          }
        ],
        "threshold": [
          "INT",
          {
            "default": 128,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "size",
        "threshold"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Arbitrary Region",
    "display_name": "Mask Arbitrary Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Batch to Mask": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "batch_number": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "batch_number"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "Mask Batch to Mask",
    "display_name": "Mask Batch to Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Batch": {
    "input": {
      "optional": {
        "masks_a": [
          "MASK"
        ],
        "masks_b": [
          "MASK"
        ],
        "masks_c": [
          "MASK"
        ],
        "masks_d": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "optional": [
        "masks_a",
        "masks_b",
        "masks_c",
        "masks_d"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "masks"
    ],
    "name": "Mask Batch",
    "display_name": "Mask Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Ceiling Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Ceiling Region",
    "display_name": "Mask Ceiling Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Crop Dominant Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "padding": [
          "INT",
          {
            "default": 24,
            "min": 0,
            "max": 4096,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "padding"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Crop Dominant Region",
    "display_name": "Mask Crop Dominant Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Crop Minority Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "padding": [
          "INT",
          {
            "default": 24,
            "min": 0,
            "max": 4096,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "padding"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Crop Minority Region",
    "display_name": "Mask Crop Minority Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Crop Region": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "padding": [
          "INT",
          {
            "default": 24,
            "min": 0,
            "max": 4096,
            "step": 1
          }
        ],
        "region_type": [
          [
            "dominant",
            "minority"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "padding",
        "region_type"
      ]
    },
    "output": [
      "MASK",
      "CROP_DATA",
      "INT",
      "INT",
      "INT",
      "INT",
      "INT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "cropped_mask",
      "crop_data",
      "top_int",
      "left_int",
      "right_int",
      "bottom_int",
      "width_int",
      "height_int"
    ],
    "name": "Mask Crop Region",
    "display_name": "Mask Crop Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Paste Region": {
    "input": {
      "required": {
        "mask": [
          "MASK"
        ],
        "crop_mask": [
          "MASK"
        ],
        "crop_data": [
          "CROP_DATA"
        ],
        "crop_blending": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ],
        "crop_sharpening": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 3,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mask",
        "crop_mask",
        "crop_data",
        "crop_blending",
        "crop_sharpening"
      ]
    },
    "output": [
      "MASK",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "RESULT_MASK",
      "CROP_MASK"
    ],
    "name": "Mask Paste Region",
    "display_name": "Mask Paste Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Dilate Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "iterations": [
          "INT",
          {
            "default": 5,
            "min": 1,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "iterations"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Dilate Region",
    "display_name": "Mask Dilate Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Dominant Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "threshold": [
          "INT",
          {
            "default": 128,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "threshold"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Dominant Region",
    "display_name": "Mask Dominant Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Erode Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "iterations": [
          "INT",
          {
            "default": 5,
            "min": 1,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "iterations"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Erode Region",
    "display_name": "Mask Erode Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Fill Holes": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Fill Holes",
    "display_name": "Mask Fill Holes",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Floor Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Floor Region",
    "display_name": "Mask Floor Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Gaussian Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "radius": [
          "FLOAT",
          {
            "default": 5.0,
            "min": 0.0,
            "max": 1024,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "radius"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Gaussian Region",
    "display_name": "Mask Gaussian Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Invert": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Invert",
    "display_name": "Mask Invert",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Minority Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "threshold": [
          "INT",
          {
            "default": 128,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "threshold"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Minority Region",
    "display_name": "Mask Minority Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Rect Area": {
    "input": {
      "required": {
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "width": [
          "INT",
          {
            "default": 50,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "height": [
          "INT",
          {
            "default": 50,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "blur_radius": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      },
      "hidden": {
        "extra_pnginfo": "EXTRA_PNGINFO",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "x",
        "y",
        "width",
        "height",
        "blur_radius"
      ],
      "hidden": [
        "extra_pnginfo",
        "unique_id"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Rect Area",
    "display_name": "Mask Rect Area",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Rect Area (Advanced)": {
    "input": {
      "required": {
        "x": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096,
            "step": 64
          }
        ],
        "y": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 4096,
            "step": 64
          }
        ],
        "width": [
          "INT",
          {
            "default": 256,
            "min": 0,
            "max": 4096,
            "step": 64
          }
        ],
        "height": [
          "INT",
          {
            "default": 256,
            "min": 0,
            "max": 4096,
            "step": 64
          }
        ],
        "image_width": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096,
            "step": 64
          }
        ],
        "image_height": [
          "INT",
          {
            "default": 512,
            "min": 64,
            "max": 4096,
            "step": 64
          }
        ],
        "blur_radius": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      },
      "hidden": {
        "extra_pnginfo": "EXTRA_PNGINFO",
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "x",
        "y",
        "width",
        "height",
        "image_width",
        "image_height",
        "blur_radius"
      ],
      "hidden": [
        "extra_pnginfo",
        "unique_id"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Rect Area (Advanced)",
    "display_name": "Mask Rect Area (Advanced)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Smooth Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "sigma": [
          "FLOAT",
          {
            "default": 5.0,
            "min": 0.0,
            "max": 128.0,
            "step": 0.1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "sigma"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Smooth Region",
    "display_name": "Mask Smooth Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Mask Threshold Region": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ],
        "black_threshold": [
          "INT",
          {
            "default": 75,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "white_threshold": [
          "INT",
          {
            "default": 175,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "masks",
        "black_threshold",
        "white_threshold"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASKS"
    ],
    "name": "Mask Threshold Region",
    "display_name": "Mask Threshold Region",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Masks Combine Regions": {
    "input": {
      "required": {
        "mask_a": [
          "MASK"
        ],
        "mask_b": [
          "MASK"
        ]
      },
      "optional": {
        "mask_c": [
          "MASK"
        ],
        "mask_d": [
          "MASK"
        ],
        "mask_e": [
          "MASK"
        ],
        "mask_f": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "mask_a",
        "mask_b"
      ],
      "optional": [
        "mask_c",
        "mask_d",
        "mask_e",
        "mask_f"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "Masks Combine Regions",
    "display_name": "Masks Combine Regions",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Masks Combine Batch": {
    "input": {
      "required": {
        "masks": [
          "MASK"
        ]
      }
    },
    "input_order": {
      "required": [
        "masks"
      ]
    },
    "output": [
      "MASK"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MASK"
    ],
    "name": "Masks Combine Batch",
    "display_name": "Masks Combine Batch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "MiDaS Model Loader": {
    "input": {
      "required": {
        "midas_model": [
          [
            "DPT_Large",
            "DPT_Hybrid"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "midas_model"
      ]
    },
    "output": [
      "MIDAS_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "midas_model"
    ],
    "name": "MiDaS Model Loader",
    "display_name": "MiDaS Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "MiDaS Depth Approximation": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "use_cpu": [
          [
            "false",
            "true"
          ]
        ],
        "midas_type": [
          [
            "DPT_Large",
            "DPT_Hybrid"
          ]
        ],
        "invert_depth": [
          [
            "false",
            "true"
          ]
        ]
      },
      "optional": {
        "midas_model": [
          "MIDAS_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "use_cpu",
        "midas_type",
        "invert_depth"
      ],
      "optional": [
        "midas_model"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "images"
    ],
    "name": "MiDaS Depth Approximation",
    "display_name": "MiDaS Depth Approximation",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/AI",
    "output_node": false
  },
  "MiDaS Mask Image": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "use_cpu": [
          [
            "false",
            "true"
          ]
        ],
        "midas_model": [
          [
            "DPT_Large",
            "DPT_Hybrid",
            "DPT_Small"
          ]
        ],
        "remove": [
          [
            "background",
            "foregroud"
          ]
        ],
        "threshold": [
          [
            "false",
            "true"
          ]
        ],
        "threshold_low": [
          "FLOAT",
          {
            "default": 10,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "threshold_mid": [
          "FLOAT",
          {
            "default": 200,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "threshold_high": [
          "FLOAT",
          {
            "default": 210,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "smoothing": [
          "FLOAT",
          {
            "default": 0.25,
            "min": 0.0,
            "max": 16.0,
            "step": 0.01
          }
        ],
        "background_red": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "background_green": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ],
        "background_blue": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 255,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "use_cpu",
        "midas_model",
        "remove",
        "threshold",
        "threshold_low",
        "threshold_mid",
        "threshold_high",
        "smoothing",
        "background_red",
        "background_green",
        "background_blue"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "RESULT",
      "DEPTH"
    ],
    "name": "MiDaS Mask Image",
    "display_name": "MiDaS Mask Image",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/AI",
    "output_node": false
  },
  "Model Input Switch": {
    "input": {
      "required": {
        "model_a": [
          "MODEL"
        ],
        "model_b": [
          "MODEL"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "model_a",
        "model_b",
        "boolean"
      ]
    },
    "output": [
      "MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "MODEL"
    ],
    "name": "Model Input Switch",
    "display_name": "Model Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Number Counter": {
    "input": {
      "required": {
        "number_type": [
          [
            "integer",
            "float"
          ]
        ],
        "mode": [
          [
            "increment",
            "decrement",
            "increment_to_stop",
            "decrement_to_stop",
            "reset_after_stop"
          ]
        ],
        "start": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615,
            "step": 0.01
          }
        ],
        "stop": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615,
            "step": 0.01
          }
        ],
        "step": [
          "FLOAT",
          {
            "default": 1,
            "min": 0,
            "max": 99999,
            "step": 0.01
          }
        ]
      },
      "optional": {
        "reset_bool": [
          "NUMBER"
        ]
      },
      "hidden": {
        "unique_id": "UNIQUE_ID"
      }
    },
    "input_order": {
      "required": [
        "number_type",
        "mode",
        "start",
        "stop",
        "step"
      ],
      "optional": [
        "reset_bool"
      ],
      "hidden": [
        "unique_id"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "number",
      "float",
      "int"
    ],
    "name": "Number Counter",
    "display_name": "Number Counter",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "Number Operation": {
    "input": {
      "required": {
        "number_a": [
          "NUMBER"
        ],
        "number_b": [
          "NUMBER"
        ],
        "operation": [
          [
            "addition",
            "subtraction",
            "division",
            "floor division",
            "multiplication",
            "exponentiation",
            "modulus",
            "greater-than",
            "greater-than or equals",
            "less-than",
            "less-than or equals",
            "equals",
            "does not equal"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "number_a",
        "number_b",
        "operation"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Number Operation",
    "display_name": "Number Operation",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Number to Float": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [
        "number"
      ]
    },
    "output": [
      "FLOAT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "FLOAT"
    ],
    "name": "Number to Float",
    "display_name": "Number to Float",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Number Input Switch": {
    "input": {
      "required": {
        "number_a": [
          "NUMBER"
        ],
        "number_b": [
          "NUMBER"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "number_a",
        "number_b",
        "boolean"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Number Input Switch",
    "display_name": "Number Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Number Input Condition": {
    "input": {
      "required": {
        "number_a": [
          "NUMBER"
        ],
        "number_b": [
          "NUMBER"
        ],
        "return_boolean": [
          [
            "false",
            "true"
          ]
        ],
        "comparison": [
          [
            "and",
            "or",
            "greater-than",
            "greater-than or equals",
            "less-than",
            "less-than or equals",
            "equals",
            "does not equal",
            "divisible by",
            "if A odd",
            "if A even",
            "if A prime",
            "factor of"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "number_a",
        "number_b",
        "return_boolean",
        "comparison"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Number Input Condition",
    "display_name": "Number Input Condition",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Number Multiple Of": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ],
        "multiple": [
          "INT",
          {
            "default": 8,
            "min": -18446744073709551615,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "number",
        "multiple"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Number Multiple Of",
    "display_name": "Number Multiple Of",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Functions",
    "output_node": false
  },
  "Number PI": {
    "input": {
      "required": {}
    },
    "input_order": {
      "required": []
    },
    "output": [
      "NUMBER",
      "FLOAT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT"
    ],
    "name": "Number PI",
    "display_name": "Number PI",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "Number to Int": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [
        "number"
      ]
    },
    "output": [
      "INT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "INT"
    ],
    "name": "Number to Int",
    "display_name": "Number to Int",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Number to Seed": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [
        "number"
      ]
    },
    "output": [
      "SEED"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SEED"
    ],
    "name": "Number to Seed",
    "display_name": "Number to Seed",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Number to String": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [
        "number"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Number to String",
    "display_name": "Number to String",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Number to Text": {
    "input": {
      "required": {
        "number": [
          "NUMBER"
        ]
      }
    },
    "input_order": {
      "required": [
        "number"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Number to Text",
    "display_name": "Number to Text",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number/Operations",
    "output_node": false
  },
  "Boolean To Text": {
    "input": {
      "required": {
        "boolean": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "boolean"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Boolean To Text",
    "display_name": "Boolean To Text",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Prompt Styles Selector": {
    "input": {
      "required": {
        "style": [
          [
            "None"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "style"
      ]
    },
    "output": [
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive_string",
      "negative_string"
    ],
    "name": "Prompt Styles Selector",
    "display_name": "Prompt Styles Selector",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Prompt Multiple Styles Selector": {
    "input": {
      "required": {
        "style1": [
          [
            "None"
          ]
        ],
        "style2": [
          [
            "None"
          ]
        ],
        "style3": [
          [
            "None"
          ]
        ],
        "style4": [
          [
            "None"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "style1",
        "style2",
        "style3",
        "style4"
      ]
    },
    "output": [
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "positive_string",
      "negative_string"
    ],
    "name": "Prompt Multiple Styles Selector",
    "display_name": "Prompt Multiple Styles Selector",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Random Number": {
    "input": {
      "required": {
        "number_type": [
          [
            "integer",
            "float",
            "bool"
          ]
        ],
        "minimum": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615
          }
        ],
        "maximum": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "number_type",
        "minimum",
        "maximum",
        "seed"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "Random Number",
    "display_name": "Random Number",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "Save Text File": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "path": [
          "STRING",
          {
            "default": "./ComfyUI/output/[time(%Y-%m-%d)]",
            "multiline": false
          }
        ],
        "filename_prefix": [
          "STRING",
          {
            "default": "ComfyUI"
          }
        ],
        "filename_delimiter": [
          "STRING",
          {
            "default": "_"
          }
        ],
        "filename_number_padding": [
          "INT",
          {
            "default": 4,
            "min": 0,
            "max": 9,
            "step": 1
          }
        ]
      },
      "optional": {
        "file_extension": [
          "STRING",
          {
            "default": ".txt"
          }
        ],
        "encoding": [
          "STRING",
          {
            "default": "utf-8"
          }
        ],
        "filename_suffix": [
          "STRING",
          {
            "default": ""
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "path",
        "filename_prefix",
        "filename_delimiter",
        "filename_number_padding"
      ],
      "optional": [
        "file_extension",
        "encoding",
        "filename_suffix"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Save Text File",
    "display_name": "Save Text File",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/IO",
    "output_node": true
  },
  "Seed": {
    "input": {
      "required": {
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "seed"
      ]
    },
    "output": [
      "SEED",
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "seed",
      "number",
      "float",
      "int"
    ],
    "name": "Seed",
    "display_name": "Seed",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "Tensor Batch to Image": {
    "input": {
      "required": {
        "images_batch": [
          "IMAGE"
        ],
        "batch_image_number": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 64,
            "step": 1
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images_batch",
        "batch_image_number"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Tensor Batch to Image",
    "display_name": "Tensor Batch to Image",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Latent/Transform",
    "output_node": false
  },
  "BLIP Analyze Image": {
    "input": {
      "required": {
        "images": [
          "IMAGE"
        ],
        "mode": [
          [
            "caption",
            "interrogate"
          ]
        ],
        "question": [
          "STRING",
          {
            "default": "What does the background consist of?",
            "multiline": true,
            "dynamicPrompts": false
          }
        ],
        "blip_model": [
          "BLIP_MODEL"
        ]
      },
      "optional": {
        "min_length": [
          "INT",
          {
            "min": 1,
            "max": 1024,
            "default": 24
          }
        ],
        "max_length": [
          "INT",
          {
            "min": 2,
            "max": 1024,
            "default": 64
          }
        ],
        "num_beams": [
          "INT",
          {
            "min": 1,
            "max": 12,
            "default": 5
          }
        ],
        "no_repeat_ngram_size": [
          "INT",
          {
            "min": 1,
            "max": 12,
            "default": 3
          }
        ],
        "early_stopping": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "images",
        "mode",
        "question",
        "blip_model"
      ],
      "optional": [
        "min_length",
        "max_length",
        "num_beams",
        "no_repeat_ngram_size",
        "early_stopping"
      ]
    },
    "output": [
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      true
    ],
    "output_name": [
      "FULL_CAPTIONS",
      "CAPTIONS"
    ],
    "name": "BLIP Analyze Image",
    "display_name": "BLIP Analyze Image",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/AI",
    "output_node": false
  },
  "SAM Model Loader": {
    "input": {
      "required": {
        "model_size": [
          [
            "ViT-H",
            "ViT-L",
            "ViT-B"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "model_size"
      ]
    },
    "output": [
      "SAM_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAM_MODEL"
    ],
    "name": "SAM Model Loader",
    "display_name": "SAM Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "SAM Parameters": {
    "input": {
      "required": {
        "points": [
          "STRING",
          {
            "default": "[128, 128]; [0, 0]",
            "multiline": false
          }
        ],
        "labels": [
          "STRING",
          {
            "default": "[1, 0]",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "points",
        "labels"
      ]
    },
    "output": [
      "SAM_PARAMETERS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAM_PARAMETERS"
    ],
    "name": "SAM Parameters",
    "display_name": "SAM Parameters",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "SAM Parameters Combine": {
    "input": {
      "required": {
        "sam_parameters_a": [
          "SAM_PARAMETERS"
        ],
        "sam_parameters_b": [
          "SAM_PARAMETERS"
        ]
      }
    },
    "input_order": {
      "required": [
        "sam_parameters_a",
        "sam_parameters_b"
      ]
    },
    "output": [
      "SAM_PARAMETERS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "SAM_PARAMETERS"
    ],
    "name": "SAM Parameters Combine",
    "display_name": "SAM Parameters Combine",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "SAM Image Mask": {
    "input": {
      "required": {
        "sam_model": [
          "SAM_MODEL"
        ],
        "sam_parameters": [
          "SAM_PARAMETERS"
        ],
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "sam_model",
        "sam_parameters",
        "image"
      ]
    },
    "output": [
      "IMAGE",
      "MASK"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "MASK"
    ],
    "name": "SAM Image Mask",
    "display_name": "SAM Image Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Masking",
    "output_node": false
  },
  "Samples Passthrough (Stat System)": {
    "input": {
      "required": {
        "samples": [
          "LATENT"
        ]
      }
    },
    "input_order": {
      "required": [
        "samples"
      ]
    },
    "output": [
      "LATENT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "samples"
    ],
    "name": "Samples Passthrough (Stat System)",
    "display_name": "Samples Passthrough (Stat System)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": false
  },
  "String to Text": {
    "input": {
      "required": {
        "string": [
          "STRING",
          {}
        ]
      }
    },
    "input_order": {
      "required": [
        "string"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "String to Text",
    "display_name": "String to Text",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Image Bounds": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ]
      }
    },
    "input_order": {
      "required": [
        "image"
      ]
    },
    "output": [
      "IMAGE_BOUNDS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE_BOUNDS"
    ],
    "name": "Image Bounds",
    "display_name": "Image Bounds",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Inset Image Bounds": {
    "input": {
      "required": {
        "image_bounds": [
          "IMAGE_BOUNDS"
        ],
        "inset_left": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "inset_right": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "inset_top": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "inset_bottom": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_bounds",
        "inset_left",
        "inset_right",
        "inset_top",
        "inset_bottom"
      ]
    },
    "output": [
      "IMAGE_BOUNDS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE_BOUNDS"
    ],
    "name": "Inset Image Bounds",
    "display_name": "Inset Image Bounds",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Bounded Image Blend": {
    "input": {
      "required": {
        "target": [
          "IMAGE"
        ],
        "target_bounds": [
          "IMAGE_BOUNDS"
        ],
        "source": [
          "IMAGE"
        ],
        "blend_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "feathering": [
          "INT",
          {
            "default": 16,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "target",
        "target_bounds",
        "source",
        "blend_factor",
        "feathering"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Bounded Image Blend",
    "display_name": "Bounded Image Blend",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Bounded Image Blend with Mask": {
    "input": {
      "required": {
        "target": [
          "IMAGE"
        ],
        "target_mask": [
          "MASK"
        ],
        "target_bounds": [
          "IMAGE_BOUNDS"
        ],
        "source": [
          "IMAGE"
        ],
        "blend_factor": [
          "FLOAT",
          {
            "default": 1.0,
            "min": 0.0,
            "max": 1.0
          }
        ],
        "feathering": [
          "INT",
          {
            "default": 16,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "target",
        "target_mask",
        "target_bounds",
        "source",
        "blend_factor",
        "feathering"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Bounded Image Blend with Mask",
    "display_name": "Bounded Image Blend with Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Bounded Image Crop": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "image_bounds": [
          "IMAGE_BOUNDS"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "image_bounds"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "Bounded Image Crop",
    "display_name": "Bounded Image Crop",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Bounded Image Crop with Mask": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "mask": [
          "MASK"
        ],
        "padding_left": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "padding_right": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "padding_top": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "padding_bottom": [
          "INT",
          {
            "default": 64,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      },
      "optional": {
        "return_list": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "mask",
        "padding_left",
        "padding_right",
        "padding_top",
        "padding_bottom"
      ],
      "optional": [
        "return_list"
      ]
    },
    "output": [
      "IMAGE",
      "IMAGE_BOUNDS"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "IMAGE",
      "IMAGE_BOUNDS"
    ],
    "name": "Bounded Image Crop with Mask",
    "display_name": "Bounded Image Crop with Mask",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Image/Bound",
    "output_node": false
  },
  "Image Bounds to Console": {
    "input": {
      "required": {
        "image_bounds": [
          "IMAGE_BOUNDS"
        ],
        "label": [
          "STRING",
          {
            "default": "Debug to Console",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image_bounds",
        "label"
      ]
    },
    "output": [
      "IMAGE_BOUNDS"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE_BOUNDS"
    ],
    "name": "Image Bounds to Console",
    "display_name": "Image Bounds to Console",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": true
  },
  "Text Dictionary Update": {
    "input": {
      "required": {
        "dictionary_a": [
          "DICT"
        ],
        "dictionary_b": [
          "DICT"
        ]
      },
      "optional": {
        "dictionary_c": [
          "DICT"
        ],
        "dictionary_d": [
          "DICT"
        ]
      }
    },
    "input_order": {
      "required": [
        "dictionary_a",
        "dictionary_b"
      ],
      "optional": [
        "dictionary_c",
        "dictionary_d"
      ]
    },
    "output": [
      "DICT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "DICT"
    ],
    "name": "Text Dictionary Update",
    "display_name": "Text Dictionary Update",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Dictionary Get": {
    "input": {
      "required": {
        "dictionary": [
          "DICT"
        ],
        "key": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "default_value": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "dictionary",
        "key"
      ],
      "optional": [
        "default_value"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Dictionary Get",
    "display_name": "Text Dictionary Get",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Dictionary Convert": {
    "input": {
      "required": {
        "dictionary_text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "dictionary_text"
      ]
    },
    "output": [
      "DICT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "DICT"
    ],
    "name": "Text Dictionary Convert",
    "display_name": "Text Dictionary Convert",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Dictionary New": {
    "input": {
      "required": {
        "key_1": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "value_1": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "key_2": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "value_2": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "key_3": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "value_3": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "key_4": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "value_4": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "key_5": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "value_5": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "key_1",
        "value_1"
      ],
      "optional": [
        "key_2",
        "value_2",
        "key_3",
        "value_3",
        "key_4",
        "value_4",
        "key_5",
        "value_5"
      ]
    },
    "output": [
      "DICT"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "DICT"
    ],
    "name": "Text Dictionary New",
    "display_name": "Text Dictionary New",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Dictionary Keys": {
    "input": {
      "required": {
        "dictionary": [
          "DICT"
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "dictionary"
      ],
      "optional": []
    },
    "output": [
      "LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LIST"
    ],
    "name": "Text Dictionary Keys",
    "display_name": "Text Dictionary Keys",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Dictionary To Text": {
    "input": {
      "required": {
        "dictionary": [
          "DICT"
        ]
      },
      "optional": {}
    },
    "input_order": {
      "required": [
        "dictionary"
      ],
      "optional": []
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Dictionary To Text",
    "display_name": "Text Dictionary To Text",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Add Tokens": {
    "input": {
      "required": {
        "tokens": [
          "STRING",
          {
            "default": "[hello]: world",
            "multiline": true
          }
        ],
        "print_current_tokens": [
          [
            "false",
            "true"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "tokens",
        "print_current_tokens"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Text Add Tokens",
    "display_name": "Text Add Tokens",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Tokens",
    "output_node": true
  },
  "Text Add Token by Input": {
    "input": {
      "required": {
        "token_name": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "token_value": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "print_current_tokens": [
          [
            "false",
            "true"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "token_name",
        "token_value",
        "print_current_tokens"
      ]
    },
    "output": [],
    "output_is_list": [],
    "output_name": [],
    "name": "Text Add Token by Input",
    "display_name": "Text Add Token by Input",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Tokens",
    "output_node": true
  },
  "Text Compare": {
    "input": {
      "required": {
        "text_a": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_b": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "mode": [
          [
            "similarity",
            "difference"
          ]
        ],
        "tolerance": [
          "FLOAT",
          {
            "default": 0.0,
            "min": 0.0,
            "max": 1.0,
            "step": 0.01
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text_a",
        "text_b",
        "mode",
        "tolerance"
      ]
    },
    "output": [
      "STRING",
      "STRING",
      "BOOLEAN",
      "NUMBER",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "TEXT_A_PASS",
      "TEXT_B_PASS",
      "BOOLEAN",
      "SCORE_NUMBER",
      "COMPARISON_TEXT"
    ],
    "name": "Text Compare",
    "display_name": "Text Compare",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Search",
    "output_node": false
  },
  "Text Concatenate": {
    "input": {
      "required": {
        "delimiter": [
          "STRING",
          {
            "default": ", "
          }
        ],
        "clean_whitespace": [
          [
            "true",
            "false"
          ]
        ]
      },
      "optional": {
        "text_a": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_b": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_c": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_d": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "delimiter",
        "clean_whitespace"
      ],
      "optional": [
        "text_a",
        "text_b",
        "text_c",
        "text_d"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Concatenate",
    "display_name": "Text Concatenate",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text File History Loader": {
    "input": {
      "required": {
        "file": [
          [
            "No History"
          ]
        ],
        "dictionary_name": [
          "STRING",
          {
            "default": "[filename]",
            "multiline": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file",
        "dictionary_name"
      ]
    },
    "output": [
      "STRING",
      "DICT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "STRING",
      "DICT"
    ],
    "name": "Text File History Loader",
    "display_name": "Text File History Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/History",
    "output_node": false
  },
  "Text Find and Replace by Dictionary": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "dictionary": [
          "DICT"
        ],
        "replacement_key": [
          "STRING",
          {
            "default": "__",
            "multiline": false
          }
        ],
        "seed": [
          "INT",
          {
            "default": 1,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "dictionary",
        "replacement_key",
        "seed"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Find and Replace by Dictionary",
    "display_name": "Text Find and Replace by Dictionary",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Search",
    "output_node": false
  },
  "Text Find and Replace Input": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "find": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "replace": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "find",
        "replace"
      ]
    },
    "output": [
      "STRING",
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "result_text",
      "replacement_count_number",
      "replacement_count_float",
      "replacement_count_int"
    ],
    "name": "Text Find and Replace Input",
    "display_name": "Text Find and Replace Input",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Search",
    "output_node": false
  },
  "Text Find and Replace": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "find": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "replace": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "find",
        "replace"
      ]
    },
    "output": [
      "STRING",
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "result_text",
      "replacement_count_number",
      "replacement_count_float",
      "replacement_count_int"
    ],
    "name": "Text Find and Replace",
    "display_name": "Text Find and Replace",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Search",
    "output_node": false
  },
  "Text Find": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "substring": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "pattern": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "substring",
        "pattern"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "found"
    ],
    "name": "Text Find",
    "display_name": "Text Find",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Search",
    "output_node": false
  },
  "Text Input Switch": {
    "input": {
      "required": {
        "text_a": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_b": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text_a",
        "text_b",
        "boolean"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Input Switch",
    "display_name": "Text Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Text List": {
    "input": {
      "required": {},
      "optional": {
        "text_a": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_b": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_c": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_d": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_e": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_f": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_g": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "text_a",
        "text_b",
        "text_c",
        "text_d",
        "text_e",
        "text_f",
        "text_g"
      ]
    },
    "output": [
      "LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LIST"
    ],
    "name": "Text List",
    "display_name": "Text List",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text List Concatenate": {
    "input": {
      "required": {},
      "optional": {
        "list_a": [
          "LIST",
          {
            "forceInput": true
          }
        ],
        "list_b": [
          "LIST",
          {
            "forceInput": true
          }
        ],
        "list_c": [
          "LIST",
          {
            "forceInput": true
          }
        ],
        "list_d": [
          "LIST",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [],
      "optional": [
        "list_a",
        "list_b",
        "list_c",
        "list_d"
      ]
    },
    "output": [
      "LIST"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "LIST"
    ],
    "name": "Text List Concatenate",
    "display_name": "Text List Concatenate",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text List to Text": {
    "input": {
      "required": {
        "delimiter": [
          "STRING",
          {
            "default": ", "
          }
        ],
        "text_list": [
          "LIST",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "delimiter",
        "text_list"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text List to Text",
    "display_name": "Text List to Text",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Load Line From File": {
    "input": {
      "required": {
        "file_path": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "dictionary_name": [
          "STRING",
          {
            "default": "[filename]",
            "multiline": false
          }
        ],
        "label": [
          "STRING",
          {
            "default": "TextBatch",
            "multiline": false
          }
        ],
        "mode": [
          [
            "automatic",
            "index"
          ]
        ],
        "index": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "step": 1
          }
        ]
      },
      "optional": {
        "multiline_text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "file_path",
        "dictionary_name",
        "label",
        "mode",
        "index"
      ],
      "optional": [
        "multiline_text"
      ]
    },
    "output": [
      "STRING",
      "DICT"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "line_text",
      "dictionary"
    ],
    "name": "Text Load Line From File",
    "display_name": "Text Load Line From File",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Multiline": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "dynamicPrompts": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Multiline",
    "display_name": "Text Multiline",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Multiline (Code Compatible)": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": true,
            "dynamicPrompts": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Multiline (Code Compatible)",
    "display_name": "Text Multiline (Code Compatible)",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Parse A1111 Embeddings": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Parse A1111 Embeddings",
    "display_name": "Text Parse A1111 Embeddings",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Parse",
    "output_node": false
  },
  "Text Parse Noodle Soup Prompts": {
    "input": {
      "required": {
        "mode": [
          [
            "Noodle Soup Prompts",
            "Wildcards"
          ]
        ],
        "noodle_key": [
          "STRING",
          {
            "default": "__",
            "multiline": false
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ],
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "mode",
        "noodle_key",
        "seed",
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Parse Noodle Soup Prompts",
    "display_name": "Text Parse Noodle Soup Prompts",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Parse",
    "output_node": true
  },
  "Text Parse Tokens": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Parse Tokens",
    "display_name": "Text Parse Tokens",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Tokens",
    "output_node": false
  },
  "Text Random Line": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "seed"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Random Line",
    "display_name": "Text Random Line",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Random Prompt": {
    "input": {
      "required": {
        "search_seed": [
          "STRING",
          {
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "search_seed"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Random Prompt",
    "display_name": "Text Random Prompt",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text String": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "text_b": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_c": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "text_d": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ],
      "optional": [
        "text_b",
        "text_c",
        "text_d"
      ]
    },
    "output": [
      "STRING",
      "STRING",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "TEXT",
      "TEXT_B",
      "TEXT_C",
      "TEXT_D"
    ],
    "name": "Text String",
    "display_name": "Text String",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text",
    "output_node": false
  },
  "Text Contains": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "sub_text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ]
      },
      "optional": {
        "case_insensitive": [
          "BOOLEAN",
          {
            "default": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "sub_text"
      ],
      "optional": [
        "case_insensitive"
      ]
    },
    "output": [
      "BOOLEAN"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "BOOLEAN"
    ],
    "name": "Text Contains",
    "display_name": "Text Contains",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Text Shuffle": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "separator": [
          "STRING",
          {
            "default": ",",
            "multiline": false
          }
        ],
        "seed": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 18446744073709551615
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "separator",
        "seed"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Shuffle",
    "display_name": "Text Shuffle",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Text Sort": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "separator": [
          "STRING",
          {
            "default": ", ",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "separator"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text Sort",
    "display_name": "Text Sort",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Text to Conditioning": {
    "input": {
      "required": {
        "clip": [
          "CLIP"
        ],
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "clip",
        "text"
      ]
    },
    "output": [
      "CONDITIONING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "CONDITIONING"
    ],
    "name": "Text to Conditioning",
    "display_name": "Text to Conditioning",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Text to Console": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "label": [
          "STRING",
          {
            "default": "Text Output",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "label"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text to Console",
    "display_name": "Text to Console",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Debug",
    "output_node": true
  },
  "Text to Number": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "NUMBER"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "NUMBER"
    ],
    "name": "Text to Number",
    "display_name": "Text to Number",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Text to String": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text"
      ]
    },
    "output": [
      "STRING"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "STRING"
    ],
    "name": "Text to String",
    "display_name": "Text to String",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "Text String Truncate": {
    "input": {
      "required": {
        "text": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "truncate_by": [
          [
            "characters",
            "words"
          ]
        ],
        "truncate_from": [
          [
            "end",
            "beginning"
          ]
        ],
        "truncate_to": [
          "INT",
          {
            "default": 10,
            "min": -99999999,
            "max": 99999999,
            "step": 1
          }
        ]
      },
      "optional": {
        "text_b": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_c": [
          "STRING",
          {
            "forceInput": true
          }
        ],
        "text_d": [
          "STRING",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "text",
        "truncate_by",
        "truncate_from",
        "truncate_to"
      ],
      "optional": [
        "text_b",
        "text_c",
        "text_d"
      ]
    },
    "output": [
      "STRING",
      "STRING",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "TEXT",
      "TEXT_B",
      "TEXT_C",
      "TEXT_D"
    ],
    "name": "Text String Truncate",
    "display_name": "Text String Truncate",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Text/Operations",
    "output_node": false
  },
  "True Random.org Number Generator": {
    "input": {
      "required": {
        "api_key": [
          "STRING",
          {
            "default": "00000000-0000-0000-0000-000000000000",
            "multiline": false
          }
        ],
        "minimum": [
          "FLOAT",
          {
            "default": 0,
            "min": -18446744073709551615,
            "max": 18446744073709551615
          }
        ],
        "maximum": [
          "FLOAT",
          {
            "default": 10000000,
            "min": -18446744073709551615,
            "max": 18446744073709551615
          }
        ],
        "mode": [
          [
            "random",
            "fixed"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "api_key",
        "minimum",
        "maximum",
        "mode"
      ]
    },
    "output": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "NUMBER",
      "FLOAT",
      "INT"
    ],
    "name": "True Random.org Number Generator",
    "display_name": "True Random.org Number Generator",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Number",
    "output_node": false
  },
  "unCLIP Checkpoint Loader": {
    "input": {
      "required": {
        "ckpt_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "ckpt_name"
      ]
    },
    "output": [
      "MODEL",
      "CLIP",
      "VAE",
      "CLIP_VISION",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false,
      false,
      false
    ],
    "output_name": [
      "MODEL",
      "CLIP",
      "VAE",
      "CLIP_VISION",
      "NAME_STRING"
    ],
    "name": "unCLIP Checkpoint Loader",
    "display_name": "unCLIP Checkpoint Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "Upscale Model Loader": {
    "input": {
      "required": {
        "model_name": [
          []
        ]
      }
    },
    "input_order": {
      "required": [
        "model_name"
      ]
    },
    "output": [
      "UPSCALE_MODEL",
      "STRING"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "UPSCALE_MODEL",
      "MODEL_NAME_TEXT"
    ],
    "name": "Upscale Model Loader",
    "display_name": "Upscale Model Loader",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Loaders",
    "output_node": false
  },
  "Upscale Model Switch": {
    "input": {
      "required": {
        "upscale_model_a": [
          "UPSCALE_MODEL"
        ],
        "upscale_model_b": [
          "UPSCALE_MODEL"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "upscale_model_a",
        "upscale_model_b",
        "boolean"
      ]
    },
    "output": [
      "UPSCALE_MODEL"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "UPSCALE_MODEL"
    ],
    "name": "Upscale Model Switch",
    "display_name": "Upscale Model Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Write to GIF": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "transition_frames": [
          "INT",
          {
            "default": 30,
            "min": 2,
            "max": 60,
            "step": 1
          }
        ],
        "image_delay_ms": [
          "FLOAT",
          {
            "default": 2500.0,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "duration_ms": [
          "FLOAT",
          {
            "default": 0.1,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "loops": [
          "INT",
          {
            "default": 0,
            "min": 0,
            "max": 100,
            "step": 1
          }
        ],
        "max_size": [
          "INT",
          {
            "default": 512,
            "min": 128,
            "max": 1280,
            "step": 1
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "/workspace/ComfyUI/output",
            "multiline": false
          }
        ],
        "filename": [
          "STRING",
          {
            "default": "morph_writer",
            "multiline": false
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "transition_frames",
        "image_delay_ms",
        "duration_ms",
        "loops",
        "max_size",
        "output_path",
        "filename"
      ]
    },
    "output": [
      "IMAGE",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "image_pass",
      "filepath_text",
      "filename_text"
    ],
    "name": "Write to GIF",
    "display_name": "Write to GIF",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation/Writer",
    "output_node": false
  },
  "Write to Video": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "transition_frames": [
          "INT",
          {
            "default": 30,
            "min": 0,
            "max": 120,
            "step": 1
          }
        ],
        "image_delay_sec": [
          "FLOAT",
          {
            "default": 2.5,
            "min": 0.1,
            "max": 60000.0,
            "step": 0.1
          }
        ],
        "fps": [
          "INT",
          {
            "default": 30,
            "min": 1,
            "max": 60.0,
            "step": 1
          }
        ],
        "max_size": [
          "INT",
          {
            "default": 512,
            "min": 128,
            "max": 1920,
            "step": 1
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/output",
            "multiline": false
          }
        ],
        "filename": [
          "STRING",
          {
            "default": "comfy_writer",
            "multiline": false
          }
        ],
        "codec": [
          [
            "AVC1",
            "FFV1",
            "H264",
            "MP4V"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "transition_frames",
        "image_delay_sec",
        "fps",
        "max_size",
        "output_path",
        "filename",
        "codec"
      ]
    },
    "output": [
      "IMAGE",
      "STRING",
      "STRING"
    ],
    "output_is_list": [
      false,
      false,
      false
    ],
    "output_name": [
      "IMAGE_PASS",
      "filepath_text",
      "filename_text"
    ],
    "name": "Write to Video",
    "display_name": "Write to Video",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation/Writer",
    "output_node": false
  },
  "VAE Input Switch": {
    "input": {
      "required": {
        "vae_a": [
          "VAE"
        ],
        "vae_b": [
          "VAE"
        ],
        "boolean": [
          "BOOLEAN",
          {
            "forceInput": true
          }
        ]
      }
    },
    "input_order": {
      "required": [
        "vae_a",
        "vae_b",
        "boolean"
      ]
    },
    "output": [
      "VAE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "VAE"
    ],
    "name": "VAE Input Switch",
    "display_name": "VAE Input Switch",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Logic",
    "output_node": false
  },
  "Video Dump Frames": {
    "input": {
      "required": {
        "video_path": [
          "STRING",
          {
            "default": "./ComfyUI/input/MyVideo.mp4",
            "multiline": false
          }
        ],
        "output_path": [
          "STRING",
          {
            "default": "./ComfyUI/input/MyVideo",
            "multiline": false
          }
        ],
        "prefix": [
          "STRING",
          {
            "default": "frame_",
            "multiline": false
          }
        ],
        "filenumber_digits": [
          "INT",
          {
            "default": 4,
            "min": -1,
            "max": 8,
            "step": 1
          }
        ],
        "extension": [
          [
            "png",
            "jpg",
            "gif",
            "tiff"
          ]
        ]
      }
    },
    "input_order": {
      "required": [
        "video_path",
        "output_path",
        "prefix",
        "filenumber_digits",
        "extension"
      ]
    },
    "output": [
      "STRING",
      "NUMBER"
    ],
    "output_is_list": [
      false,
      false
    ],
    "output_name": [
      "output_path",
      "processed_count"
    ],
    "name": "Video Dump Frames",
    "display_name": "Video Dump Frames",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "WAS Suite/Animation",
    "output_node": false
  },
  "CLIPSEG2": {
    "input": {
      "required": {
        "image": [
          "IMAGE"
        ],
        "text": [
          "STRING",
          {
            "default": "",
            "multiline": false
          }
        ],
        "use_cuda": [
          "BOOLEAN",
          {
            "default": false
          }
        ]
      },
      "optional": {
        "clipseg_model": [
          "CLIPSEG_MODEL"
        ]
      }
    },
    "input_order": {
      "required": [
        "image",
        "text",
        "use_cuda"
      ],
      "optional": [
        "clipseg_model"
      ]
    },
    "output": [
      "IMAGE"
    ],
    "output_is_list": [
      false
    ],
    "output_name": [
      "IMAGE"
    ],
    "name": "CLIPSEG2",
    "display_name": "CLIPSEG2",
    "description": "",
    "python_module": "custom_nodes.was-ns",
    "category": "image/transformation",
    "output_node": false
  }
}